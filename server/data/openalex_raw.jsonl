{"id": "https://openalex.org/W2345356016", "title": "Enrichr: a comprehensive gene set enrichment analysis web server 2016 update", "abstract": "Enrichment analysis is a popular method for analyzing gene sets generated by genome-wide experiments. Here we present a significant update to one of the tools in this domain called Enrichr. Enrichr currently contains a large collection of diverse gene set libraries available for analysis and download. In total, Enrichr currently contains 180 184 annotated gene sets from 102 gene set libraries. New features have been added to Enrichr including the ability to submit fuzzy sets, upload BED files, improved application programming interface and visualization of the results as clustergrams. Overall, Enrichr is a comprehensive resource for curated gene sets and a search engine that accumulates biological knowledge for further biological discoveries. Enrichr is freely available at: http://amp.pharm.mssm.edu/Enrichr.", "concepts": ["Biology", "Computational biology", "Computer science", "Information retrieval", "World Wide Web", "Data mining", "Genetics", "Programming language"], "domain": "environmental_science"}
{"id": "https://openalex.org/W4324046518", "title": "Chatting and cheating: Ensuring academic integrity in the era of ChatGPT", "abstract": "The use of artificial intelligence in academia is a hot topic in the education field. ChatGPT is an AI tool that offers a range of benefits, including increased student engagement, collaboration, and accessibility. However, is also raises concerns regarding academic honesty and plagiarism. This paper examines the opportunities and challenges of using ChatGPT in higher education, and discusses the potential risks and rewards of these tools. The paper also considers the difficulties of detecting and preventing academic dishonesty, and suggests strategies that universities can adopt to ensure ethical and responsible use of these tools. These strategies include developing policies and procedures, providing training and support, and using various methods to detect and prevent cheating. The paper concludes that while the use of AI in higher education presents both opportunities and challenges, universities can effectively address these concerns by taking a proactive and ethical approach to the use of these tools.", "concepts": ["Engineering ethics", "Public relations", "Psychology", "Political science", "Engineering", "Social psychology", "Mathematics", "Law"], "domain": "social_sciences"}
{"id": "https://openalex.org/W4403939428", "title": "Mindfulness-based cognitive therapy for depression", "abstract": "Dear Editor, Mindfulness gives a sight to be aware of the present moment-by-moment sensations, emotions, thoughts, and experiences with a non-judgmental attitude.[1,2] Practitioners of mindfulness learn to live in the present moment and not travel in the past or future with their emotional interpretations of events which leads to pain in life. This technique is helpful in patient groups to overcome their depressive feeling, emotions, and behavior.[3-6] Two approaches of mindfulness that are widely evaluated and effective are Mindfulness-Based Stress Reduction (MBSR) and Mindfulness-Based Cognitive Therapy (MBCT). MBCT and MBSR both are also effective in clinical depression. Practicing it decreases the risk of relapse in depression.[1-3] A, 30 yrs old female, post-graduate, married, Hindu, Hindi speaking, belongs to middle socioeconomic status, and from an urban area came to OPD with her husband for persistent low mood, crying spells, lack of joy in every activity, inability to perform household chores, avoiding others and try to live in her room alone, hopelessness, worthlessness, disturbed sleep and appetite from last three months. She was treated with antidepressants by a Psychiatrist with gradual response and referred for psychotherapy. A detailed interview showed that the patient's illness was precipitated by her repeated failure to get her desired job. Strained relationships and conflicts with her in-law also contribute to maintaining her problems. Due to her husband's job, they had to live far away from their native place leading to a sense of loneliness, lack of support, avoidance behavior, and poor motivation for activities. She was assessed with the Beck Depression Inventory (BDI), Hopelessness Scale of Beck et al.[4] (HSB), and WHOQOL-BRIEF at baseline, after 8 weeks of therapy sessions to understand the efficacy of Mindfulness-based cognitive therapy, and again after a follow-up period of next one month to know the durability of the management [Table 1].Table 1: Shows the pre-, post, and follow-up assessment scores of the patient on BDI, HSB, and WHOQOL-BRIEFHer scores on BDI suggest a severe level of depression at baseline. High on all domains of the hopelessness scale suggests a sense of hopelessness, negative expectations, and low motivation for the future. After intervention and in follow up she showed improvement in depressive symptoms and have hope in her life. Scores on WHOQOL-BRIEF were found low in baseline assessment on all domains. Anxiety and depression contribute to worsening the quality of life of sufferers due to poor support, lack of functioning, poor health, and low mood. Post-intervention scores were suggestive of improved quality of life in the patient which was maintained in follow-up. She improved in all domains of quality of life after intervention. Previous studies supported the result that MBCT provides an improvement in depressive symptoms, relapse prevention, and quality of life in patients with depression.[5-7] Depressive symptoms are colored with lots of negative emotions and cognitions, distorted ways of evaluation of self, others, and events, judgmental thinking, and pessimism. MBCT effectively deals with depressive symptoms. The results propose that depressive symptoms can be healed by disengaging from distorted cognition and restructuring it, increasing attention to the present moment through mindfulness exercises. It is a promising treatment for turning down the severity of depression and improving quality of life. Declaration of patient consent The authors certify that they have obtained all appropriate patient consent forms. In the form the patient(s) has/have given his/her/their consent for his/her/their images and other clinical information to be reported in the journal. The patients understand that their names and initials will not be published and due efforts will be made to conceal their identity, but anonymity cannot be guaranteed. Author's contribution Concept, design, definition of intellectual content, literature search, data acquisition: DK, NS Manuscript preparation: DK, NS. Manuscript editing and manuscript review. DK. Guarantor: DK. Financial support and sponsorship Nil. Conflicts of interest There are no conflicts of interest.", "concepts": ["Psychotherapist", "Psychology", "Clinical psychology", "Psychiatry", "Social psychology", "Economics", "Macroeconomics", "Philosophy"], "domain": "economics"}
{"id": "https://openalex.org/W3003217347", "title": "A new coronavirus associated with human respiratory disease in China", "abstract": "Abstract Emerging infectious diseases, such as severe acute respiratory syndrome (SARS) and Zika virus disease, present a major threat to public health 1–3 . Despite intense research efforts, how, when and where new diseases appear are still a source of considerable uncertainty. A severe respiratory disease was recently reported in Wuhan, Hubei province, China. As of 25 January 2020, at least 1,975 cases had been reported since the first patient was hospitalized on 12 December 2019. Epidemiological investigations have suggested that the outbreak was associated with a seafood market in Wuhan. Here we study a single patient who was a worker at the market and who was admitted to the Central Hospital of Wuhan on 26 December 2019 while experiencing a severe respiratory syndrome that included fever, dizziness and a cough. Metagenomic RNA sequencing 4 of a sample of bronchoalveolar lavage fluid from the patient identified a new RNA virus strain from the family Coronaviridae , which is designated here ‘WH-Human 1’ coronavirus (and has also been referred to as ‘2019-nCoV’). Phylogenetic analysis of the complete viral genome (29,903 nucleotides) revealed that the virus was most closely related (89.1% nucleotide similarity) to a group of SARS-like coronaviruses (genus Betacoronavirus, subgenus Sarbecovirus) that had previously been found in bats in China 5 . This outbreak highlights the ongoing ability of viral spill-over from animals to cause severe disease in humans.", "concepts": ["Virology", "Medicine", "Biology", "Internal medicine", "Genetics"], "domain": "environmental_science"}
{"id": "https://openalex.org/W3112376646", "title": "UniProt: the universal protein knowledgebase in 2021", "abstract": "The aim of the UniProt Knowledgebase is to provide users with a comprehensive, high-quality and freely accessible set of protein sequences annotated with functional information. In this article, we describe significant updates that we have made over the last two years to the resource. The number of sequences in UniProtKB has risen to approximately 190 million, despite continued work to reduce sequence redundancy at the proteome level. We have adopted new methods of assessing proteome completeness and quality. We continue to extract detailed annotations from the literature to add to reviewed entries and supplement these in unreviewed entries with annotations provided by automated systems such as the newly implemented Association-Rule-Based Annotator (ARBA). We have developed a credit-based publication submission interface to allow the community to contribute publications and annotations to UniProt entries. We describe how UniProtKB responded to the COVID-19 pandemic through expert curation of relevant entries that were rapidly made available to the research community through a dedicated portal. UniProt resources are available under a CC-BY (4.0) license via the web at https://www.uniprot.org/.", "concepts": ["Biology", "Computer science", "World Wide Web", "Computational biology", "Bioinformatics", "Genetics"], "domain": "environmental_science"}
{"id": "https://openalex.org/W4381799391", "title": "Global, regional, and national burden of diabetes from 1990 to 2021, with projections of prevalence to 2050: a systematic analysis for the Global Burden of Disease Study 2021", "abstract": "Background: Diabetes is one of the leading causes of death and disability worldwide, and affects people regardless of country, age group, or sex. Using the most recent evidentiary and analytical framework from the Global Burden of Diseases, Injuries, and Risk Factors Study (GBD), we produced location-specific, age-specific, and sex-specific estimates of diabetes prevalence and burden from 1990 to 2021, the proportion of type 1 and type 2 diabetes in 2021, the proportion of the type 2 diabetes burden attributable to selected risk factors, and projections of diabetes prevalence through 2050. Methods: Estimates of diabetes prevalence and burden were computed in 204 countries and territories, across 25 age groups, for males and females separately and combined; these estimates comprised lost years of healthy life, measured in disability-adjusted life-years (DALYs; defined as the sum of years of life lost [YLLs] and years lived with disability [YLDs]). We used the Cause of Death Ensemble model (CODEm) approach to estimate deaths due to diabetes, incorporating 25 666 location-years of data from vital registration and verbal autopsy reports in separate total (including both type 1 and type 2 diabetes) and type-specific models. Other forms of diabetes, including gestational and monogenic diabetes, were not explicitly modelled. Total and type 1 diabetes prevalence was estimated by use of a Bayesian meta-regression modelling tool, DisMod-MR 2.1, to analyse 1527 location-years of data from the scientific literature, survey microdata, and insurance claims; type 2 diabetes estimates were computed by subtracting type 1 diabetes from total estimates. Mortality and prevalence estimates, along with standard life expectancy and disability weights, were used to calculate YLLs, YLDs, and DALYs. When appropriate, we extrapolated estimates to a hypothetical population with a standardised age structure to allow comparison in populations with different age structures. We used the comparative risk assessment framework to estimate the risk-attributable type 2 diabetes burden for 16 risk factors falling under risk categories including environmental and occupational factors, tobacco use, high alcohol use, high body-mass index (BMI), dietary factors, and low physical activity. Using a regression framework, we forecast type 1 and type 2 diabetes prevalence through 2050 with Socio-demographic Index (SDI) and high BMI as predictors, respectively. Findings: In 2021, there were 529 million (95% uncertainty interval [UI] 500–564) people living with diabetes worldwide, and the global age-standardised total diabetes prevalence was 6·1% (5·8–6·5). At the super-region level, the highest age-standardised rates were observed in north Africa and the Middle East (9·3% [8·7–9·9]) and, at the regional level, in Oceania (12·3% [11·5–13·0]). Nationally, Qatar had the world's highest age-specific prevalence of diabetes, at 76·1% (73·1–79·5) in individuals aged 75–79 years. Total diabetes prevalence—especially among older adults—primarily reflects type 2 diabetes, which in 2021 accounted for 96·0% (95·1–96·8) of diabetes cases and 95·4% (94·9–95·9) of diabetes DALYs worldwide. In 2021, 52·2% (25·5–71·8) of global type 2 diabetes DALYs were attributable to high BMI. The contribution of high BMI to type 2 diabetes DALYs rose by 24·3% (18·5–30·4) worldwide between 1990 and 2021. By 2050, more than 1·31 billion (1·22–1·39) people are projected to have diabetes, with expected age-standardised total diabetes prevalence rates greater than 10% in two super-regions: 16·8% (16·1–17·6) in north Africa and the Middle East and 11·3% (10·8–11·9) in Latin America and Caribbean. By 2050, 89 (43·6%) of 204 countries and territories will have an age-standardised rate greater than 10%. Interpretation: Diabetes remains a substantial public health issue. Type 2 diabetes, which makes up the bulk of diabetes cases, is largely preventable and, in some cases, potentially reversible if identified and managed early in the disease course. However, all evidence indicates that diabetes prevalence is increasing worldwide, primarily due to a rise in obesity caused by multiple factors. Preventing and controlling type 2 diabetes remains an ongoing challenge. It is essential to better understand disparities in risk factor profiles and diabetes burden across populations, to inform strategies to successfully control diabetes risk factors within the context of multiple and complex drivers. Funding: Bill & Melinda Gates Foundation.", "concepts": ["Medicine", "Environmental health", "Intensive care medicine", "Internal medicine", "Political science", "Pathology", "Endocrinology", "Law"], "domain": "social_sciences"}
{"id": "https://openalex.org/W4394828356", "title": "GPT (Generative Pre-Trained Transformer)— A Comprehensive Review on Enabling Technologies, Potential Applications, Emerging Challenges, and Future Directions", "abstract": "The Generative Pre-trained Transformer (GPT) represents a notable breakthrough in the domain of natural language processing, which is propelling us toward the development of machines that can understand and communicate using language in a manner that closely resembles that of humans. GPT is based on the transformer architecture, a deep neural network designed for natural language processing tasks. Due to their impressive performance on natural language processing tasks and ability to effectively converse, GPT have gained significant popularity among researchers and industrial communities, making them one of the most widely used and effective models in natural language processing and related fields, which motivated to conduct this review. This review provides a detailed overview of the GPT, including its architecture, working process, training procedures, enabling technologies, and its impact on various applications. In this review, we also explored the potential challenges and limitations of a GPT. Furthermore, we discuss potential solutions and future directions. Overall, this paper aims to provide a comprehensive understanding of GPT, its enabling technologies, their impact on various applications, emerging challenges, and potential solutions.", "concepts": ["Computer science", "Artificial intelligence", "Risk analysis (engineering)", "Engineering", "Electrical engineering", "Medicine", "Art", "Visual arts"], "domain": "computer_science"}
{"id": "https://openalex.org/W4389166035", "title": "2023 ACC/AHA/ACCP/HRS Guideline for the Diagnosis and Management of Atrial Fibrillation: A Report of the American College of Cardiology/American Heart Association Joint Committee on Clinical Practice Guidelines", "abstract": "The \"2023 ACC/AHA/ACCP/HRS Guideline for the Diagnosis and Management of Atrial Fibrillation\" provides recommendations to guide clinicians in the treatment of patients with atrial fibrillation.", "concepts": ["Medicine", "Cardiology", "Internal medicine", "Intensive care medicine", "Pathology", "Political science", "Law"], "domain": "social_sciences"}
{"id": "https://openalex.org/W2256016639", "title": "Analysis of protein-coding genetic variation in 60,706 humans", "abstract": "Large-scale reference data sets of human genetic variation are critical for the medical and functional interpretation of DNA sequence changes. Here we describe the aggregation and analysis of high-quality exome (protein-coding region) DNA sequence data for 60,706 individuals of diverse ancestries generated as part of the Exome Aggregation Consortium (ExAC). This catalogue of human genetic diversity contains an average of one variant every eight bases of the exome, and provides direct evidence for the presence of widespread mutational recurrence. We have used this catalogue to calculate objective metrics of pathogenicity for sequence variants, and to identify genes subject to strong selection against various classes of mutation; identifying 3,230 genes with near-complete depletion of predicted protein-truncating variants, with 72% of these genes having no currently established human disease phenotype. Finally, we demonstrate that these data can be used for the efficient filtering of candidate disease-causing variants, and for the discovery of human 'knockout' variants in protein-coding genes. Exome sequencing data from 60,706 people of diverse geographic ancestry is presented, providing insight into genetic variation across populations, and illuminating the relationship between DNA variants and human disease. As part of the Exome Aggregation Consortium (ExAC) project, Daniel MacArthur and colleagues report on the generation and analysis of high-quality exome sequencing data from 60,706 individuals of diverse ancestry. This provides the most comprehensive catalogue of human protein-coding genetic variation to date, yielding unprecedented resolution for the analysis of very rare variants across multiple human populations. The catalogue is freely accessible and provides a critical reference panel for the clinical interpretation of genetic variants and the discovery of disease-related genes.", "concepts": ["Evolutionary biology", "Computational biology", "Biology", "Genetics", "Statistics", "Mathematics", "Physics", "Astrophysics"], "domain": "environmental_science"}
{"id": "https://openalex.org/W2473930607", "title": "Learning without Forgetting", "abstract": "When building a unified vision system or gradually adding new apabilities to a system, the usual assumption is that training data for all tasks is always available. However, as the number of tasks grows, storing and retraining on such data becomes infeasible. A new problem arises where we add new capabilities to a Convolutional Neural Network (CNN), but the training data for its existing capabilities are unavailable. We propose our Learning without Forgetting method, which uses only new task data to train the network while preserving the original capabilities. Our method performs favorably compared to commonly used feature extraction and fine-tuning adaption techniques and performs similarly to multitask learning that uses original task data we assume unavailable. A more surprising observation is that Learning without Forgetting may be able to replace fine-tuning with similar old and new task datasets for improved new task performance.", "concepts": ["Computer science", "Artificial intelligence", "Machine learning", "Philosophy", "Linguistics", "Business", "International trade", "Economics"], "domain": "materials_science"}
{"id": "https://openalex.org/W2337225114", "title": "The Scenario Model Intercomparison Project (ScenarioMIP) for CMIP6", "abstract": "Abstract. Projections of future climate change play a fundamental role in improving understanding of the climate system as well as characterizing societal risks and response options. The Scenario Model Intercomparison Project (ScenarioMIP) is the primary activity within Phase 6 of the Coupled Model Intercomparison Project (CMIP6) that will provide multi-model climate projections based on alternative scenarios of future emissions and land use changes produced with integrated assessment models. In this paper, we describe ScenarioMIP's objectives, experimental design, and its relation to other activities within CMIP6. The ScenarioMIP design is one component of a larger scenario process that aims to facilitate a wide range of integrated studies across the climate science, integrated assessment modeling, and impacts, adaptation, and vulnerability communities, and will form an important part of the evidence base in the forthcoming Intergovernmental Panel on Climate Change (IPCC) assessments. At the same time, it will provide the basis for investigating a number of targeted science and policy questions that are especially relevant to scenario-based analysis, including the role of specific forcings such as land use and aerosols, the effect of a peak and decline in forcing, the consequences of scenarios that limit warming to below 2 °C, the relative contributions to uncertainty from scenarios, climate models, and internal variability, and long-term climate system outcomes beyond the 21st century. To serve this wide range of scientific communities and address these questions, a design has been identified consisting of eight alternative 21st century scenarios plus one large initial condition ensemble and a set of long-term extensions, divided into two tiers defined by relative priority. Some of these scenarios will also provide a basis for variants planned to be run in other CMIP6-Endorsed MIPs to investigate questions related to specific forcings. Harmonized, spatially explicit emissions and land use scenarios generated with integrated assessment models will be provided to participating climate modeling groups by late 2016, with the climate model simulations run within the 2017–2018 time frame, and output from the climate model projections made available and analyses performed over the 2018–2020 period.", "concepts": ["Environmental science", "Climatology", "Environmental resource management", "Computer science", "Ecology", "Computer security", "Biology", "Geology"], "domain": "engineering"}
{"id": "https://openalex.org/W4396771941", "title": "Comparative Analysis of Flood Estimation using Log-Pearson Type III and Gumbel Max Models in the Cauvery River, India", "abstract": "Flooding is one of the most destructive global disasters in scale, geographical extent, property and life loss, and population displacement. The Cauvery River is one of the flood vulnerable rivers in the Peninsular region of India. At-site flood frequency analysis is performed using flow data obtained at the Kodumudi gauged site in the Cauvery River. Log Pearson Type III and Gumbel Max distribution models are used in the present study to estimate peak floods for different return periods. The Central Water Commission provides the annual maximum discharge for the Kodumudi gauged site over 39 years (1980-2018). The goodness of fit test employing the Kolmogorov-Smirnov and Anderson- Darling tests, reveals that Log-Pearson Type III best estimates peak floods in the study area. The peak floods predicted by Log-Pearson Type III for return periods 2, 5, 10, 25, 50, 100, 200, and 500 years are approximately 929, 1886, 2998, 5303, 8002, 11929, 17633, and 29228 cumecs. Hydraulic structures can be designed in the region based on 100-year flood. The present research could help with flooding management approaches, vulnerability analyses, and hydraulic structure design in the study region.", "concepts": ["Statistics", "Mathematics", "Geography", "Geology", "Biology", "Ecology", "Engineering", "Archaeology"], "domain": "mathematics"}
{"id": "https://openalex.org/W2611772571", "title": "The Modern-Era Retrospective Analysis for Research and Applications, Version 2 (MERRA-2)", "abstract": "The Modern-Era Retrospective Analysis for Research and Applications, version 2 (MERRA-2), is the latest atmospheric reanalysis of the modern satellite era produced by NASA’s Global Modeling and Assimilation Office (GMAO). MERRA-2 assimilates observation types not available to its predecessor, MERRA, and includes updates to the Goddard Earth Observing System (GEOS) model and analysis scheme so as to provide a viable ongoing climate analysis beyond MERRA’s terminus. While addressing known limitations of MERRA, MERRA-2 is also intended to be a development milestone for a future integrated Earth system analysis (IESA) currently under development at GMAO. This paper provides an overview of the MERRA-2 system and various performance metrics. Among the advances in MERRA-2 relevant to IESA are the assimilation of aerosol observations, several improvements to the representation of the stratosphere including ozone, and improved representations of cryospheric processes. Other improvements in the quality of MERRA-2 compared with MERRA include the reduction of some spurious trends and jumps related to changes in the observing system and reduced biases and imbalances in aspects of the water cycle. Remaining deficiencies are also identified. Production of MERRA-2 began in June 2014 in four processing streams and converged to a single near-real-time stream in mid-2015. MERRA-2 products are accessible online through the NASA Goddard Earth Sciences Data Information Services Center (GES DISC).", "concepts": ["Environmental science", "Meteorology", "Climatology", "Computer science", "Geology", "Geography", "Engineering", "Machine learning"], "domain": "engineering"}
{"id": "https://openalex.org/W4384464487", "title": "Students’ voices on generative AI: perceptions, benefits, and challenges in higher education", "abstract": "Abstract This study explores university students’ perceptions of generative AI (GenAI) technologies, such as ChatGPT, in higher education, focusing on familiarity, their willingness to engage, potential benefits and challenges, and effective integration. A survey of 399 undergraduate and postgraduate students from various disciplines in Hong Kong revealed a generally positive attitude towards GenAI in teaching and learning. Students recognized the potential for personalized learning support, writing and brainstorming assistance, and research and analysis capabilities. However, concerns about accuracy, privacy, ethical issues, and the impact on personal development, career prospects, and societal values were also expressed. According to John Biggs’ 3P model, student perceptions significantly influence learning approaches and outcomes. By understanding students’ perceptions, educators and policymakers can tailor GenAI technologies to address needs and concerns while promoting effective learning outcomes. Insights from this study can inform policy development around the integration of GenAI technologies into higher education. By understanding students’ perceptions and addressing their concerns, policymakers can create well-informed guidelines and strategies for the responsible and effective implementation of GenAI tools, ultimately enhancing teaching and learning experiences in higher education.", "concepts": ["Psychology", "Engineering ethics", "Medical education", "Pedagogy", "Political science", "Engineering", "Medicine", "Business"], "domain": "social_sciences"}
{"id": "https://openalex.org/W4390352677", "title": "Evaluasi Pembelajaran", "abstract": "Implementation of learning in the classroom has consequences for a teacher to improve his role and competence, because a competent teacher will find it easier to manage classes and carry out evaluations for his students both individually and in class. Evaluation is an attempt to obtain information about student learning outcomes as a whole, both attitudes, knowledge, and skills. This can be used by teachers as a decision-making step in determining teaching and learning strategies. Thus, teachers need to conduct assessments in the process and student learning outcomes. So that this paper will examine the evaluation of learning related to the achievement of student learning competencies, as well as innovations in improving learning evaluation in accordance with the times. This research uses descriptive qualitative research. This type of research library research with the method of literature study.", "concepts": ["Mathematics education", "Psychology", "Computer science", "Pedagogy", "Knowledge management", "Artificial intelligence", "Social psychology"], "domain": "biology"}
{"id": "https://openalex.org/W4315619045", "title": "The global epidemiology of nonalcoholic fatty liver disease (NAFLD) and nonalcoholic steatohepatitis (NASH): a systematic review", "abstract": "Background and Aims: NAFLD is a leading cause of liver-related morbidity and mortality. We assessed the global and regional prevalence, incidence, and mortality of NAFLD using an in-depth meta-analytic approach. Approach and Results: PubMed and Ovid MEDLINE were searched for NAFLD population-based studies from 1990 to 2019 survey year (last published 2022) per Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA). Meta-analysis was conducted using random-effects models. Bias risk assessment was per Joanna Briggs Institute. Of 2585 studies reviewed, 92 studies (N=9,361,716) met eligibility criteria. Across the study period (1990–2019), meta-analytic pooling of NAFLD prevalence estimates and ultrasound-defined NAFLD yielded an overall global prevalence of 30.05% (95% CI: 27.88%–32.32%) and 30.69% (28.4–33.09), respectively. Global NAFLD prevalence increased by +50.4% from 25.26% (21.59–29.33) in 1990–2006 to 38.00% (33.71–42.49) in 2016–2019 ( p &lt;0.001); ultrasound-defined NAFLD prevalence increased by +38.7% from 25.16% (19.46–31.87) in 1990–2006 to 34.59% (29.05–40.57) ( p =0.029). The highest NAFLD prevalence was in Latin America 44.37% (30.66%–59.00%), then Middle East and North Africa (MENA) (36.53%, 28.63%–45.22%), South Asia (33.83%, 22.91%–46.79%), South-East Asia (33.07%, 18.99%–51.03%), North America (31.20%, 25.86%–37.08%), East Asia (29.71%, 25.96%–33.76%), Asia Pacific 28.02% (24.69%–31.60%), Western Europe 25.10% (20.55%–30.28%). Among the NAFLD cohort diagnosed without a liver biopsy, pooled mortality rate per 1000 PY was 12.60 (6.68–23.67) for all-cause mortality; 4.20 (1.34–7.05) for cardiac-specific mortality; 2.83 (0.78–4.88) for extrahepatic cancer-specific mortality; and 0.92 (0.00–2.21) for liver-specific mortality. Conclusions: NAFLD global prevalence is 30% and increasing which requires urgent and comprehensive strategies to raise awareness and address all aspects of NAFLD on local, regional, and global levels.", "concepts": ["Medicine", "Internal medicine", "Gastroenterology", "Demography", "Environmental health", "Biology", "Sociology", "Optics"], "domain": "medicine"}
{"id": "https://openalex.org/W4319662928", "title": "Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models", "abstract": "We evaluated the performance of a large language model called ChatGPT on the United States Medical Licensing Exam (USMLE), which consists of three exams: Step 1, Step 2CK, and Step 3. ChatGPT performed at or near the passing threshold for all three exams without any specialized training or reinforcement. Additionally, ChatGPT demonstrated a high level of concordance and insight in its explanations. These results suggest that large language models may have the potential to assist with medical education, and potentially, clinical decision-making.", "concepts": ["Medical education", "Computer science", "Artificial intelligence", "Medicine", "Internal medicine"], "domain": "medicine"}
{"id": "https://openalex.org/W4318263917", "title": "ChatGPT is fun, but not an author", "abstract": "In less than 2 months, the artificial intelligence (AI) program ChatGPT has become a cultural sensation. It is freely accessible through a web portal created by the tool's developer, OpenAI. The program-which automatically creates text based on written prompts-is so popular that it's likely to be \"at capacity right now\" if you attempt to use it. When you do get through, ChatGPT provides endless entertainment. I asked it to rewrite the first scene of the classic American play Death of a Salesman, but to feature Princess Elsa from the animated movie Frozen as the main character instead of Willy Loman. The output was an amusing conversation in which Elsa-who has come home from a tough day of selling-is told by her son Happy, \"Come on, Mom. You're Elsa from Frozen. You have ice powers and you're a queen. You're unstoppable.\" Mash-ups like this are certainly fun, but there are serious implications for generative AI programs like ChatGPT in science and academia.", "concepts": ["Visual arts", "Computer science", "Media studies", "World Wide Web", "Psychology", "Artificial intelligence", "Art", "Sociology"], "domain": "psychology"}
{"id": "https://openalex.org/W2759190050", "title": "An Overview of Heart Rate Variability Metrics and Norms", "abstract": "Healthy biological systems exhibit complex patterns of variability that can be described by mathematical chaos. Heart rate variability (HRV) consists of changes in the time intervals between consecutive heartbeats, called interbeat intervals (IBIs). A healthy heart is not a metronome. The oscillations of a healthy heart are complex and constantly changing, which allow the cardiovascular system to rapidly adjust to sudden physical and psychological challenges to homeostasis. This article briefly reviews current perspectives on the mechanisms that generate 24 h, short-term (~5 min), and ultra-short-term (< 5 min) HRV, the importance of HRV, and its implications for health and performance. The authors provide an overview of widely-used HRV time domain, frequency, and nonlinear metrics. Time-domain indices quantify the amount of HRV observed during monitoring periods that may range from ~2 min to 24 h. Frequency-domain values calculate the absolute or relative amount of signal energy within component bands. Nonlinear measurements quantify the unpredictability and complexity of a series of IBIs. The authors survey published normative values for clinical, healthy, and optimal performance populations. They stress the importance of measurement context, including recording period length, subject age, and sex, on baseline HRV values. They caution that 24 h, short-term, and ultra-short-term normative values are not interchangeable. They encourage professionals to supplement published norms with findings from their own specialized populations. Finally, the authors provide an overview of HRV assessment strategies for clinical and optimal performance interventions.", "concepts": ["Computer science", "Medicine", "Psychology", "Internal medicine", "Biology", "Paleontology", "Philosophy", "Epistemology"], "domain": "materials_science"}
{"id": "https://openalex.org/W4360620450", "title": "Opinion Paper: “So what if ChatGPT wrote it?” Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy", "abstract": "Transformative artificially intelligent tools, such as ChatGPT, designed to generate sophisticated text indistinguishable from that produced by a human, are applicable across a wide range of contexts. The technology presents opportunities as well as, often ethical and legal, challenges, and has the potential for both positive and negative impacts for organisations, society, and individuals. Offering multi-disciplinary insight into some of these, this article brings together 43 contributions from experts in fields such as computer science, marketing, information systems, education, policy, hospitality and tourism, management, publishing, and nursing. The contributors acknowledge ChatGPT's capabilities to enhance productivity and suggest that it is likely to offer significant gains in the banking, hospitality and tourism, and information technology industries, and enhance business activities, such as management and marketing. Nevertheless, they also consider its limitations, disruptions to practices, threats to privacy and security, and consequences of biases, misuse, and misinformation. However, opinion is split on whether ChatGPT's use should be restricted or legislated. Drawing on these contributions, the article identifies questions requiring further research across three thematic areas: knowledge, transparency, and ethics; digital transformation of organisations and societies; and teaching, learning, and scholarly research. The avenues for further research include: identifying skills, resources, and capabilities needed to handle generative AI; examining biases of generative AI attributable to training datasets and processes; exploring business and societal contexts best suited for generative AI implementation; determining optimal combinations of human and generative AI for various tasks; identifying ways to assess accuracy of text produced by generative AI; and uncovering the ethical and legal issues in using generative AI across different contexts.", "concepts": ["Knowledge management", "Engineering ethics", "Sociology", "Public relations", "Political science", "Computer science", "Engineering", "Artificial intelligence"], "domain": "social_sciences"}
{"id": "https://openalex.org/W4313439128", "title": "MIMIC-IV, a freely accessible electronic health record dataset", "abstract": "Digital data collection during routine clinical practice is now ubiquitous within hospitals. The data contains valuable information on the care of patients and their response to treatments, offering exciting opportunities for research. Typically, data are stored within archival systems that are not intended to support research. These systems are often inaccessible to researchers and structured for optimal storage, rather than interpretability and analysis. Here we present MIMIC-IV, a publicly available database sourced from the electronic health record of the Beth Israel Deaconess Medical Center. Information available includes patient measurements, orders, diagnoses, procedures, treatments, and deidentified free-text clinical notes. MIMIC-IV is intended to support a wide array of research studies and educational material, helping to reduce barriers to conducting clinical research.", "concepts": ["Computer science", "Information retrieval", "World Wide Web", "Political science", "Law"], "domain": "social_sciences"}
{"id": "https://openalex.org/W4402625926", "title": "Twenty years of microplastics pollution research—what have we learned?", "abstract": "Twenty years after the first publication that used the term microplastic, we review current understanding, refine definitions, and consider future prospects. Microplastics arise from multiple sources, including tires, textiles, cosmetics, paint, and the fragmentation of larger items. They are widely distributed throughout the natural environment, with evidence of harm at multiple levels of biological organization. They are pervasive in food and drink and have been detected throughout the human body, with emerging evidence of negative effects. Environmental contamination could double by 2040, and wide-scale harm has been predicted. Public concern is increasing, and diverse measures to address microplastic pollution are being considered in international negotiations. Clear evidence on the efficacy of potential solutions is now needed to address the issue and to minimize the risks of unintended consequences.", "concepts": ["Environmental planning", "Environmental science", "Business", "Natural resource economics", "Environmental protection", "Biology", "Ecology", "Political science"], "domain": "economics"}
{"id": "https://openalex.org/W4391855109", "title": "A Review on Large Language Models: Architectures, Applications, Taxonomies, Open Issues and Challenges", "abstract": "Large Language Models (LLMs) recently demonstrated extraordinary capability, including natural language processing (NLP), language translation, text generation, question answering, etc. Moreover, LLMs are a new and essential part of computerized language processing, having the ability to understand complex verbal patterns and generate coherent and appropriate replies for the situation. Though this success of LLMs has prompted a substantial increase in research contributions, rapid growth has made it difficult to understand the overall impact of these improvements. Since a lot of new research on LLMs is coming out quickly, it is getting tough to get an overview of all of them in a short note. Consequently, the research community would benefit from a short but thorough review of the recent changes in this area. This article thoroughly overviews LLMs, including their history, architectures, transformers, resources, training methods, applications, impacts, challenges, etc. This paper begins by discussing the fundamental concepts of LLMs with its traditional pipeline of the LLMs training phase. It then provides an overview of the existing works, the history of LLMs, their evolution over time, the architecture of transformers in LLMs, the different resources of LLMs, and the different training methods that have been used to train them. It also demonstrated the datasets utilized in the studies. After that, the paper discusses the wide range of applications of LLMs, including biomedical and healthcare, education, social, business, and agriculture. It also illustrates how LLMs create an impact on society and shape the future of AI and how they can be used to solve real-world problems. Then it also explores open issues and challenges to deploying LLMs in real-world scenario. Our review paper aims to help practitioners, researchers, and experts thoroughly understand the evolution of LLMs, pre-trained architectures, applications, challenges, and future goals.", "concepts": ["Computer science", "Data science", "Natural language processing", "World Wide Web"], "domain": "computer_science"}
{"id": "https://openalex.org/W3159829212", "title": "<i>CrystalExplorer</i>: a program for Hirshfeld surface analysis, visualization and quantitative analysis of molecular crystals", "abstract": "CrystalExplorer is a native cross-platform program supported on Windows, MacOS and Linux with the primary function of visualization and investigation of molecular crystal structures, especially through the decorated Hirshfeld surface and its corresponding two-dimensional fingerprint, and through the visualization of void spaces in the crystal via isosurfaces of the promolecule electron density. Over the past decade, significant changes and enhancements have been incorporated into the program, such as the capacity to accurately and quickly calculate and visualize quantitative intermolecular interactions and, perhaps most importantly, the ability to interface with the Gaussian and NWChem programs to calculate quantum-mechanical properties of molecules. The current version, CrystalExplorer21 , incorporates these and other changes, and the software can be downloaded and used free of charge for academic research.", "concepts": ["Computer science", "Computer graphics (images)", "Crystallography", "Computational science", "Materials science", "Physics", "Chemistry", "Data mining"], "domain": "chemistry"}
{"id": "https://openalex.org/W2890167612", "title": "Nano based drug delivery systems: recent developments and future prospects", "abstract": "Nanomedicine and nano delivery systems are a relatively new but rapidly developing science where materials in the nanoscale range are employed to serve as means of diagnostic tools or to deliver therapeutic agents to specific targeted sites in a controlled manner. Nanotechnology offers multiple benefits in treating chronic human diseases by site-specific, and target-oriented delivery of precise medicines. Recently, there are a number of outstanding applications of the nanomedicine (chemotherapeutic agents, biological agents, immunotherapeutic agents etc.) in the treatment of various diseases. The current review, presents an updated summary of recent advances in the field of nanomedicines and nano based drug delivery systems through comprehensive scrutiny of the discovery and application of nanomaterials in improving both the efficacy of novel and old drugs (e.g., natural products) and selective diagnosis through disease marker molecules. The opportunities and challenges of nanomedicines in drug delivery from synthetic/natural sources to their clinical applications are also discussed. In addition, we have included information regarding the trends and perspectives in nanomedicine area.", "concepts": ["Nanotechnology", "Medicine", "Computer science", "Risk analysis (engineering)", "Materials science"], "domain": "biology"}
{"id": "https://openalex.org/W2963881378", "title": "SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation", "abstract": "We present a novel and practical deep fully convolutional neural network architecture for semantic pixel-wise segmentation termed SegNet. This core trainable segmentation engine consists of an encoder network, a corresponding decoder network followed by a pixel-wise classification layer. The architecture of the encoder network is topologically identical to the 13 convolutional layers in the VGG16 network [1] . The role of the decoder network is to map the low resolution encoder feature maps to full input resolution feature maps for pixel-wise classification. The novelty of SegNet lies is in the manner in which the decoder upsamples its lower resolution input feature map(s). Specifically, the decoder uses pooling indices computed in the max-pooling step of the corresponding encoder to perform non-linear upsampling. This eliminates the need for learning to upsample. The upsampled maps are sparse and are then convolved with trainable filters to produce dense feature maps. We compare our proposed architecture with the widely adopted FCN [2] and also with the well known DeepLab-LargeFOV [3] , DeconvNet [4] architectures. This comparison reveals the memory versus accuracy trade-off involved in achieving good segmentation performance. SegNet was primarily motivated by scene understanding applications. Hence, it is designed to be efficient both in terms of memory and computational time during inference. It is also significantly smaller in the number of trainable parameters than other competing architectures and can be trained end-to-end using stochastic gradient descent. We also performed a controlled benchmark of SegNet and other architectures on both road scenes and SUN RGB-D indoor scene segmentation tasks. These quantitative assessments show that SegNet provides good performance with competitive inference time and most efficient inference memory-wise as compared to other architectures. We also provide a Caffe implementation of SegNet and a web demo at http://mi.eng.cam.ac.uk/projects/segnet/.", "concepts": ["Computer science", "Artificial intelligence", "Computer vision", "Philosophy", "Linguistics", "Computer security", "Geodesy", "Geography"], "domain": "materials_science"}
{"id": "https://openalex.org/W2951912016", "title": "fastp: an ultra-fast all-in-one FASTQ preprocessor", "abstract": "Quality control and preprocessing of FASTQ files are essential to providing clean data for downstream analysis. Traditionally, a different tool is used for each operation, such as quality control, adapter trimming and quality filtering. These tools are often insufficiently fast as most are developed using high-level programming languages (e.g. Python and Java) and provide limited multi-threading support. Reading and loading data multiple times also renders preprocessing slow and I/O inefficient.We developed fastp as an ultra-fast FASTQ preprocessor with useful quality control and data-filtering features. It can perform quality control, adapter trimming, quality filtering, per-read quality pruning and many other operations with a single scan of the FASTQ data. This tool is developed in C++ and has multi-threading support. Based on our evaluation, fastp is 2-5 times faster than other FASTQ preprocessing tools such as Trimmomatic or Cutadapt despite performing far more operations than similar tools.The open-source code and corresponding instructions are available at https://github.com/OpenGene/fastp.", "concepts": ["Computer science", "Data mining", "Programming language", "Operating system"], "domain": "biology"}
{"id": "https://openalex.org/W2766358903", "title": "A communal catalogue reveals Earth’s multiscale microbial diversity", "abstract": "Our growing awareness of the microbial world's importance and diversity contrasts starkly with our limited understanding of its fundamental structure. Despite recent advances in DNA sequencing, a lack of standardized protocols and common analytical frameworks impedes comparisons among studies, hindering the development of global inferences about microbial life on Earth. Here we present a meta-analysis of microbial community samples collected by hundreds of researchers for the Earth Microbiome Project. Coordinated protocols and new analytical methods, particularly the use of exact sequences instead of clustered operational taxonomic units, enable bacterial and archaeal ribosomal RNA gene sequences to be followed across multiple studies and allow us to explore patterns of diversity at an unprecedented scale. The result is both a reference database giving global context to DNA sequence data and a framework for incorporating data from future studies, fostering increasingly complete characterization of Earth's microbial diversity.", "concepts": ["Astrobiology", "Earth science", "Geography", "Evolutionary biology", "Biology", "Geology", "Physics", "Sociology"], "domain": "engineering"}
{"id": "https://openalex.org/W4391848979", "title": "Explainable Artificial Intelligence (XAI) 2.0: A manifesto of open challenges and interdisciplinary research directions", "abstract": "Understanding black box models has become paramount as systems based on opaque Artificial Intelligence (AI) continue to flourish in diverse real-world applications. In response, Explainable AI (XAI) has emerged as a field of research with practical and ethical benefits across various domains. This paper highlights the advancements in XAI and its application in real-world scenarios and addresses the ongoing challenges within XAI, emphasizing the need for broader perspectives and collaborative efforts. We bring together experts from diverse fields to identify open problems, striving to synchronize research agendas and accelerate XAI in practical applications. By fostering collaborative discussion and interdisciplinary cooperation, we aim to propel XAI forward, contributing to its continued success. We aim to develop a comprehensive proposal for advancing XAI. To achieve this goal, we present a manifesto of 28 open problems categorized into nine categories. These challenges encapsulate the complexities and nuances of XAI and offer a road map for future research. For each problem, we provide promising research directions in the hope of harnessing the collective intelligence of interested stakeholders.", "concepts": ["Computer science", "Artificial intelligence", "Data science", "Political science", "World Wide Web", "Law"], "domain": "computer_science"}
{"id": "https://openalex.org/W2986574354", "title": "African Journal of Environmental Science and Technology", "abstract": "The aim of the present study is to test ESA's Sentinel-2 (S2) satellites (S2A and S2B) for an efficient quantification of land cover (LC) and forest compositions in a tropical environment southwest of Mount Kenya.Furthermore, outcome of the research is used to validate ESA's S2 prototype LC 20 m map of Africa that was produced in 2016.A decision tree that is based on significant altitudinal ranges was used to discriminate four natural tree compositions that occur within the investigation area.In addition, the classification process was supported by Google Earth images, and land use (LU) data that were provided by the local Kenyan Forest Service (KFS).Final classification products include four LC classes and five subclasses of forest (four natural forest subclasses plus one non-natural forest class).Results of the Jeffries-Matusita (JM) distance test show significant differences in spectral separability between all classes.Furthermore, the study identifies spectral signatures and significant wavelengths for a classification of all LC classes and forest subclasses where wavelengths of SWIR and the rededge domain show highest importance for the discrimination of tree compositions.Finally, considerable differences can be seen between the utilized multi-temporal classification set (total of 39 bands from three acquisition dates) and ESA's S2 prototype LC 20 m map of Africa 2016.A visual comparison of ESA's prototype map within the investigation area indicates an overrepresentation of tree cover areas (as confirmed in previous studies) and also an underrepresentation of water.", "concepts": ["Remote sensing", "Geography", "Environmental science", "Forestry", "Cartography", "Physical geography", "Computer science", "Mathematics"], "domain": "mathematics"}
{"id": "https://openalex.org/W2901954177", "title": "BEAST 2.5: An advanced software platform for Bayesian evolutionary analysis", "abstract": "Elaboration of Bayesian phylogenetic inference methods has continued at pace in recent years with major new advances in nearly all aspects of the joint modelling of evolutionary data. It is increasingly appreciated that some evolutionary questions can only be adequately answered by combining evidence from multiple independent sources of data, including genome sequences, sampling dates, phenotypic data, radiocarbon dates, fossil occurrences, and biogeographic range information among others. Including all relevant data into a single joint model is very challenging both conceptually and computationally. Advanced computational software packages that allow robust development of compatible (sub-)models which can be composed into a full model hierarchy have played a key role in these developments. Developing such software frameworks is increasingly a major scientific activity in its own right, and comes with specific challenges, from practical software design, development and engineering challenges to statistical and conceptual modelling challenges. BEAST 2 is one such computational software platform, and was first announced over 4 years ago. Here we describe a series of major new developments in the BEAST 2 core platform and model hierarchy that have occurred since the first release of the software, culminating in the recent 2.5 release.", "concepts": ["Computer science", "Data science", "Data mining", "Artificial intelligence", "Geography", "Geodesy", "Economics", "Market economy"], "domain": "economics"}
{"id": "https://openalex.org/W2297831771", "title": "Portugaliae Mathematica", "abstract": "Let S be a surface of general type with not birational bicanonical map and that does not contain a pencil of genus 2 curves.If K 2 S = 8, p g (S) = 4 and q(S) = 0 then S can be given as double cover of a quadric surface.We show that its moduli space is generically smooth of dimension 38, and single out an open subset.Note that for these surfaces h 2 (S, T S ) is not zero.", "concepts": ["Mathematics", "Pure mathematics", "Combinatorics", "Geometry", "Physics", "Botany", "Mechanical engineering", "Linguistics"], "domain": "mathematics"}
{"id": "https://openalex.org/W4368367885", "title": "ChatGPT in medicine: an overview of its applications, advantages, limitations, future prospects, and ethical considerations", "abstract": "This paper presents an analysis of the advantages, limitations, ethical considerations, future prospects, and practical applications of ChatGPT and artificial intelligence (AI) in the healthcare and medical domains. ChatGPT is an advanced language model that uses deep learning techniques to produce human-like responses to natural language inputs. It is part of the family of generative pre-training transformer (GPT) models developed by OpenAI and is currently one of the largest publicly available language models. ChatGPT is capable of capturing the nuances and intricacies of human language, allowing it to generate appropriate and contextually relevant responses across a broad spectrum of prompts. The potential applications of ChatGPT in the medical field range from identifying potential research topics to assisting professionals in clinical and laboratory diagnosis. Additionally, it can be used to help medical students, doctors, nurses, and all members of the healthcare fraternity to know about updates and new developments in their respective fields. The development of virtual assistants to aid patients in managing their health is another important application of ChatGPT in medicine. Despite its potential applications, the use of ChatGPT and other AI tools in medical writing also poses ethical and legal concerns. These include possible infringement of copyright laws, medico-legal complications, and the need for transparency in AI-generated content. In conclusion, ChatGPT has several potential applications in the medical and healthcare fields. However, these applications come with several limitations and ethical considerations which are presented in detail along with future prospects in medicine and healthcare.", "concepts": ["Engineering ethics", "Computer science", "Management science", "Data science", "Engineering", "Political science", "Computer security", "Law"], "domain": "social_sciences"}
{"id": "https://openalex.org/W2975424845", "title": "How to perform a meta-analysis with R: a practical tutorial", "abstract": "Objective Meta-analysis is of fundamental importance to obtain an unbiased assessment of the available evidence. In general, the use of meta-analysis has been increasing over the last three decades with mental health as a major research topic. It is then essential to well understand its methodology and interpret its results. In this publication, we describe how to perform a meta-analysis with the freely available statistical software environment R, using a working example taken from the field of mental health. Methods R package meta is used to conduct standard meta-analysis. Sensitivity analyses for missing binary outcome data and potential selection bias are conducted with R package metasens. All essential R commands are provided and clearly described to conduct and report analyses. Results The working example considers a binary outcome: we show how to conduct a fixed effect and random effects meta-analysis and subgroup analysis, produce a forest and funnel plot and to test and adjust for funnel plot asymmetry. All these steps work similar for other outcome types. Conclusions R represents a powerful and flexible tool to conduct meta-analyses. This publication gives a brief glimpse into the topic and provides directions to more advanced meta-analysis methods available in R.", "concepts": ["Computer science", "Data science", "Statistics", "Data mining", "Medicine", "Mathematics", "Mathematical economics", "Internal medicine"], "domain": "medicine"}
{"id": "https://openalex.org/W4400588278", "title": "The Government's Role in DMO-based Urban Tourism in Kayutangan area of Malang city", "abstract": "This research was conducted to determine the role of local governments to develop of urban tourism in Kayutangan area, Malang city East Java. The method used in this study is a quantitative method using Binomial analysis. This study uses six Destination Management Organization role variables, which were given to the stakeholder of the Kayutangan Area consisting of thirty respondents. The results in this study indicate that Coordination and leadership, marketing and promotion, partnerships, and public relations are the roles of the Destination Management Organization that are considered to have been carried out well by the government. However, the role of the government can still be improved, especially in planning and research indicators and in the role of product development which can be improved through further evaluation and concrete actions to increase the role of the government in planning and research and structured support in the development of tourist product packages still needs to be strengthened.", "concepts": ["Business", "Marketing", "Public relations", "Geography", "Political science", "Public administration", "Engineering", "Civil engineering"], "domain": "mathematics"}
{"id": "https://openalex.org/W3152719213", "title": "Toxic Mechanisms of Five Heavy Metals: Mercury, Lead, Chromium, Cadmium, and Arsenic", "abstract": "The industrial activities of the last century have caused massive increases in human exposure to heavy metals. Mercury, lead, chromium, cadmium, and arsenic have been the most common heavy metals that induced human poisonings. Here, we reviewed the mechanistic action of these heavy metals according to the available animal and human studies. Acute or chronic poisonings may occur following exposure through water, air, and food. Bioaccumulation of these heavy metals leads to a diversity of toxic effects on a variety of body tissues and organs. Heavy metals disrupt cellular events including growth, proliferation, differentiation, damage repairing processes, and apoptosis. Comparison of the mechanisms of action reveals similar pathways for these metals to induce toxicity including ROS generation, weakening of the antioxidant defense, enzymes inactivation, and oxidative stress. On the other hand, some of them have selective binding to specific macromolecules. The interaction of lead with aminolevulinic acid dehydratase and ferrochelatase is within this context. Reactions of other heavy metals with certain proteins were discussed as well. Some toxic metals including chromium, cadmium, and arsenic cause genomic instability. Defects in DNA repair following the induction of oxidative stress and DNA damage by the three metals have been considered as the cause of their carcinogenicity. Even with the current knowledge of hazards of heavy metals, the incidence of poisoning remains considerable and requires preventive and effective treatment. The application of chelation therapy for the management of metals poisoning could be another aspect of heavy metals to be reviewed in the future.", "concepts": ["Chemistry", "Environmental chemistry", "Biochemistry", "Organic chemistry", "Computer science", "Programming language"], "domain": "chemistry"}
{"id": "https://openalex.org/W3104895181", "title": "Climatologies at high resolution for the earth’s land surface areas", "abstract": "High resolution information on climatic conditions is essential to many applications in environmental and ecological sciences. Here we present the CHELSA Climatologies at high resolution for the earths land surface areas data of downscaled model output temperature and precipitation estimates of the ERA Interim climatic reanalysis to a high resolution of 30 arc seconds. The temperature algorithm is based on statistical downscaling of atmospheric temperatures. The precipitation algorithm incorporates orographic predictors including wind fields, valley exposition, and boundary layer height with a subsequent bias correction. The resulting data consist of a monthly temperature and precipitation climatology for the years 1979 to 2013. We compare the data derived from the CHELSA algorithm with other standard gridded products and station data from the Global Historical Climate Network. We compare the performance of the new climatologies in species distribution modelling and show that we can increase the accuracy of species range predictions. We further show that CHELSA climatological data has a similar accuracy as other products for temperature but that its predictions of precipitation patterns are better.", "concepts": ["Environmental science", "Climatology", "Meteorology", "Atmospheric sciences", "Geology", "Geography", "Composite material", "Oceanography"], "domain": "engineering"}
{"id": "https://openalex.org/W1550189296", "title": "Introduction to Computer Security", "abstract": "In this authoritative book, widely respected practitioner and teacher Matt Bishop presents a clear and useful introduction to the art and science of information security. Bishop's insights and realistic examples will help any practitioner or student understand the crucial links between security theory and the day-to-day security challenges of IT environments.Bishop explains the fundamentals of security: the different types of widely used policies, the mechanisms that implement these policies, the principles underlying both policies and mechanisms, and how attackers can subvert these tools--as well as how to defend against attackers. A practicum demonstrates how to apply these ideas and mechanisms to a realistic company.Coverage includes Confidentiality, integrity, and availability Operational issues, cost-benefit and risk analyses, legal and human factors Planning and implementing effective access control Defining security, confidentiality, and integrity policies Using cryptography and public-key systems, and recognizing their limits Understanding and using authentication: from passwords to biometrics Security design principles: least-privilege, fail-safe defaults, open design, economy of mechanism, and more Controlling information flow through systems and networks Assuring security throughout the system lifecycle Malicious logic: Trojan horses, viruses, boot sector and executable infectors, rabbits, bacteria, logic bombs--and defenses against them Vulnerability analysis, penetration studies, auditing, and intrusion detection and prevention Applying security principles to networks, systems, users, and programsIntroduction to Computer Security is adapted from Bishop's comprehensive and widely praised book, Computer Security: Art and Science. This shorter version of the original work omits much mathematical formalism, making it more accessible for professionals and students who have a less formal mathematical background, or for readers with a more practical than theoretical interest.", "concepts": ["Computer security", "Computer science", "Operating system"], "domain": "computer_science"}
{"id": "https://openalex.org/W4288079944", "title": "<i>Planck</i>2018 results", "abstract": "We present cosmological parameter results from the final full-mission Planck measurements of the CMB anisotropies. We find good consistency with the standard spatially-flat 6-parameter $\\Lambda$CDM cosmology having a power-law spectrum of adiabatic scalar perturbations (denoted \"base $\\Lambda$CDM\" in this paper), from polarization, temperature, and lensing, separately and in combination. A combined analysis gives dark matter density $\\Omega_c h^2 = 0.120\\pm 0.001$, baryon density $\\Omega_b h^2 = 0.0224\\pm 0.0001$, scalar spectral index $n_s = 0.965\\pm 0.004$, and optical depth $\\tau = 0.054\\pm 0.007$ (in this abstract we quote $68\\,\\%$ confidence regions on measured parameters and $95\\,\\%$ on upper limits). The angular acoustic scale is measured to $0.03\\,\\%$ precision, with $100\\theta_*=1.0411\\pm 0.0003$. These results are only weakly dependent on the cosmological model and remain stable, with somewhat increased errors, in many commonly considered extensions. Assuming the base-$\\Lambda$CDM cosmology, the inferred late-Universe parameters are: Hubble constant $H_0 = (67.4\\pm 0.5)$km/s/Mpc; matter density parameter $\\Omega_m = 0.315\\pm 0.007$; and matter fluctuation amplitude $\\sigma_8 = 0.811\\pm 0.006$. We find no compelling evidence for extensions to the base-$\\Lambda$CDM model. Combining with BAO we constrain the effective extra relativistic degrees of freedom to be $N_{\\rm eff} = 2.99\\pm 0.17$, and the neutrino mass is tightly constrained to $\\sum m_\\nu< 0.12$eV. The CMB spectra continue to prefer higher lensing amplitudes than predicted in base -$\\Lambda$CDM at over $2\\,\\sigma$, which pulls some parameters that affect the lensing amplitude away from the base-$\\Lambda$CDM model; however, this is not supported by the lensing reconstruction or (in models that also change the background geometry) BAO data. (Abridged)", "concepts": ["Physics", "Astrophysics", "Particle physics", "Quantum mechanics", "Statistics", "Mathematics"], "domain": "physics"}
{"id": "https://openalex.org/W2975859535", "title": "2017 ESC Guidelines on the Diagnosis and Treatment of Peripheral Arterial Diseases, in collaboration with the European Society for Vascular Surgery (ESVS)", "abstract": "The ESC Guidelines represent the views of the ESC and were produced after careful consideration of the scientific and medical knowledge and the evidence available at the time of their publication.The ESC is not responsible in the event of any contradiction, discrepancy and/or ambiguity between the ESC Guidelines and any other official recommendations or guidelines issued by the relevant public health authorities, in particular in relation to good use of healthcare or therapeutic strategies.Health professionals are encouraged to take the ESC Guidelines fully into account when exercising their clinical judgment, as well as in the determination and the implementation of preventive, diagnostic or therapeutic medical strategies; however, the ESC Guidelines do not override, in any way whatsoever, the individual responsibility of health professionals to make appropriate and accurate decisions in consideration of each patient's health condition and in consultation with that patient and, where appropriate and/or necessary, the patient's caregiver.Nor do the ESC Guidelines exempt health professionals from taking into full and careful consideration the relevant official updated recommendations or guidelines issued by the competent public health authorities, in order to manage each patient's case in light of the scientifically accepted data pursuant to their respective ethical and professional obligations.It is also the health professional's responsibility to verify the applicable rules and regulations relating to drugs and medical devices at the time of prescription.", "concepts": ["Medicine", "Public relations", "Medical emergency", "Nursing", "Law", "Linguistics", "Philosophy", "Political science"], "domain": "materials_science"}
{"id": "https://openalex.org/W4321499901", "title": "What if the devil is my guardian angel: ChatGPT as a case study of using chatbots in education", "abstract": "Abstract Artificial Intelligence (AI) technologies have been progressing constantly and being more visible in different aspects of our lives. One recent phenomenon is ChatGPT, a chatbot with a conversational artificial intelligence interface that was developed by OpenAI. As one of the most advanced artificial intelligence applications, ChatGPT has drawn much public attention across the globe. In this regard, this study examines ChatGPT in education, among early adopters, through a qualitative instrumental case study. Conducted in three stages, the first stage of the study reveals that the public discourse in social media is generally positive and there is enthusiasm regarding its use in educational settings. However, there are also voices who are approaching cautiously using ChatGPT in educational settings. The second stage of the study examines the case of ChatGPT through lenses of educational transformation, response quality, usefulness, personality and emotion, and ethics. In the third and final stage of the study, the investigation of user experiences through ten educational scenarios revealed various issues, including cheating, honesty and truthfulness of ChatGPT, privacy misleading, and manipulation. The findings of this study provide several research directions that should be considered to ensure a safe and responsible adoption of chatbots, specifically ChatGPT, in education.", "concepts": ["Psychology", "Engineering ethics", "Computer science", "Social psychology", "Political science", "Artificial intelligence", "Engineering", "Epistemology"], "domain": "social_sciences"}
{"id": "https://openalex.org/W2618096841", "title": "Sedentary Behavior Research Network (SBRN) – Terminology Consensus Project process and outcome", "abstract": "The prominence of sedentary behavior research in health science has grown rapidly. With this growth there is increasing urgency for clear, common and accepted terminology and definitions. Such standardization is difficult to achieve, especially across multi-disciplinary researchers, practitioners, and industries. The Sedentary Behavior Research Network (SBRN) undertook a Terminology Consensus Project to address this need. First, a literature review was completed to identify key terms in sedentary behavior research. These key terms were then reviewed and modified by a Steering Committee formed by SBRN. Next, SBRN members were invited to contribute to this project and interested participants reviewed and provided feedback on the proposed list of terms and draft definitions through an online survey. Finally, a conceptual model and consensus definitions (including caveats and examples for all age groups and functional abilities) were finalized based on the feedback received from the 87 SBRN member participants who responded to the original invitation and survey. Consensus definitions for the terms physical inactivity, stationary behavior, sedentary behavior, standing, screen time, non-screen-based sedentary time, sitting, reclining, lying, sedentary behavior pattern, as well as how the terms bouts, breaks, and interruptions should be used in this context are provided. It is hoped that the definitions resulting from this comprehensive, transparent, and broad-based participatory process will result in standardized terminology that is widely supported and adopted, thereby advancing future research, interventions, policies, and practices related to sedentary behaviors.", "concepts": ["Psychology", "Applied psychology", "Medical education", "Medicine", "Computer science", "Physical therapy", "Psychiatry", "Psychotherapist"], "domain": "materials_science"}
{"id": "https://openalex.org/W2339359539", "title": "International System for Human Cytogenetic Nomenclature", "abstract": "Ope n Pe e r Re v ie w", "concepts": ["Biology", "Evolutionary biology", "Computational biology", "Genetics", "Zoology"], "domain": "environmental_science"}
{"id": "https://openalex.org/W4280617757", "title": "Water electrolysis: from textbook knowledge to the latest scientific strategies and industrial developments", "abstract": "Replacing fossil fuels with energy sources and carriers that are sustainable, environmentally benign, and affordable is amongst the most pressing challenges for future socio-economic development.", "concepts": ["Engineering ethics", "Business", "Environmental science", "Engineering", "Waste management", "Political science", "Chemistry", "Electrical engineering"], "domain": "social_sciences"}
{"id": "https://openalex.org/W4244836331", "title": "Chemical Communications", "abstract": "Using ®eld mesocosms maintained for 6 months in an acid spruce forest, we investigated the in¯uence of microarthropods on biomass, structure and function of the soil microbial community.In the litter layer (L/F layer), the re-immigration of mesofauna into mesocosms did not signi®cantly aect substrate-induced respiration (SIR), biomass C, biomass N, biomass P, Nmineralisation or enzymes involved in N cycling.There was no eect of the mesofauna on the biomarkers for fungal biomass (ergosterol and phospholipid fatty acid 18:2o6) in the litter layer.Mesofauna activities increased microbial biomass (biomass C, N and P) in the H layer, and signi®cantly increased soil protease activity and phosphate content in the H layer. Since biomass P did not change signi®cantly when mesofauna recolonised mesocosms, they presumably aected P-mineralisation by producing Prich faeces.Discriminant analysis showed that mesofauna aected microbial N-mobilisation in the H layer. Higher protease and arginine deaminase activities in mesocosms with mesofauna may have been caused by faunal grazing on soil microorganisms.", "concepts": ["Chemistry", "Computer science"], "domain": "chemistry"}
{"id": "https://openalex.org/W2772366318", "title": "An assessment of the global impact of 21st century land use change on soil erosion", "abstract": "Abstract Human activity and related land use change are the primary cause of accelerated soil erosion, which has substantial implications for nutrient and carbon cycling, land productivity and in turn, worldwide socio-economic conditions. Here we present an unprecedentedly high resolution (250 × 250 m) global potential soil erosion model, using a combination of remote sensing, GIS modelling and census data. We challenge the previous annual soil erosion reference values as our estimate, of 35.9 Pg yr −1 of soil eroded in 2012, is at least two times lower. Moreover, we estimate the spatial and temporal effects of land use change between 2001 and 2012 and the potential offset of the global application of conservation practices. Our findings indicate a potential overall increase in global soil erosion driven by cropland expansion. The greatest increases are predicted to occur in Sub-Saharan Africa, South America and Southeast Asia. The least developed economies have been found to experience the highest estimates of soil erosion rates.", "concepts": ["Environmental science", "Physical geography", "Geography", "Soil science", "Ecology", "Geology", "Oceanography", "Paleontology"], "domain": "engineering"}
{"id": "https://openalex.org/W4400459768", "title": "Design and Analysis of Various Formwork Systems", "abstract": "Concrete is a fundamental material in the construction industry, with formwork playing a crucial role in shaping and strengthening concrete elements. It also represents a significant cost in building projects. The history of formwork is extensive, and diverse systems have been employed across various projects. When selecting a formwork system, considerations such as safety, cost, structural requirements, construction duration, and environmental impact must be carefully weighed. This project provides a comprehensive review of different formwork systems used in concrete construction, encompassing their materials, flexibility, fabrication methods, application in structures, and environmental implications. The advantages and limitations of these systems are analysed and compared, culminating in practical recommendations. Formwork systems are pivotal in determining the success of construction projects in terms of efficiency, quality, cost-effectiveness, and safety. Recent innovations, particularly modular formwork systems, have revolutionized the construction industry in countries like Japan, Singapore, Malaysia, and the Middle East. These systems have proven to be cost- effective, enhance construction quality, and accelerate project timelines. Their adaptability makes them particularly suitable for mass construction projects in India, where achieving high-quality, rapid construction is crucial. By leveraging modern formwork technologies, construction practices can achieve safer, faster, and more sustainable outcomes, aligning with advancements", "concepts": ["Construction engineering", "Engineering", "Risk analysis (engineering)", "Civil engineering", "Computer science", "Business", "History", "Ecology"], "domain": "mathematics"}
{"id": "https://openalex.org/W2981869278", "title": "Dissecting racial bias in an algorithm used to manage the health of populations", "abstract": "Health systems rely on commercial prediction algorithms to identify and help patients with complex health needs. We show that a widely used algorithm, typical of this industry-wide approach and affecting millions of patients, exhibits significant racial bias: At a given risk score, Black patients are considerably sicker than White patients, as evidenced by signs of uncontrolled illnesses. Remedying this disparity would increase the percentage of Black patients receiving additional help from 17.7 to 46.5%. The bias arises because the algorithm predicts health care costs rather than illness, but unequal access to care means that we spend less money caring for Black patients than for White patients. Thus, despite health care cost appearing to be an effective proxy for health by some measures of predictive accuracy, large racial biases arise. We suggest that the choice of convenient, seemingly effective proxies for ground truth can be an important source of algorithmic bias in many contexts.", "concepts": ["Computer science", "Actuarial science", "Medicine", "Algorithm", "Psychology", "Machine learning", "Economics", "Political science"], "domain": "psychology"}
{"id": "https://openalex.org/W4319662928", "title": "Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models", "abstract": "We evaluated the performance of a large language model called ChatGPT on the United States Medical Licensing Exam (USMLE), which consists of three exams: Step 1, Step 2CK, and Step 3. ChatGPT performed at or near the passing threshold for all three exams without any specialized training or reinforcement. Additionally, ChatGPT demonstrated a high level of concordance and insight in its explanations. These results suggest that large language models may have the potential to assist with medical education, and potentially, clinical decision-making.", "concepts": ["Medical education", "Computer science", "Artificial intelligence", "Medicine", "Internal medicine"], "domain": "biology"}
{"id": "https://openalex.org/W4294732694", "title": "Standards of Care for the Health of Transgender and Gender Diverse People, Version 8", "abstract": "Transgender healthcare is a rapidly evolving interdisciplinary field. In the last decade, there has been an unprecedented increase in the number and visibility of transgender and gender diverse (TGD) people seeking support and gender-affirming medical treatment in parallel with a significant rise in the scientific literature in this area. The World Professional Association for Transgender Health (WPATH) is an international, multidisciplinary, professional association whose mission is to promote evidence-based care, education, research, public policy, and respect in transgender health. One of the main functions of WPATH is to promote the highest standards of health care for TGD people through the Standards of Care (SOC). The SOC was initially developed in 1979 and the last version (SOC-7) was published in 2012. In view of the increasing scientific evidence, WPATH commissioned a new version of the Standards of Care, the SOC-8.", "concepts": ["Psychology", "Gender studies", "Medicine", "Sociology", "Family medicine", "Political science", "Law"], "domain": "social_sciences"}
{"id": "https://openalex.org/W2752033985", "title": "2017 ESC focused update on dual antiplatelet therapy in coronary artery disease developed in collaboration with EACTS", "abstract": "The ESC Guidelines represent the views of the ESC and were produced after careful consideration of the scientific and medical knowledge and the evidence available at the time of their publication.The ESC is not responsible in the event of any contradiction, discrepancy and/or ambiguity between the ESC Guidelines and any other official recommendations or guidelines issued by the relevant public health authorities, in particular in relation to good use of healthcare or therapeutic strategies.Health professionals are encouraged to take the ESC Guidelines fully into account when exercising their clinical judgment, as well as in the determination and the implementation of preventive, diagnostic or therapeutic medical strategies; however, the ESC Guidelines do not override, in any way whatsoever, the individual responsibility of health professionals to make appropriate and accurate decisions in consideration of each patient's health condition and in consultation with that patient and, where appropriate and/or necessary, the patient's caregiver.Nor do the ESC Guidelines exempt health professionals from taking into full and careful consideration the relevant official updated recommendations or guidelines issued by the competent public health authorities, in order to manage each patient's case in light of the scientifically accepted data pursuant to their respective ethical and professional obligations.It is also the health professional's responsibility to verify the applicable rules and regulations relating to drugs and medical devices at the time of prescription.", "concepts": ["Medicine", "Public relations", "Medical emergency", "Medical education", "Nursing", "Law", "Linguistics", "Philosophy"], "domain": "materials_science"}
{"id": "https://openalex.org/W4402061574", "title": "Abstractive Text Summarization Using GAN", "abstract": "In the field of natural language processing, the task of writing long concepts into short expressions has attracted attention due to its ability to simplify the processing and understanding of information. While traditional transcription techniques are effective to some extent, they often fail to capture the essence and nuances of the original texts. This article explores a new approach to collecting abstract data using artificial neural networks (GANs), a class of deep learning models known for their ability to create patterns of real information. We describe the fundamentals of text collection through a comprehensive review of existing literature and methods and highlight the complexity of GAN-based text. Our goal is to transform complex text into context and meaning by combining the power of GANs with natural language understanding. We detail the design and training of an adaptive GAN model for the text recognition task. We also conduct various experiments and evaluations using established metrics such as ROUGE and BLEU scores to evaluate the effectiveness and efficiency of our approach. The results show that GANs can be used to improve the quality and consistency of generated content, data storage, data analysis paper, etc. It shows its promise in paving the way for advanced applications in fields. Through this research, we aim to contribute to the continued evolution of writing technology, providing insights and innovations that support the field to a new level of well-done.", "concepts": ["Computer science", "Artificial intelligence", "Natural language processing", "Psychology", "Paleontology", "Mathematics", "Management", "Pure mathematics"], "domain": "mathematics"}
{"id": "https://openalex.org/W2905811773", "title": "When to use and how to report the results of PLS-SEM", "abstract": "Purpose The purpose of this paper is to provide a comprehensive, yet concise, overview of the considerations and metrics required for partial least squares structural equation modeling (PLS-SEM) analysis and result reporting. Preliminary considerations are summarized first, including reasons for choosing PLS-SEM, recommended sample size in selected contexts, distributional assumptions, use of secondary data, statistical power and the need for goodness-of-fit testing. Next, the metrics as well as the rules of thumb that should be applied to assess the PLS-SEM results are covered. Besides presenting established PLS-SEM evaluation criteria, the overview includes the following new guidelines: PLSpredict (i.e., a novel approach for assessing a model’s out-of-sample prediction), metrics for model comparisons, and several complementary methods for checking the results’ robustness. Design/methodology/approach This paper provides an overview of previously and recently proposed metrics as well as rules of thumb for evaluating the research results based on the application of PLS-SEM. Findings Most of the previously applied metrics for evaluating PLS-SEM results are still relevant. Nevertheless, scholars need to be knowledgeable about recently proposed metrics (e.g. model comparison criteria) and methods (e.g. endogeneity assessment, latent class analysis and PLSpredict), and when and how to apply them to extend their analyses. Research limitations/implications Methodological developments associated with PLS-SEM are rapidly emerging. The metrics reported in this paper are useful for current applications, but must always be up to date with the latest developments in the PLS-SEM method. Originality/value In light of more recent research and methodological developments in the PLS-SEM domain, guidelines for the method’s use need to be continuously extended and updated. This paper is the most current and comprehensive summary of the PLS-SEM method and the metrics applied to assess its solutions.", "concepts": ["Computer science", "Data mining", "Artificial intelligence", "Machine learning", "Mathematics", "Statistics", "Algorithm", "Psychology"], "domain": "mathematics"}
{"id": "https://openalex.org/W2594644573", "title": "Operational classification of seizure types by the International League Against Epilepsy: Position Paper of the ILAE Commission for Classification and Terminology", "abstract": "The International League Against Epilepsy (ILAE) presents a revised operational classification of seizure types. The purpose of such a revision is to recognize that some seizure types can have either a focal or generalized onset, to allow classification when the onset is unobserved, to include some missing seizure types, and to adopt more transparent names. Because current knowledge is insufficient to form a scientifically based classification, the 2017 Classification is operational (practical) and based on the 1981 Classification, extended in 2010. Changes include the following: (1) \"partial\" becomes \"focal\"; (2) awareness is used as a classifier of focal seizures; (3) the terms dyscognitive, simple partial, complex partial, psychic, and secondarily generalized are eliminated; (4) new focal seizure types include automatisms, behavior arrest, hyperkinetic, autonomic, cognitive, and emotional; (5) atonic, clonic, epileptic spasms, myoclonic, and tonic seizures can be of either focal or generalized onset; (6) focal to bilateral tonic-clonic seizure replaces secondarily generalized seizure; (7) new generalized seizure types are absence with eyelid myoclonia, myoclonic absence, myoclonic-atonic, myoclonic-tonic-clonic; and (8) seizures of unknown onset may have features that can still be classified. The new classification does not represent a fundamental change, but allows greater flexibility and transparency in naming seizure types.", "concepts": ["Medicine", "Political science", "Neuroscience", "Psychology", "Computer science", "Psychiatry", "Data science", "Philosophy"], "domain": "materials_science"}
{"id": "https://openalex.org/W2500751094", "title": "Deep Feature Extraction and Classification of Hyperspectral Images Based on Convolutional Neural Networks", "abstract": "Due to the advantages of deep learning, in this paper, a regularized deep feature extraction (FE) method is presented for hyperspectral image (HSI) classification using a convolutional neural network (CNN). The proposed approach employs several convolutional and pooling layers to extract deep features from HSIs, which are nonlinear, discriminant, and invariant. These features are useful for image classification and target detection. Furthermore, in order to address the common issue of imbalance between high dimensionality and limited availability of training samples for the classification of HSI, a few strategies such as L2 regularization and dropout are investigated to avoid overfitting in class data modeling. More importantly, we propose a 3-D CNN-based FE model with combined regularization to extract effective spectral-spatial features of hyperspectral imagery. Finally, in order to further improve the performance, a virtual sample enhanced method is proposed. The proposed approaches are carried out on three widely used hyperspectral data sets: Indian Pines, University of Pavia, and Kennedy Space Center. The obtained results reveal that the proposed models with sparse constraints provide competitive results to state-of-the-art methods. In addition, the proposed deep FE opens a new window for further research.", "concepts": ["Artificial intelligence", "Computer science", "Remote sensing", "Geology", "Philosophy", "Linguistics"], "domain": "engineering"}
{"id": "https://openalex.org/W3009906937", "title": "The species Severe acute respiratory syndrome-related coronavirus: classifying 2019-nCoV and naming it SARS-CoV-2", "abstract": "The present outbreak of a coronavirus-associated acute respiratory disease called coronavirus disease 19 (COVID-19) is the third documented spillover of an animal coronavirus to humans in only two decades that has resulted in a major epidemic. The Coronaviridae Study Group (CSG) of the International Committee on Taxonomy of Viruses, which is responsible for developing the classification of viruses and taxon nomenclature of the family Coronaviridae, has assessed the placement of the human pathogen, tentatively named 2019-nCoV, within the Coronaviridae. Based on phylogeny, taxonomy and established practice, the CSG recognizes this virus as forming a sister clade to the prototype human and bat severe acute respiratory syndrome coronaviruses (SARS-CoVs) of the species Severe acute respiratory syndrome-related coronavirus, and designates it as SARS-CoV-2. In order to facilitate communication, the CSG proposes to use the following naming convention for individual isolates: SARS-CoV-2/host/location/isolate/date. While the full spectrum of clinical manifestations associated with SARS-CoV-2 infections in humans remains to be determined, the independent zoonotic transmission of SARS-CoV and SARS-CoV-2 highlights the need for studying viruses at the species level to complement research focused on individual pathogenic viruses of immediate significance. This will improve our understanding of virus–host interactions in an ever-changing environment and enhance our preparedness for future outbreaks.", "concepts": ["Biology", "Virology", "Medicine", "Pathology", "Internal medicine"], "domain": "environmental_science"}
{"id": "https://openalex.org/W2790166049", "title": "The spread of true and false news online", "abstract": "We investigated the differential diffusion of all of the verified true and false news stories distributed on Twitter from 2006 to 2017. The data comprise ~126,000 stories tweeted by ~3 million people more than 4.5 million times. We classified news as true or false using information from six independent fact-checking organizations that exhibited 95 to 98% agreement on the classifications. Falsehood diffused significantly farther, faster, deeper, and more broadly than the truth in all categories of information, and the effects were more pronounced for false political news than for false news about terrorism, natural disasters, science, urban legends, or financial information. We found that false news was more novel than true news, which suggests that people were more likely to share novel information. Whereas false stories inspired fear, disgust, and surprise in replies, true stories inspired anticipation, sadness, joy, and trust. Contrary to conventional wisdom, robots accelerated the spread of true and false news at the same rate, implying that false news spreads more than the truth because humans, not robots, are more likely to spread it.", "concepts": ["Internet privacy", "Political science", "Psychology", "Computer science", "Social psychology", "Law", "Programming language"], "domain": "biology"}
{"id": "https://openalex.org/W3105577662", "title": "AID: A Benchmark Data Set for Performance Evaluation of Aerial Scene Classification", "abstract": "Aerial scene classification, which aims to automatically label an aerial image with a specific semantic category, is a fundamental problem for understanding high-resolution remote sensing imagery. In recent years, it has become an active task in the remote sensing area, and numerous algorithms have been proposed for this task, including many machine learning and data-driven approaches. However, the existing data sets for aerial scene classification, such as UC-Merced data set and WHU-RS19, contain relatively small sizes, and the results on them are already saturated. This largely limits the development of scene classification algorithms. This paper describes the Aerial Image data set (AID): a large-scale data set for aerial scene classification. The goal of AID is to advance the state of the arts in scene classification of remote sensing images. For creating AID, we collect and annotate more than 10000 aerial scene images. In addition, a comprehensive review of the existing aerial scene classification techniques as well as recent widely used deep learning methods is given. Finally, we provide a performance analysis of typical aerial scene classification and deep learning approaches on AID, which can be served as the baseline results on this benchmark.", "concepts": ["Computer science", "Artificial intelligence", "Remote sensing", "Data mining", "Computer vision", "Geology", "Geodesy", "Programming language"], "domain": "engineering"}
{"id": "https://openalex.org/W2626354203", "title": "Diabetic Foot Ulcers and Their Recurrence", "abstract": "Foot ulceration is the most common lower-extremity complication in patients with diabetes mellitus. This review considers the pathogenesis, treatment, and management of diabetic foot ulcers, including prevention of recurrence.", "concepts": ["Medicine", "Surgery", "Internal medicine", "Endocrinology", "Philosophy", "Linguistics"], "domain": "materials_science"}
{"id": "https://openalex.org/W2493916176", "title": "Enriching Word Vectors with Subword Information", "abstract": "Continuous word representations, trained on large unlabeled corpora are useful for many natural language processing tasks. Popular models that learn such representations ignore the morphology of words, by assigning a distinct vector to each word. This is a limitation, especially for languages with large vocabularies and many rare words. In this paper, we propose a new approach based on the skipgram model, where each word is represented as a bag of character n-grams. A vector representation is associated to each character n-gram; words being represented as the sum of these representations. Our method is fast, allowing to train models on large corpora quickly and allows us to compute word representations for words that did not appear in the training data. We evaluate our word representations on nine different languages, both on word similarity and analogy tasks. By comparing to recently proposed morphological word representations, we show that our vectors achieve state-of-the-art performance on these tasks.", "concepts": ["Computer science", "Natural language processing", "Artificial intelligence", "Speech recognition", "Linguistics", "Mathematics", "Philosophy", "Geometry"], "domain": "materials_science"}
{"id": "https://openalex.org/W4390352677", "title": "Evaluasi Pembelajaran", "abstract": "Implementation of learning in the classroom has consequences for a teacher to improve his role and competence, because a competent teacher will find it easier to manage classes and carry out evaluations for his students both individually and in class. Evaluation is an attempt to obtain information about student learning outcomes as a whole, both attitudes, knowledge, and skills. This can be used by teachers as a decision-making step in determining teaching and learning strategies. Thus, teachers need to conduct assessments in the process and student learning outcomes. So that this paper will examine the evaluation of learning related to the achievement of student learning competencies, as well as innovations in improving learning evaluation in accordance with the times. This research uses descriptive qualitative research. This type of research library research with the method of literature study.", "concepts": ["Mathematics education", "Psychology", "Computer science", "Pedagogy", "Knowledge management", "Artificial intelligence", "Social psychology"], "domain": "psychology"}
{"id": "https://openalex.org/W2530960585", "title": "Impact of anthropogenic climate change on wildfire across western US forests", "abstract": "Significance Increased forest fire activity across the western United States in recent decades has contributed to widespread forest mortality, carbon emissions, periods of degraded air quality, and substantial fire suppression expenditures. Although numerous factors aided the recent rise in fire activity, observed warming and drying have significantly increased fire-season fuel aridity, fostering a more favorable fire environment across forested systems. We demonstrate that human-caused climate change caused over half of the documented increases in fuel aridity since the 1970s and doubled the cumulative forest fire area since 1984. This analysis suggests that anthropogenic climate change will continue to chronically enhance the potential for western US forest fire activity while fuels are not limiting.", "concepts": ["Geography", "Environmental science", "Physical geography", "Climatology", "Environmental resource management", "Ecology", "Geology", "Biology"], "domain": "engineering"}
{"id": "https://openalex.org/W4400837307", "title": "Quality Control to Reduce Appearance Defects at PT. Musical Instrument", "abstract": "This research was conducted at PT. Musical Instruments that aim to analyze quality control to reduce appearance defects in piano products on the assembling production line. The problem faced by the company is the high level of product defects which has an impact on decreasing quality and customer satisfaction. The research method used is Six sigma with a DMAIC (Define, Measure, Analyze, Improve, Control) approach. This type of research is quantitative, with data collected in the form of the number of production defects in pianos. To analyze the causes of defects, a fishbone diagram with 4M + 1E factors is used, namely Man, Machine, Method, Material, and Environment. The results of the analysis show that the main factors causing appearance defects in piano products include incompatibility with work methods, lack of worker training, use of non-standard materials, suboptimal jig conditions, and unsupportive working environment. Based on these findings, improvement proposals are given in the form of improving standard operating procedures, regular training for workers, the use of high-quality materials, regular maintenance and calibration of jigs, and improvement of work environment conditions. The implementation of this improvement proposal is expected to reduce the number of appearance defects in piano products, improve product quality, and meet the quality standards expected by PT. Musical instrument.", "concepts": ["Computer science", "Reliability engineering", "Manufacturing engineering", "Operations management", "Engineering", "Mathematics", "Artificial intelligence", "Mechanical engineering"], "domain": "mathematics"}
{"id": "https://openalex.org/W4400928626", "title": "Analysis of Cylinder Comp Product Quality Control with Proposed Improvements at PT. Jakarta Automotive", "abstract": "In the era of globalization, the manufacturing industry faces its biggest challenge, namely the demands of consumer needs with high quality standards. Various kinds of waste often occur in the production process, one of which is caused by a poor layout of facilities, for example the arrangement of machines on the production line that is not suitable. This is a problem in the production process of machining cylinder comp at PT. Jakarta Automotive. With the aim of finding out the factors that cause product defects in machining cylinder comp and finding design of improvement proposals to reduce the defects that occur, this study uses a quantitative method to find DPMO and sigma values as an analysis of the cause of the problem. The result of this study was the discovery of less than optimal engine layout settings that caused TAP NG defects in the product. So that a design of a proposed improvement was made in the form of a change in the engine layout. In conclusion, in this study, it was identified that the non-optimal engine layout was the cause of the high defects. Therefore, improvements are proposed in the form of changing the engine layout on the production line with the aim of reducing the level of defects caused by a less than optimal layout.", "concepts": ["Manufacturing engineering", "Computer science", "Automotive engineering", "Engineering", "Mechanical engineering", "Mathematics", "Philosophy", "Epistemology"], "domain": "mathematics"}
{"id": "https://openalex.org/W4391136507", "title": "A Survey on Evaluation of Large Language Models", "abstract": "Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate , where to evaluate , and how to evaluate . Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, education, natural and social sciences, agent applications, and other areas. Secondly, we answer the ‘where’ and ‘how’ questions by diving into the evaluation methods and benchmarks, which serve as crucial components in assessing the performance of LLMs. Then, we summarize the success and failure cases of LLMs in different tasks. Finally, we shed light on several future challenges that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to researchers in the realm of LLMs evaluation, thereby aiding the development of more proficient LLMs. Our key point is that evaluation should be treated as an essential discipline to better assist the development of LLMs. We consistently maintain the related open-source materials at: https://github.com/MLGroupJLU/LLM-eval-survey", "concepts": ["Computer science", "Psychology", "Social psychology"], "domain": "computer_science"}
{"id": "https://openalex.org/W3010233963", "title": "The Incubation Period of Coronavirus Disease 2019 (COVID-19) From Publicly Reported Confirmed Cases: Estimation and Application", "abstract": "A novel human coronavirus, severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), was identified in China in December 2019. There is limited support for many of its key epidemiologic features, including the incubation period for clinical disease (coronavirus disease 2019 [COVID-19]), which has important implications for surveillance and control activities.", "concepts": ["Medicine", "Internal medicine", "Pathology", "Biology", "Biochemistry", "Statistics", "Mathematics"], "domain": "environmental_science"}
{"id": "https://openalex.org/W4386151915", "title": "2023 ESC Guidelines for the management of cardiovascular disease in patients with diabetes", "abstract": "The ESC Guidelines represent the views of the ESC and were produced after careful consideration of the scientific and medical knowledge and the evidence available at the time of their publication.The ESC is not responsible in the event of any contradiction, discrepancy, and/or ambiguity between the ESC Guidelines and any other official recommendations or guidelines issued by the relevant public health authorities, in particular in relation to good use of healthcare or therapeutic strategies.Health professionals are encouraged to take the ESC Guidelines fully into account when exercising their clinical judgment, as well as in the determination and the implementation of preventive, diagnostic or therapeutic medical strategies; however, the ESC Guidelines do not override, in any way whatsoever, the individual responsibility of health professionals to make appropriate and accurate decisions in consideration of each patient's health condition and in consultation with that patient and, where appropriate and/or necessary, the patient's caregiver.Nor do the ESC Guidelines exempt health professionals from taking into full and careful consideration the relevant official updated recommendations or guidelines issued by the competent public health authorities, in order to manage each patient's case in light of the scientifically accepted data pursuant to their respective ethical and professional obligations.It is also the health professional's responsibility to verify the applicable rules and regulations relating to drugs and medical devices at the time of prescription.", "concepts": ["Medicine", "Public relations", "Medical emergency", "Nursing", "Law", "Linguistics", "Philosophy", "Epistemology"], "domain": "social_sciences"}
{"id": "https://openalex.org/W2738516213", "title": "Extended Reconstructed Sea Surface Temperature, Version 5 (ERSSTv5): Upgrades, Validations, and Intercomparisons", "abstract": "Abstract The monthly global 2° × 2° Extended Reconstructed Sea Surface Temperature (ERSST) has been revised and updated from version 4 to version 5. This update incorporates a new release of ICOADS release 3.0 (R3.0), a decade of near-surface data from Argo floats, and a new estimate of centennial sea ice from HadISST2. A number of choices in aspects of quality control, bias adjustment, and interpolation have been substantively revised. The resulting ERSST estimates have more realistic spatiotemporal variations, better representation of high-latitude SSTs, and ship SST biases are now calculated relative to more accurate buoy measurements, while the global long-term trend remains about the same. Progressive experiments have been undertaken to highlight the effects of each change in data source and analysis technique upon the final product. The reconstructed SST is systematically decreased by 0.077°C, as the reference data source is switched from ship SST in ERSSTv4 to modern buoy SST in ERSSTv5. Furthermore, high-latitude SSTs are decreased by 0.1°–0.2°C by using sea ice concentration from HadISST2 over HadISST1. Changes arising from remaining innovations are mostly important at small space and time scales, primarily having an impact where and when input observations are sparse. Cross validations and verifications with independent modern observations show that the updates incorporated in ERSSTv5 have improved the representation of spatial variability over the global oceans, the magnitude of El Niño and La Niña events, and the decadal nature of SST changes over 1930s–40s when observation instruments changed rapidly. Both long- (1900–2015) and short-term (2000–15) SST trends in ERSSTv5 remain significant as in ERSSTv4.", "concepts": ["Environmental science", "Climatology", "Meteorology", "Geology", "Geodesy", "Oceanography", "Geography", "Physics"], "domain": "engineering"}
{"id": "https://openalex.org/W4392741075", "title": "Evaluation metrics and statistical tests for machine learning", "abstract": "Abstract Research on different machine learning (ML) has become incredibly popular during the past few decades. However, for some researchers not familiar with statistics, it might be difficult to understand how to evaluate the performance of ML models and compare them with each other. Here, we introduce the most common evaluation metrics used for the typical supervised ML tasks including binary, multi-class, and multi-label classification, regression, image segmentation, object detection, and information retrieval. We explain how to choose a suitable statistical test for comparing models, how to obtain enough values of the metric for testing, and how to perform the test and interpret its results. We also present a few practical examples about comparing convolutional neural networks used to classify X-rays with different lung infections and detect cancer tumors in positron emission tomography images.", "concepts": ["Computer science", "Artificial intelligence", "Machine learning", "Statistics", "Mathematics", "Operations management", "Economics"], "domain": "economics"}
{"id": "https://openalex.org/W4393936599", "title": "ADMETlab 3.0: an updated comprehensive online ADMET prediction platform enhanced with broader coverage, improved performance, API functionality and decision support", "abstract": "Abstract ADMETlab 3.0 is the second updated version of the web server that provides a comprehensive and efficient platform for evaluating ADMET-related parameters as well as physicochemical properties and medicinal chemistry characteristics involved in the drug discovery process. This new release addresses the limitations of the previous version and offers broader coverage, improved performance, API functionality, and decision support. For supporting data and endpoints, this version includes 119 features, an increase of 31 compared to the previous version. The updated number of entries is 1.5 times larger than the previous version with over 400 000 entries. ADMETlab 3.0 incorporates a multi-task DMPNN architecture coupled with molecular descriptors, a method that not only guaranteed calculation speed for each endpoint simultaneously, but also achieved a superior performance in terms of accuracy and robustness. In addition, an API has been introduced to meet the growing demand for programmatic access to large amounts of data in ADMETlab 3.0. Moreover, this version includes uncertainty estimates in the prediction results, aiding in the confident selection of candidate compounds for further studies and experiments. ADMETlab 3.0 is publicly for access without the need for registration at: https://admetlab3.scbdd.com.", "concepts": ["Computer science", "Data mining", "Database", "Machine learning", "Bioinformatics", "Biology", "World Wide Web", "Systems engineering"], "domain": "computer_science"}
{"id": "https://openalex.org/W4318457133", "title": "Reporting reliability, convergent and discriminant validity with structural equation modeling: A review and best-practice recommendations", "abstract": "Abstract Many constructs in management studies, such as perceptions, personalities, attitudes, and behavioral intentions, are not directly observable. Typically, empirical studies measure such constructs using established scales with multiple indicators. When the scales are used in a different population, the items are translated into other languages or revised to adapt to other populations, it is essential for researchers to report the quality of measurement scales before using them to test hypotheses. Researchers commonly report the quality of these measurement scales based on Cronbach’s alpha and confirmatory factor analysis results. However, these results are usually inadequate and sometimes inappropriate. Moreover, researchers rarely consider sampling errors for these psychometric quality measures. In this best practice paper, we first critically review the most frequently-used approaches in empirical studies to evaluate the quality of measurement scales when using structural equation modeling. Next, we recommend best practices in assessing reliability, convergent and discriminant validity based on multiple criteria and taking sampling errors into consideration. Then, we illustrate with numerical examples the application of a specifically-developed R package, measureQ, that provides a one-stop solution for implementing the recommended best practices and a template for reporting the results. measureQ is easy to implement, even for those new to R. Our overall aim is to provide a best-practice reference for future authors, reviewers, and editors in reporting and reviewing the quality of measurement scales in empirical management studies.", "concepts": ["Psychology", "Computer science", "Applied psychology", "Management science", "Data science", "Statistics", "Clinical psychology", "Machine learning"], "domain": "psychology"}
{"id": "https://openalex.org/W4323544162", "title": "Electrochemical Impedance Spectroscopy─A Tutorial", "abstract": "This tutorial provides the theoretical background, the principles, and applications of Electrochemical Impedance Spectroscopy (EIS) in various research and technological sectors. The text has been organized in 17 sections starting with basic knowledge on sinusoidal signals, complex numbers, phasor notation, and transfer functions, continuing with the definition of impedance in electrical circuits, the principles of EIS, the validation of the experimental data, their simulation to equivalent electrical circuits, and ending with practical considerations and selected examples on the utility of EIS to corrosion, energy related applications, and biosensing. A user interactive excel file showing the Nyquist and Bode plots of some model circuits is provided in the Supporting Information. This tutorial aspires to provide the essential background to graduate students working on EIS, as well as to endow the knowledge of senior researchers on various fields where EIS is involved. We also believe that the content of this tutorial will be a useful educational tool for EIS instructors.", "concepts": ["Computer science", "Electronic engineering", "Electrical engineering", "Engineering", "Chemistry", "Mathematics", "Physics", "Psychology"], "domain": "psychology"}
{"id": "https://openalex.org/W2804822363", "title": "SWISS-MODEL: homology modelling of protein structures and complexes", "abstract": "Homology modelling has matured into an important technique in structural biology, significantly contributing to narrowing the gap between known protein sequences and experimentally determined structures. Fully automated workflows and servers simplify and streamline the homology modelling process, also allowing users without a specific computational expertise to generate reliable protein models and have easy access to modelling results, their visualization and interpretation. Here, we present an update to the SWISS-MODEL server, which pioneered the field of automated modelling 25 years ago and been continuously further developed. Recently, its functionality has been extended to the modelling of homo- and heteromeric complexes. Starting from the amino acid sequences of the interacting proteins, both the stoichiometry and the overall structure of the complex are inferred by homology modelling. Other major improvements include the implementation of a new modelling engine, ProMod3 and the introduction a new local model quality estimation method, QMEANDisCo. SWISS-MODEL is freely available at https://swissmodel.expasy.org.", "concepts": ["Biology", "Computational biology", "Computer science", "Bioinformatics", "Data mining", "Genetics", "Database", "Biochemistry"], "domain": "biology"}
{"id": "https://openalex.org/W2911188335", "title": "Cancer statistics, 2019", "abstract": "Each year, the American Cancer Society estimates the numbers of new cancer cases and deaths that will occur in the United States and compiles the most recent data on cancer incidence, mortality, and survival. Incidence data, available through 2015, were collected by the Surveillance, Epidemiology, and End Results Program; the National Program of Cancer Registries; and the North American Association of Central Cancer Registries. Mortality data, available through 2016, were collected by the National Center for Health Statistics. In 2019, 1,762,450 new cancer cases and 606,880 cancer deaths are projected to occur in the United States. Over the past decade of data, the cancer incidence rate (2006-2015) was stable in women and declined by approximately 2% per year in men, whereas the cancer death rate (2007-2016) declined annually by 1.4% and 1.8%, respectively. The overall cancer death rate dropped continuously from 1991 to 2016 by a total of 27%, translating into approximately 2,629,200 fewer cancer deaths than would have been expected if death rates had remained at their peak. Although the racial gap in cancer mortality is slowly narrowing, socioeconomic inequalities are widening, with the most notable gaps for the most preventable cancers. For example, compared with the most affluent counties, mortality rates in the poorest counties were 2-fold higher for cervical cancer and 40% higher for male lung and liver cancers during 2012-2016. Some states are home to both the wealthiest and the poorest counties, suggesting the opportunity for more equitable dissemination of effective cancer prevention, early detection, and treatment strategies. A broader application of existing cancer control knowledge with an emphasis on disadvantaged groups would undoubtedly accelerate progress against cancer.", "concepts": ["Medicine", "Demography", "Gerontology", "Environmental health", "Surgery", "Oncology", "Internal medicine", "Physics"], "domain": "medicine"}
{"id": "https://openalex.org/W2801159594", "title": "Posterior Summarization in Bayesian Phylogenetics Using Tracer 1.7", "abstract": "Bayesian inference of phylogeny using Markov chain Monte Carlo (MCMC) plays a central role in understanding evolutionary history from molecular sequence data. Visualizing and analyzing the MCMC-generated samples from the posterior distribution is a key step in any non-trivial Bayesian inference. We present the software package Tracer (version 1.7) for visualizing and analyzing the MCMC trace files generated through Bayesian phylogenetic inference. Tracer provides kernel density estimation, multivariate visualization, demographic trajectory reconstruction, conditional posterior distribution summary, and more. Tracer is open-source and available at http://beast.community/tracer.", "concepts": ["Computer science", "Artificial intelligence", "Biology"], "domain": "biology"}
{"id": "https://openalex.org/W2939222610", "title": "Canagliflozin and Renal Outcomes in Type 2 Diabetes and Nephropathy", "abstract": "Type 2 diabetes mellitus is the leading cause of kidney failure worldwide, but few effective long-term treatments are available. In cardiovascular trials of inhibitors of sodium–glucose cotransporter 2 (SGLT2), exploratory results have suggested that such drugs may improve renal outcomes in patients with type 2 diabetes.", "concepts": ["Medicine", "Internal medicine", "Endocrinology", "Intensive care medicine", "Pharmacology", "Urology"], "domain": "medicine"}
{"id": "https://openalex.org/W4324309277", "title": "2023 Alzheimer's disease facts and figures", "abstract": "Abstract This article describes the public health impact of Alzheimer's disease, including prevalence and incidence, mortality and morbidity, use and costs of care, and the overall impact on family caregivers, the dementia workforce and society. The Special Report examines the patient journey from awareness of cognitive changes to potential treatment with drugs that change the underlying biology of Alzheimer's. An estimated 6.7 million Americans age 65 and older are living with Alzheimer's dementia today. This number could grow to 13.8 million by 2060 barring the development of medical breakthroughs to prevent, slow or cure AD. Official death certificates recorded 121,499 deaths from AD in 2019, and Alzheimer's disease was officially listed as the sixth‐leading cause of death in the United States. In 2020 and 2021, when COVID‐19 entered the ranks of the top ten causes of death, Alzheimer's was the seventh‐leading cause of death. Alzheimer's remains the fifth‐leading cause of death among Americans age 65 and older. Between 2000 and 2019, deaths from stroke, heart disease and HIV decreased, whereas reported deaths from AD increased more than 145%. This trajectory of deaths from AD was likely exacerbated by the COVID‐19 pandemic in 2020 and 2021. More than 11 million family members and other unpaid caregivers provided an estimated 18 billion hours of care to people with Alzheimer's or other dementias in 2022. These figures reflect a decline in the number of caregivers compared with a decade earlier, as well as an increase in the amount of care provided by each remaining caregiver. Unpaid dementia caregiving was valued at $339.5 billion in 2022. Its costs, however, extend to family caregivers’ increased risk for emotional distress and negative mental and physical health outcomes — costs that have been aggravated by COVID‐19. Members of the paid health care workforce are involved in diagnosing, treating and caring for people with dementia. In recent years, however, a shortage of such workers has developed in the United States. This shortage — brought about, in part, by COVID‐19 — has occurred at a time when more members of the dementia care workforce are needed. Therefore, programs will be needed to attract workers and better train health care teams. Average per‐person Medicare payments for services to beneficiaries age 65 and older with AD or other dementias are almost three times as great as payments for beneficiaries without these conditions, and Medicaid payments are more than 22 times as great. Total payments in 2023 for health care, long‐term care and hospice services for people age 65 and older with dementia are estimated to be $345 billion. The Special Report examines whether there will be sufficient numbers of physician specialists to provide Alzheimer's care and treatment now that two drugs are available that change the underlying biology of Alzheimer's disease.", "concepts": ["Medicine", "Gerontology", "Internal medicine", "Physics", "Optics", "Economics", "Economic growth"], "domain": "medicine"}
{"id": "https://openalex.org/W2950464315", "title": "The R package Rsubread is easier, faster, cheaper and better for alignment and quantification of RNA sequencing reads", "abstract": "We present Rsubread, a Bioconductor software package that provides high-performance alignment and read counting functions for RNA-seq reads. Rsubread is based on the successful Subread suite with the added ease-of-use of the R programming environment, creating a matrix of read counts directly as an R object ready for downstream analysis. It integrates read mapping and quantification in a single package and has no software dependencies other than R itself. We demonstrate Rsubread's ability to detect exon-exon junctions de novo and to quantify expression at the level of either genes, exons or exon junctions. The resulting read counts can be input directly into a wide range of downstream statistical analyses using other Bioconductor packages. Using SEQC data and simulations, we compare Rsubread to TopHat2, STAR and HTSeq as well as to counting functions in the Bioconductor infrastructure packages. We consider the performance of these tools on the combined quantification task starting from raw sequence reads through to summary counts, and in particular evaluate the performance of different combinations of alignment and counting algorithms. We show that Rsubread is faster and uses less memory than competitor tools and produces read count summaries that more accurately correlate with true values.", "concepts": ["Biology", "Computer science", "Computational biology", "Genetics", "Programming language", "Operations management", "Economics"], "domain": "economics"}
{"id": "https://openalex.org/W2903062212", "title": "Tisagenlecleucel in Adult Relapsed or Refractory Diffuse Large B-Cell Lymphoma", "abstract": "Patients with diffuse large B-cell lymphoma that is refractory to primary and second-line therapies or that has relapsed after stem-cell transplantation have a poor prognosis. The chimeric antigen receptor (CAR) T-cell therapy tisagenlecleucel targets and eliminates CD19-expressing B cells and showed efficacy against B-cell lymphomas in a single-center, phase 2a study.We conducted an international, phase 2, pivotal study of centrally manufactured tisagenlecleucel involving adult patients with relapsed or refractory diffuse large B-cell lymphoma who were ineligible for or had disease progression after autologous hematopoietic stem-cell transplantation. The primary end point was the best overall response rate (i.e., the percentage of patients who had a complete or partial response), as judged by an independent review committee.A total of 93 patients received an infusion and were included in the evaluation of efficacy. The median time from infusion to data cutoff was 14 months (range, 0.1 to 26). The best overall response rate was 52% (95% confidence interval, 41 to 62); 40% of the patients had complete responses, and 12% had partial responses. Response rates were consistent across prognostic subgroups. At 12 months after the initial response, the rate of relapse-free survival was estimated to be 65% (79% among patients with a complete response). The most common grade 3 or 4 adverse events of special interest included cytokine release syndrome (22%), neurologic events (12%), cytopenias lasting more than 28 days (32%), infections (20%), and febrile neutropenia (14%). Three patients died from disease progression within 30 days after infusion. No deaths were attributed to tisagenlecleucel, cytokine release syndrome, or cerebral edema. No differences between response groups in tumor expression of CD19 or immune checkpoint-related proteins were found.In this international study of CAR T-cell therapy in relapsed or refractory diffuse large B-cell lymphoma in adults, high rates of durable responses were produced with the use of tisagenlecleucel. (Funded by Novartis; JULIET ClinicalTrials.gov number, NCT02445248 .).", "concepts": ["Medicine", "Internal medicine", "Gastroenterology", "Oncology", "Immunology", "Physics", "Astrobiology"], "domain": "physics"}
{"id": "https://openalex.org/W2928467655", "title": "Health effects of dietary risks in 195 countries, 1990–2017: a systematic analysis for the Global Burden of Disease Study 2017", "abstract": "<h2>Summary</h2><h3>Background</h3> Suboptimal diet is an important preventable risk factor for non-communicable diseases (NCDs); however, its impact on the burden of NCDs has not been systematically evaluated. This study aimed to evaluate the consumption of major foods and nutrients across 195 countries and to quantify the impact of their suboptimal intake on NCD mortality and morbidity. <h3>Methods</h3> By use of a comparative risk assessment approach, we estimated the proportion of disease-specific burden attributable to each dietary risk factor (also referred to as population attributable fraction) among adults aged 25 years or older. The main inputs to this analysis included the intake of each dietary factor, the effect size of the dietary factor on disease endpoint, and the level of intake associated with the lowest risk of mortality. Then, by use of disease-specific population attributable fractions, mortality, and disability-adjusted life-years (DALYs), we calculated the number of deaths and DALYs attributable to diet for each disease outcome. <h3>Findings</h3> In 2017, 11 million (95% uncertainty interval [UI] 10–12) deaths and 255 million (234–274) DALYs were attributable to dietary risk factors. High intake of sodium (3 million [1–5] deaths and 70 million [34–118] DALYs), low intake of whole grains (3 million [2–4] deaths and 82 million [59–109] DALYs), and low intake of fruits (2 million [1–4] deaths and 65 million [41–92] DALYs) were the leading dietary risk factors for deaths and DALYs globally and in many countries. Dietary data were from mixed sources and were not available for all countries, increasing the statistical uncertainty of our estimates. <h3>Interpretation</h3> This study provides a comprehensive picture of the potential impact of suboptimal diet on NCD mortality and morbidity, highlighting the need for improving diet across nations. Our findings will inform implementation of evidence-based dietary interventions and provide a platform for evaluation of their impact on human health annually. <h3>Funding</h3> Bill & Melinda Gates Foundation.", "concepts": ["Medicine", "Environmental health", "Demography", "Internal medicine", "Sociology"], "domain": "medicine"}
{"id": "https://openalex.org/W3168436232", "title": "AutoDock Vina 1.2.0: New Docking Methods, Expanded Force Field, and Python Bindings", "abstract": "AutoDock Vina is arguably one of the fastest and most widely used open-source programs for molecular docking. However, compared to other programs in the AutoDock Suite, it lacks support for modeling specific features such as macrocycles or explicit water molecules. Here, we describe the implementation of this functionality in AutoDock Vina 1.2.0. Additionally, AutoDock Vina 1.2.0 supports the AutoDock4.2 scoring function, simultaneous docking of multiple ligands, and a batch mode for docking a large number of ligands. Furthermore, we implemented Python bindings to facilitate scripting and the development of docking workflows. This work is an effort toward the unification of the features of the AutoDock4 and AutoDock Vina programs. The source code is available at https://github.com/ccsb-scripps/AutoDock-Vina.", "concepts": ["Computer science", "Programming language", "Operating system", "Chemistry", "Medicine", "Biochemistry", "Nursing"], "domain": "chemistry"}
{"id": "https://openalex.org/W2611395271", "title": "Weyl and Dirac semimetals in three-dimensional solids", "abstract": "Weyl and Dirac semimetals are three dimensional phases of matter with gapless electronic excitations that are protected by topology and symmetry. As three dimensional analogs of graphene, they have generated much recent interest. Deep connections exist with particle physics models of relativistic chiral fermions, and -- despite their gaplessness -- to solid-state topological and Chern insulators. Their characteristic electronic properties lead to protected surface states and novel responses to applied electric and magnetic fields. Here we review the theoretical foundations of these phases, their proposed realizations in solid state systems, recent experiments on candidate materials, as well as their relation to other states of matter.", "concepts": ["Physics", "Theoretical physics", "Condensed matter physics", "Quantum mechanics", "Geometry", "Mathematics"], "domain": "physics"}
{"id": "https://openalex.org/W4400232689", "title": "Economic growth and income inequality", "abstract": "In recent years the problem of economic inequalities has become one of the most often discussed problems in economics. Even though from neoclassical perspective inequalities should not have negative impact on economy, still the relation between inequalities and economic growth is not obvious. Traditionally, the starting point in this discussion is Simon Kuznets concept, according to which inequality rises in the early phases of economic development and decreases as the growth takes place. The empirical verification of this concept has been investigated, but the evidence is ambiguous. In this context, re-examining Kuznets theory for socialist countries in Asian (i.e. China, Vietnam and Lao) is especially interesting because of the rapid economic growth yet still keeping authoritarian regime. Therefore the main aim of the study is to verify the relation between economic growth and income inequality in China, Lao and Vietnam in years 1990–2022 and assess whether the relation takes shape of so-called Kuznets curve. In order to achieve the goal the data analysis and basic econometric methods are used. The results generally support relations indicated by Kuznets except for Lao for which obtained result were not statistically significant. The findings keep the door open to further analyses aimed at the identification and exploration of more significant determinants that could conclusively verify the relation between inequalities and economic development. Most promising would be incorporating some institutional determinants as it was proposed in Acemoglu and Robinson works.", "concepts": ["Economics", "Development economics", "Economic system", "Econometrics", "Political science", "Geography", "Mathematics", "Mathematical analysis"], "domain": "economics"}
{"id": "https://openalex.org/W2234054032", "title": "A mixed-cation lead mixed-halide perovskite absorber for tandem solar cells", "abstract": "Metal halide perovskite photovoltaic cells could potentially boost the efficiency of commercial silicon photovoltaic modules from ∼20 toward 30% when used in tandem architectures. An optimum perovskite cell optical band gap of ~1.75 electron volts (eV) can be achieved by varying halide composition, but to date, such materials have had poor photostability and thermal stability. Here we present a highly crystalline and compositionally photostable material, [HC(NH2)2](0.83)Cs(0.17)Pb(I(0.6)Br(0.4))3, with an optical band gap of ~1.74 eV, and we fabricated perovskite cells that reached open-circuit voltages of 1.2 volts and power conversion efficiency of over 17% on small areas and 14.7% on 0.715 cm(2) cells. By combining these perovskite cells with a 19%-efficient silicon cell, we demonstrated the feasibility of achieving >25%-efficient four-terminal tandem cells.", "concepts": ["Materials science", "Chemical engineering", "Chemistry", "Inorganic chemistry", "Crystallography", "Geology", "Composite material", "Engineering"], "domain": "engineering"}
{"id": "https://openalex.org/W2901669506", "title": "Systematic review or scoping review? Guidance for authors when choosing between a systematic or scoping review approach", "abstract": "Scoping reviews are a relatively new approach to evidence synthesis and currently there exists little guidance regarding the decision to choose between a systematic review or scoping review approach when synthesising evidence. The purpose of this article is to clearly describe the differences in indications between scoping reviews and systematic reviews and to provide guidance for when a scoping review is (and is not) appropriate. Researchers may conduct scoping reviews instead of systematic reviews where the purpose of the review is to identify knowledge gaps, scope a body of literature, clarify concepts or to investigate research conduct. While useful in their own right, scoping reviews may also be helpful precursors to systematic reviews and can be used to confirm the relevance of inclusion criteria and potential questions. Scoping reviews are a useful tool in the ever increasing arsenal of evidence synthesis approaches. Although conducted for different purposes compared to systematic reviews, scoping reviews still require rigorous and transparent methods in their conduct to ensure that the results are trustworthy. Our hope is that with clear guidance available regarding whether to conduct a scoping review or a systematic review, there will be less scoping reviews being performed for inappropriate indications better served by a systematic review, and vice-versa.", "concepts": ["Management science", "Medicine", "Computer science", "Psychology", "Engineering", "Political science", "Law", "Programming language"], "domain": "biology"}
{"id": "https://openalex.org/W3004227146", "title": "Re-epithelialization and immune cell behaviour in an ex vivo human skin model", "abstract": "Abstract A large body of literature is available on wound healing in humans. Nonetheless, a standardized ex vivo wound model without disruption of the dermal compartment has not been put forward with compelling justification. Here, we present a novel wound model based on application of negative pressure and its effects for epidermal regeneration and immune cell behaviour. Importantly, the basement membrane remained intact after blister roof removal and keratinocytes were absent in the wounded area. Upon six days of culture, the wound was covered with one to three-cell thick K14 + Ki67 + keratinocyte layers, indicating that proliferation and migration were involved in wound closure. After eight to twelve days, a multi-layered epidermis was formed expressing epidermal differentiation markers (K10, filaggrin, DSG-1, CDSN). Investigations about immune cell-specific manners revealed more T cells in the blister roof epidermis compared to normal epidermis. We identified several cell populations in blister roof epidermis and suction blister fluid that are absent in normal epidermis which correlated with their decrease in the dermis, indicating a dermal efflux upon negative pressure. Together, our model recapitulates the main features of epithelial wound regeneration, and can be applied for testing wound healing therapies and investigating underlying mechanisms.", "concepts": ["Cell biology", "Biology", "Pathology", "Medicine", "Anatomy", "Immunology", "Biochemistry", "Genetics"], "domain": "environmental_science"}
{"id": "https://openalex.org/W3186179742", "title": "Accurate prediction of protein structures and interactions using a three-track neural network", "abstract": "Deep learning takes on protein folding In 1972, Anfinsen won a Nobel prize for demonstrating a connection between a protein’s amino acid sequence and its three-dimensional structure. Since 1994, scientists have competed in the biannual Critical Assessment of Structure Prediction (CASP) protein-folding challenge. Deep learning methods took center stage at CASP14, with DeepMind’s Alphafold2 achieving remarkable accuracy. Baek et al . explored network architectures based on the DeepMind framework. They used a three-track network to process sequence, distance, and coordinate information simultaneously and achieved accuracies approaching those of DeepMind. The method, RoseTTA fold, can solve challenging x-ray crystallography and cryo–electron microscopy modeling problems and generate accurate models of protein-protein complexes. —VV", "concepts": ["Computer science", "Artificial intelligence", "Computational biology", "Machine learning", "Chemistry", "Biology", "Engineering", "Biochemistry"], "domain": "chemistry"}
{"id": "https://openalex.org/W4394785938", "title": "Interactive Tree of Life (iTOL) v6: recent updates to the phylogenetic tree display and annotation tool", "abstract": "Abstract The Interactive Tree Of Life (https://itol.embl.de) is an online tool for the management, display, annotation and manipulation of phylogenetic and other trees. It is freely available and open to everyone. iTOL version 6 introduces a modernized and completely rewritten user interface, together with numerous new features. A new dataset type has been introduced (colored/labeled ranges), greatly upgrading the functionality of the previous simple colored range annotation function. Additional annotation options have been implemented for several existing dataset types. Dataset template files now support simple assignment of annotations to multiple tree nodes through substring matching, including full regular expression support. Node metadata handling has been greatly extended with novel display and exporting options, and it can now be edited interactively or bulk updated through annotation files. Tree labels can be displayed using multiple simultaneous font styles, with precise positioning, sizing and styling of each individual label part. Various bulk label editing functions have been implemented, simplifying large scale changes of all tree node labels. iTOL’s automatic taxonomy assignment functions now support trees based on the Genome Taxonomy Database (GTDB), in addition to the NCBI taxonomy. The functionality of the optional user account pages has been expanded, simplifying the management, navigation and sharing of projects and trees. iTOL currently handles more than one and a half million trees from &amp;gt;130 000 individual user accounts.", "concepts": ["Computer science", "Information retrieval", "Data mining", "Artificial intelligence", "World Wide Web", "Programming language", "Mathematics", "Mathematical analysis"], "domain": "mathematics"}
{"id": "https://openalex.org/W3189646261", "title": "An oral SARS-CoV-2 M <sup>pro</sup> inhibitor clinical candidate for the treatment of COVID-19", "abstract": "The worldwide outbreak of COVID-19 caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has become a global pandemic. Alongside vaccines, antiviral therapeutics are an important part of the healthcare response to countering the ongoing threat presented by COVID-19. Here, we report the discovery and characterization of PF-07321332, an orally bioavailable SARS-CoV-2 main protease inhibitor with in vitro pan-human coronavirus antiviral activity and excellent off-target selectivity and in vivo safety profiles. PF-07321332 has demonstrated oral activity in a mouse-adapted SARS-CoV-2 model and has achieved oral plasma concentrations exceeding the in vitro antiviral cell potency in a phase 1 clinical trial in healthy human participants.", "concepts": ["Virology", "Pharmacology", "Medicine", "Chemistry", "Biology", "Internal medicine", "Biochemistry", "Biotechnology"], "domain": "chemistry"}
{"id": "https://openalex.org/W2791453970", "title": "Heart Disease and Stroke Statistics—2018 Update: A Report From the American Heart Association", "abstract": "Each chapter listed in the Table of Contents (see next page) is a hyperlink to that chapter. The reader clicks the chapter name to access that chapter.\n\nEach chapter listed here is a hyperlink. Click on the chapter name to be taken to that chapter. \n\nEach year, the American Heart Association (AHA), in conjunction with the Centers for Disease Control and Prevention, the National Institutes of Health, and other government agencies, brings together in a single document the most up-to-date statistics related to heart disease, stroke, and the cardiovascular risk factors listed in the AHA’s My Life Check - Life’s Simple 7 (Figure1), which include core health behaviors (smoking, physical activity, diet, and weight) and health factors (cholesterol, blood pressure [BP], and glucose control) that contribute to cardiovascular health. The Statistical Update represents …", "concepts": ["Medicine", "Gerontology", "Family medicine", "Internal medicine", "World Wide Web", "Mechanical engineering", "Linguistics", "Philosophy"], "domain": "materials_science"}
{"id": "https://openalex.org/W4394857110", "title": "TRIPOD+AI statement: updated guidance for reporting clinical prediction models that use regression or machine learning methods", "abstract": "The TRIPOD (Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis) statement was published in 2015 to provide the minimum reporting recommendations for studies developing or evaluating the performance of a prediction model. Methodological advances in the field of prediction have since included the widespread use of artificial intelligence (AI) powered by machine learning methods to develop prediction models. An update to the TRIPOD statement is thus needed. TRIPOD+AI provides harmonised guidance for reporting prediction model studies, irrespective of whether regression modelling or machine learning methods have been used. The new checklist supersedes the TRIPOD 2015 checklist, which should no longer be used. This article describes the development of TRIPOD+AI and presents the expanded 27 item checklist with more detailed explanation of each reporting recommendation, and the TRIPOD+AI for Abstracts checklist. TRIPOD+AI aims to promote the complete, accurate, and transparent reporting of studies that develop a prediction model or evaluate its performance. Complete reporting will facilitate study appraisal, model evaluation, and model implementation.", "concepts": ["Machine learning", "Computer science", "Artificial intelligence", "Engineering", "Psychology", "Mechanical engineering", "Cognitive psychology"], "domain": "computer_science"}
{"id": "https://openalex.org/W4390692489", "title": "Unifying Large Language Models and Knowledge Graphs: A Roadmap", "abstract": "Large language models (LLMs), such as ChatGPT and GPT4, are making new waves in the field of natural language processing and artificial intelligence, due to their emergent ability and generalizability. However, LLMs are black-box models, which often fall short of capturing and accessing factual knowledge. In contrast, Knowledge Graphs (KGs), Wikipedia and Huapu for example, are structured knowledge models that explicitly store rich factual knowledge. KGs can enhance LLMs by providing external knowledge for inference and interpretability. Meanwhile, KGs are difficult to construct and evolve by nature, which challenges the existing methods in KGs to generate new facts and represent unseen knowledge. Therefore, it is complementary to unify LLMs and KGs together and simultaneously leverage their advantages. In this article, we present a forward-looking roadmap for the unification of LLMs and KGs. Our roadmap consists of three general frameworks, namely, <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1) KG-enhanced LLMs,</i> which incorporate KGs during the pre-training and inference phases of LLMs, or for the purpose of enhancing understanding of the knowledge learned by LLMs; <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2) LLM-augmented KGs,</i> that leverage LLMs for different KG tasks such as embedding, completion, construction, graph-to-text generation, and question answering; and <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">3) Synergized LLMs + KGs</i> , in which LLMs and KGs play equal roles and work in a mutually beneficial way to enhance both LLMs and KGs for bidirectional reasoning driven by both data and knowledge. We review and summarize existing efforts within these three frameworks in our roadmap and pinpoint their future research directions.", "concepts": ["Computer science", "Natural language processing", "Artificial intelligence", "Data science", "Theoretical computer science"], "domain": "computer_science"}
{"id": "https://openalex.org/W3005235420", "title": "IQ-TREE 2: New Models and Efficient Methods for Phylogenetic Inference in the Genomic Era", "abstract": "Abstract IQ-TREE (http://www.iqtree.org, last accessed February 6, 2020) is a user-friendly and widely used software package for phylogenetic inference using maximum likelihood. Since the release of version 1 in 2014, we have continuously expanded IQ-TREE to integrate a plethora of new models of sequence evolution and efficient computational approaches of phylogenetic inference to deal with genomic data. Here, we describe notable features of IQ-TREE version 2 and highlight the key advantages over other software.", "concepts": ["Biology", "Evolutionary biology", "Computational biology", "Computer science", "Machine learning", "Artificial intelligence", "Genetics", "Mathematics"], "domain": "environmental_science"}
{"id": "https://openalex.org/W4366783381", "title": "Artificial intelligence in higher education: the state of the field", "abstract": "Abstract This systematic review provides unique findings with an up-to-date examination of artificial intelligence (AI) in higher education (HE) from 2016 to 2022. Using PRISMA principles and protocol, 138 articles were identified for a full examination. Using a priori, and grounded coding, the data from the 138 articles were extracted, analyzed, and coded. The findings of this study show that in 2021 and 2022, publications rose nearly two to three times the number of previous years. With this rapid rise in the number of AIEd HE publications, new trends have emerged. The findings show that research was conducted in six of the seven continents of the world. The trend has shifted from the US to China leading in the number of publications. Another new trend is in the researcher affiliation as prior studies showed a lack of researchers from departments of education. This has now changed to be the most dominant department. Undergraduate students were the most studied students at 72%. Similar to the findings of other studies, language learning was the most common subject domain. This included writing, reading, and vocabulary acquisition. In examination of who the AIEd was intended for 72% of the studies focused on students, 17% instructors, and 11% managers. In answering the overarching question of how AIEd was used in HE, grounded coding was used. Five usage codes emerged from the data: (1) Assessment/Evaluation, (2) Predicting, (3) AI Assistant, (4) Intelligent Tutoring System (ITS), and (5) Managing Student Learning. This systematic review revealed gaps in the literature to be used as a springboard for future researchers, including new tools, such as Chat GPT.", "concepts": ["Mathematics education", "Psychology", "Computer science", "Artificial intelligence", "Library science", "Social science", "Linguistics", "Sociology"], "domain": "psychology"}
{"id": "https://openalex.org/W4205483821", "title": "Efficacy and Safety of the mRNA-1273 SARS-CoV-2 Vaccine", "abstract": "Vaccines are needed to prevent coronavirus disease 2019 (Covid-19) and to protect persons who are at high risk for complications. The mRNA-1273 vaccine is a lipid nanoparticle-encapsulated mRNA-based vaccine that encodes the prefusion stabilized full-length spike protein of the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), the virus that causes Covid-19.This phase 3 randomized, observer-blinded, placebo-controlled trial was conducted at 99 centers across the United States. Persons at high risk for SARS-CoV-2 infection or its complications were randomly assigned in a 1:1 ratio to receive two intramuscular injections of mRNA-1273 (100 μg) or placebo 28 days apart. The primary end point was prevention of Covid-19 illness with onset at least 14 days after the second injection in participants who had not previously been infected with SARS-CoV-2.The trial enrolled 30,420 volunteers who were randomly assigned in a 1:1 ratio to receive either vaccine or placebo (15,210 participants in each group). More than 96% of participants received both injections, and 2.2% had evidence (serologic, virologic, or both) of SARS-CoV-2 infection at baseline. Symptomatic Covid-19 illness was confirmed in 185 participants in the placebo group (56.5 per 1000 person-years; 95% confidence interval [CI], 48.7 to 65.3) and in 11 participants in the mRNA-1273 group (3.3 per 1000 person-years; 95% CI, 1.7 to 6.0); vaccine efficacy was 94.1% (95% CI, 89.3 to 96.8%; P<0.001). Efficacy was similar across key secondary analyses, including assessment 14 days after the first dose, analyses that included participants who had evidence of SARS-CoV-2 infection at baseline, and analyses in participants 65 years of age or older. Severe Covid-19 occurred in 30 participants, with one fatality; all 30 were in the placebo group. Moderate, transient reactogenicity after vaccination occurred more frequently in the mRNA-1273 group. Serious adverse events were rare, and the incidence was similar in the two groups.The mRNA-1273 vaccine showed 94.1% efficacy at preventing Covid-19 illness, including severe disease. Aside from transient local and systemic reactions, no safety concerns were identified. (Funded by the Biomedical Advanced Research and Development Authority and the National Institute of Allergy and Infectious Diseases; COVE ClinicalTrials.gov number, NCT04470427.).", "concepts": ["Virology", "Medicine", "Biology", "Internal medicine", "Genetics"], "domain": "environmental_science"}
{"id": "https://openalex.org/W4394728226", "title": "Improved charge extraction in inverted perovskite solar cells with dual-site-binding ligands", "abstract": "Inverted (pin) perovskite solar cells (PSCs) afford improved operating stability in comparison to their nip counterparts but have lagged in power conversion efficiency (PCE). The energetic losses responsible for this PCE deficit in pin PSCs occur primarily at the interfaces between the perovskite and the charge-transport layers. Additive and surface treatments that use passivating ligands usually bind to a single active binding site: This dense packing of electrically resistive passivants perpendicular to the surface may limit the fill factor in pin PSCs. We identified ligands that bind two neighboring lead(II) ion (Pb", "concepts": ["Materials science", "Optoelectronics", "Chemistry", "Crystallography", "Biochemistry", "Electrical engineering", "Engineering"], "domain": "chemistry"}
{"id": "https://openalex.org/W2150959326", "title": "2019 ESC Guidelines on diabetes, pre-diabetes, and cardiovascular diseases developed in collaboration with the EASD", "abstract": "The Guidelines represent the views of the ESC and were produced after careful consideration of the scientific and medical knowledge, and the evidence available at the time of their publication.The ESC and EASD are not responsible in the event of any contradiction, discrepancy, and/or ambiguity between the Guidelines and any other official recommendations or guidelines issued by the relevant public health authorities, in particular in relation to good use of healthcare or therapeutic strategies.Health professionals are encouraged to take the Guidelines fully into account when exercising their clinical judgment, as well as in the determination and the implementation of preventive, diagnostic, or therapeutic medical strategies; however, the Guidelines do not override, in any way whatsoever, the individual responsibility of health professionals to make appropriate and accurate decisions in consideration of each patient's health condition and in consultation with that patient and, where appropriate and/or necessary, the patient's caregiver.Nor do the Guidelines exempt health professionals from taking into full and careful consideration the relevant official updated recommendations or guidelines issued by the competent public health authorities, in order to manage each patient's case in light of the scientifically accepted data pursuant to their respective ethical and professional obligations.It is also the health professional's responsibility to verify the applicable rules and regulations relating to drugs and medical devices at the time of prescription.", "concepts": ["Medicine", "Public relations", "Family medicine", "Medical education", "Nursing", "Law", "Linguistics", "Philosophy"], "domain": "medicine"}
{"id": "https://openalex.org/W2768753204", "title": "A New Convolutional Neural Network-Based Data-Driven Fault Diagnosis Method", "abstract": "Fault diagnosis is vital in manufacturing system, since early detections on the emerging problem can save invaluable time and cost. With the development of smart manufacturing, the data-driven fault diagnosis becomes a hot topic. However, the traditional data-driven fault diagnosis methods rely on the features extracted by experts. The feature extraction process is an exhausted work and greatly impacts the final result. Deep learning (DL) provides an effective way to extract the features of raw data automatically. Convolutional neural network (CNN) is an effective DL method. In this study, a new CNN based on LeNet-5 is proposed for fault diagnosis. Through a conversion method converting signals into two-dimensional (2-D) images, the proposed method can extract the features of the converted 2-D images and eliminate the effect of handcrafted features. The proposed method which is tested on three famous datasets, including motor bearing dataset, self-priming centrifugal pump dataset, and axial piston hydraulic pump dataset, has achieved prediction accuracy of 99.79%, 99.481%, and 100%, respectively. The results have been compared with other DL and traditional methods, including adaptive deep CNN, sparse filter, deep belief network, and support vector machine. The comparisons show that the proposed CNN-based data-driven fault diagnosis method has achieved significant improvements.", "concepts": ["Computer science", "Artificial intelligence", "Data mining", "Machine learning", "Computer vision", "Seismology", "Geology", "Operating system"], "domain": "engineering"}
{"id": "https://openalex.org/W4392051461", "title": "Computational Linguistics", "abstract": "Linguistics is concerned with rules that are followed by languages as a system. Computational linguistics(CL)combines the power of machine learning and human language.As a subfield of linguistics, CL is concerned with the computational description of rules that languages follow. Itis what powers anything in a machine or device that has to do with language—speaking, writing, reading, and listening. It is often linked with natural language processing (NLP), which is the use of computers to identify structures in natural language.The boundary between NLP and CL is not so clear-cut. This paper is a primer on computational linguistics", "concepts": ["Linguistics", "Computer science", "Philosophy"], "domain": "computer_science"}
{"id": "https://openalex.org/W4384071683", "title": "Large language models encode clinical knowledge", "abstract": "Abstract Large language models (LLMs) have demonstrated impressive capabilities, but the bar for clinical applications is high. Attempts to assess the clinical knowledge of models typically rely on automated evaluations based on limited benchmarks. Here, to address these limitations, we present MultiMedQA, a benchmark combining six existing medical question answering datasets spanning professional medicine, research and consumer queries and a new dataset of medical questions searched online, HealthSearchQA. We propose a human evaluation framework for model answers along multiple axes including factuality, comprehension, reasoning, possible harm and bias. In addition, we evaluate Pathways Language Model 1 (PaLM, a 540-billion parameter LLM) and its instruction-tuned variant, Flan-PaLM 2 on MultiMedQA. Using a combination of prompting strategies, Flan-PaLM achieves state-of-the-art accuracy on every MultiMedQA multiple-choice dataset (MedQA 3 , MedMCQA 4 , PubMedQA 5 and Measuring Massive Multitask Language Understanding (MMLU) clinical topics 6 ), including 67.6% accuracy on MedQA (US Medical Licensing Exam-style questions), surpassing the prior state of the art by more than 17%. However, human evaluation reveals key gaps. To resolve this, we introduce instruction prompt tuning, a parameter-efficient approach for aligning LLMs to new domains using a few exemplars. The resulting model, Med-PaLM, performs encouragingly, but remains inferior to clinicians. We show that comprehension, knowledge recall and reasoning improve with model scale and instruction prompt tuning, suggesting the potential utility of LLMs in medicine. Our human evaluations reveal limitations of today’s models, reinforcing the importance of both evaluation frameworks and method development in creating safe, helpful LLMs for clinical applications.", "concepts": ["Computer science", "Artificial intelligence", "Data science", "Machine learning", "Natural language processing", "Medicine", "Psychology", "Computer security"], "domain": "psychology"}
{"id": "https://openalex.org/W4392773210", "title": "Embracing the future of Artificial Intelligence in the classroom: the relevance of AI literacy, prompt engineering, and critical thinking in modern education", "abstract": "Abstract The present discussion examines the transformative impact of Artificial Intelligence (AI) in educational settings, focusing on the necessity for AI literacy, prompt engineering proficiency, and enhanced critical thinking skills. The introduction of AI into education marks a significant departure from conventional teaching methods, offering personalized learning and support for diverse educational requirements, including students with special needs. However, this integration presents challenges, including the need for comprehensive educator training and curriculum adaptation to align with societal structures. AI literacy is identified as crucial, encompassing an understanding of AI technologies and their broader societal impacts. Prompt engineering is highlighted as a key skill for eliciting specific responses from AI systems, thereby enriching educational experiences and promoting critical thinking. There is detailed analysis of strategies for embedding these skills within educational curricula and pedagogical practices. This is discussed through a case-study based on a Swiss university and a narrative literature review, followed by practical suggestions of how to implement AI in the classroom.", "concepts": ["Mathematics education", "Engineering ethics", "Psychology", "Pedagogy", "Engineering", "Political science", "Law"], "domain": "computer_science"}
{"id": "https://openalex.org/W4391006361", "title": "A meta systematic review of artificial intelligence in higher education: a call for increased ethics, collaboration, and rigour", "abstract": "Abstract Although the field of Artificial Intelligence in Education (AIEd) has a substantial history as a research domain, never before has the rapid evolution of AI applications in education sparked such prominent public discourse. Given the already rapidly growing AIEd literature base in higher education, now is the time to ensure that the field has a solid research and conceptual grounding. This review of reviews is the first comprehensive meta review to explore the scope and nature of AIEd in higher education (AIHEd) research, by synthesising secondary research (e.g., systematic reviews), indexed in the Web of Science, Scopus, ERIC, EBSCOHost, IEEE Xplore, ScienceDirect and ACM Digital Library, or captured through snowballing in OpenAlex, ResearchGate and Google Scholar. Reviews were included if they synthesised applications of AI solely in formal higher or continuing education, were published in English between 2018 and July 2023, were journal articles or full conference papers, and if they had a method section 66 publications were included for data extraction and synthesis in EPPI Reviewer, which were predominantly systematic reviews (66.7%), published by authors from North America (27.3%), conducted in teams (89.4%) in mostly domestic-only collaborations (71.2%). Findings show that these reviews mostly focused on AIHEd generally (47.0%) or Profiling and Prediction (28.8%) as thematic foci, however key findings indicated a predominance of the use of Adaptive Systems and Personalisation in higher education. Research gaps identified suggest a need for greater ethical, methodological, and contextual considerations within future research, alongside interdisciplinary approaches to AIHEd application. Suggestions are provided to guide future primary and secondary research.", "concepts": ["Library science", "Sociology", "Social science", "Computer science", "Political science", "Art", "Geometry", "Mathematics"], "domain": "computer_science"}
{"id": "https://openalex.org/W2883251903", "title": "ape 5.0: an environment for modern phylogenetics and evolutionary analyses in R", "abstract": "After more than fifteen years of existence, the R package ape has continuously grown its contents, and has been used by a growing community of users. The release of version 5.0 has marked a leap towards a modern software for evolutionary analyses. Efforts have been put to improve efficiency, flexibility, support for 'big data' (R's long vectors), ease of use and quality check before a new release. These changes will hopefully make ape a useful software for the study of biodiversity and evolution in a context of increasing data quantity.ape is distributed through the Comprehensive R Archive Network: http://cran.r-project.org/package=ape. Further information may be found at http://ape-package.ird.fr/.", "concepts": ["Computer science", "Data science", "Biology", "Data mining", "Programming language", "Mathematics", "Statistics", "Paleontology"], "domain": "materials_science"}
{"id": "https://openalex.org/W2533800772", "title": "Deep Learning in Medical Image Analysis", "abstract": "This review covers computer-assisted analysis of images in the field of medical imaging. Recent advances in machine learning, especially with regard to deep learning, are helping to identify, classify, and quantify patterns in medical images. At the core of these advances is the ability to exploit hierarchical feature representations learned solely from data, instead of features designed by hand according to domain-specific knowledge. Deep learning is rapidly becoming the state of the art, leading to enhanced performance in various medical applications. We introduce the fundamentals of deep learning methods and review their successes in image registration, detection of anatomical and cellular structures, tissue segmentation, computer-aided disease diagnosis and prognosis, and so on. We conclude by discussing research issues and suggesting future directions for further improvement.", "concepts": ["Artificial intelligence", "Computer science", "Machine learning", "Mathematical analysis", "Linguistics", "Philosophy", "Computer security", "Mathematics"], "domain": "materials_science"}
{"id": "https://openalex.org/W2786358356", "title": "glmmTMB Balances Speed and Flexibility Among Packages for Zero-inflated Generalized Linear Mixed Modeling", "abstract": "Count data can be analyzed using generalized linear mixed models when observations are correlated in ways that require random effects. However, count data are often zero-inflated, containing more zeros than would be expected from the typical error distributions. We present a new package, glmmTMB, and compare it to other R packages that fit zero-inflated mixed models. The glmmTMB package fits many types of GLMMs and extensions, including models with continuously distributed responses, but here we focus on count responses. glmmTMB is faster than glmmADMB, MCMCglmm, and brms, and more flexible than INLA and mgcv for zero-inflated modeling. One unique feature of glmmTMB (among packages that fit zero-inflated mixed models) is its ability to estimate the Conway-Maxwell-Poisson distribution parameterized by the mean. Overall, its most appealing features for new users may be the combination of speed, flexibility, and its interface's similarity to lme4.", "concepts": ["Mathematics", "Applied mathematics", "Statistics", "Computer science", "Philosophy", "Linguistics"], "domain": "materials_science"}
{"id": "https://openalex.org/W3130661498", "title": "Heavy Metals and Pesticides Toxicity in Agricultural Soil and Plants: Ecological Risks and Human Health Implications", "abstract": "Environmental problems have always received immense attention from scientists. Toxicants pollution is a critical environmental concern that has posed serious threats to human health and agricultural production. Heavy metals and pesticides are top of the list of environmental toxicants endangering nature. This review focuses on the toxic effect of heavy metals (cadmium (Cd), lead (Pb), copper (Cu), and zinc (Zn)) and pesticides (insecticides, herbicides, and fungicides) adversely influencing the agricultural ecosystem (plant and soil) and human health. Furthermore, heavy metals accumulation and pesticide residues in soils and plants have been discussed in detail. In addition, the characteristics of contaminated soil and plant physiological parameters have been reviewed. Moreover, human diseases caused by exposure to heavy metals and pesticides were also reported. The bioaccumulation, mechanism of action, and transmission pathways of both heavy metals and pesticides are emphasized. In addition, the bioavailability in soil and plant uptake of these contaminants has also been considered. Meanwhile, the synergistic and antagonistic interactions between heavy metals and pesticides and their combined toxic effects have been discussed. Previous relevant studies are included to cover all aspects of this review. The information in this review provides deep insights into the understanding of environmental toxicants and their hazardous effects.", "concepts": ["Environmental chemistry", "Environmental science", "Environmental protection", "Chemistry", "Ecology", "Biology", "Environmental health", "Medicine"], "domain": "chemistry"}
{"id": "https://openalex.org/W2793350103", "title": "Correlation Coefficients: Appropriate Use and Interpretation", "abstract": "Correlation in the broadest sense is a measure of an association between variables. In correlated data, the change in the magnitude of 1 variable is associated with a change in the magnitude of another variable, either in the same (positive correlation) or in the opposite (negative correlation) direction. Most often, the term correlation is used in the context of a linear relationship between 2 continuous variables and expressed as Pearson product-moment correlation. The Pearson correlation coefficient is typically used for jointly normally distributed data (data that follow a bivariate normal distribution). For nonnormally distributed continuous data, for ordinal data, or for data with relevant outliers, a Spearman rank correlation can be used as a measure of a monotonic association. Both correlation coefficients are scaled such that they range from –1 to +1, where 0 indicates that there is no linear or monotonic association, and the relationship gets stronger and ultimately approaches a straight line (Pearson correlation) or a constantly increasing or decreasing curve (Spearman correlation) as the coefficient approaches an absolute value of 1. Hypothesis tests and confidence intervals can be used to address the statistical significance of the results and to estimate the strength of the relationship in the population from which the data were sampled. The aim of this tutorial is to guide researchers and clinicians in the appropriate use and interpretation of correlation coefficients.", "concepts": ["Statistics", "Mathematics", "Geometry"], "domain": "mathematics"}
{"id": "https://openalex.org/W4317910584", "title": "ChatGPT: Bullshit spewer or the end of traditional assessments in higher education?", "abstract": "ChatGPT is the world’s most advanced chatbot thus far. Unlike other chatbots, it can create impressive prose within seconds, and it has created much hype and doomsday predictions when it comes to student assessment in higher education and a host of other matters. ChatGPT is a state-of-the-art language model (a variant of OpenAI’s Generative Pretrained Transformer (GPT) language model) designed to generate text that can be indistinguishable from text written by humans. It can engage in conversation with users in a seemingly natural and intuitive way. In this article, we briefly tell the story of OpenAI, the organisation behind ChatGPT. We highlight the fundamental change from a not-for-profit organisation to a commercial business model. In terms of our methods, we conducted an extensive literature review and experimented with this artificial intelligence (AI) software. Our literature review shows our review to be amongst the first peer-reviewed academic journal articles to explore ChatGPT and its relevance for higher education (especially assessment, learning and teaching). After a description of ChatGPT’s functionality and a summary of its strengths and limitations, we focus on the technology’s implications for higher education and discuss what is the future of learning, teaching and assessment in higher education in the context of AI chatbots such as ChatGPT. We position ChatGPT in the context of current Artificial Intelligence in Education (AIEd) research, discuss student-facing, teacher-facing and system-facing applications, and analyse opportunities and threats. We conclude the article with recommendations for students, teachers and higher education institutions. Many of them focus on assessment.", "concepts": ["Computer science", "Engineering ethics", "Artificial intelligence", "Pedagogy", "Psychology", "Engineering", "Political science", "Paleontology"], "domain": "psychology"}
{"id": "https://openalex.org/W2767767460", "title": "Properties and potential optoelectronic applications of lead halide perovskite nanocrystals", "abstract": "Semiconducting lead halide perovskites (LHPs) have not only become prominent thin-film absorber materials in photovoltaics but have also proven to be disruptive in the field of colloidal semiconductor nanocrystals (NCs). The most important feature of LHP NCs is their so-called defect-tolerance-the apparently benign nature of structural defects, highly abundant in these compounds, with respect to optical and electronic properties. Here, we review the important differences that exist in the chemistry and physics of LHP NCs as compared with more conventional, tetrahedrally bonded, elemental, and binary semiconductor NCs (such as silicon, germanium, cadmium selenide, gallium arsenide, and indium phosphide). We survey the prospects of LHP NCs for optoelectronic applications such as in television displays, light-emitting devices, and solar cells, emphasizing the practical hurdles that remain to be overcome.", "concepts": ["Optoelectronics", "Materials science", "Nanotechnology", "Chemistry", "Inorganic chemistry", "Crystallography", "Geology", "Geomorphology"], "domain": "engineering"}
{"id": "https://openalex.org/W3196836501", "title": "Revisiting Event-Study Designs: Robust and Efficient Estimation", "abstract": "Abstract We develop a framework for difference-in-differences designs with staggered treatment adoption and heterogeneous causal effects. We show that conventional regression-based estimators fail to provide unbiased estimates of relevant estimands absent strong restrictions on treatment-effect homogeneity. We then derive the efficient estimator addressing this challenge, which takes an intuitive “imputation” form when treatment-effect heterogeneity is unrestricted. We characterize the asymptotic behaviour of the estimator, propose tools for inference, and develop tests for identifying assumptions. Our method applies with time-varying controls, in triple-difference designs, and with certain non-binary treatments. We show the practical relevance of our results in a simulation study and an application. Studying the consumption response to tax rebates in the U.S., we find that the notional marginal propensity to consume is between 8 and 11% in the first quarter—about half as large as benchmark estimates used to calibrate macroeconomic models—and predominantly occurs in the first month after the rebate.", "concepts": ["Econometrics", "Economics", "Computer science", "Statistics", "Mathematics", "Artificial intelligence", "Geodesy", "Finance"], "domain": "economics"}
{"id": "https://openalex.org/W4360620450", "title": "Opinion Paper: “So what if ChatGPT wrote it?” Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy", "abstract": "Transformative artificially intelligent tools, such as ChatGPT, designed to generate sophisticated text indistinguishable from that produced by a human, are applicable across a wide range of contexts. The technology presents opportunities as well as, often ethical and legal, challenges, and has the potential for both positive and negative impacts for organisations, society, and individuals. Offering multi-disciplinary insight into some of these, this article brings together 43 contributions from experts in fields such as computer science, marketing, information systems, education, policy, hospitality and tourism, management, publishing, and nursing. The contributors acknowledge ChatGPT's capabilities to enhance productivity and suggest that it is likely to offer significant gains in the banking, hospitality and tourism, and information technology industries, and enhance business activities, such as management and marketing. Nevertheless, they also consider its limitations, disruptions to practices, threats to privacy and security, and consequences of biases, misuse, and misinformation. However, opinion is split on whether ChatGPT's use should be restricted or legislated. Drawing on these contributions, the article identifies questions requiring further research across three thematic areas: knowledge, transparency, and ethics; digital transformation of organisations and societies; and teaching, learning, and scholarly research. The avenues for further research include: identifying skills, resources, and capabilities needed to handle generative AI; examining biases of generative AI attributable to training datasets and processes; exploring business and societal contexts best suited for generative AI implementation; determining optimal combinations of human and generative AI for various tasks; identifying ways to assess accuracy of text produced by generative AI; and uncovering the ethical and legal issues in using generative AI across different contexts.", "concepts": ["Knowledge management", "Engineering ethics", "Sociology", "Public relations", "Political science", "Computer science", "Engineering", "Artificial intelligence"], "domain": "biology"}
{"id": "https://openalex.org/W3105353888", "title": "Binary Companions of Evolved Stars in APOGEE DR14: Search Method and Catalog of ∼5000 Companions", "abstract": "Abstract Multi-epoch radial velocity measurements of stars can be used to identify stellar, substellar, and planetary-mass companions. Even a small number of observation epochs can be informative about companions, though there can be multiple qualitatively different orbital solutions that fit the data. We have custom-built a Monte Carlo sampler ( The Joker ) that delivers reliable (and often highly multimodal) posterior samplings for companion orbital parameters given sparse radial velocity data. Here we use The Joker to perform a search for companions to 96,231 red giant stars observed in the APOGEE survey (DR14) with ≥3 spectroscopic epochs. We select stars with probable companions by making a cut on our posterior belief about the amplitude of the variation in stellar radial velocity induced by the orbit. We provide (1) a catalog of 320 companions for which the stellar companion’s properties can be confidently determined, (2) a catalog of 4898 stars that likely have companions, but would require more observations to uniquely determine the orbital properties, and (3) posterior samplings for the full orbital parameters for all stars in the parent sample. We show the characteristics of systems with confidently determined companion properties and highlight interesting systems with candidate compact object companions.", "concepts": ["Physics", "Astrophysics", "Astronomy", "Mathematics", "Arithmetic", "Engineering", "Aerospace engineering"], "domain": "physics"}
{"id": "https://openalex.org/W4211246989", "title": "International Journal of Molecular Sciences", "abstract": "Osteoclasts are large, multinucleated cells that are responsible for the resorption of bone.Bone degenerative diseases, such as osteoporosis, are characterized by overactive osteoclasts.Receptor activator of nuclear factor-κB (NF-κB) ligand (RANKL) binding to its receptor on osteoclast precursors will trigger osteoclast formation and resorption.The production of reactive oxygen species (ROS) is known to play a crucial role in RANKL-induced osteoclast formation and resorption.G-protein coupled receptor 120 (GPR120) signalling has been shown to affect osteoclast formation, but the exact mechanisms of action require further investigation.RAW264.7 murine macrophages were seeded into culture plates and exposed to the GPR120 agonist, TUG-891, at varying concentrations (20-100 µM) and RANKL to induce osteoclast formation.TUG-891 was shown to inhibit osteoclast formation and resorption without affecting cell viability in RAW264.7 macrophages.TUG-891 further decreased ROS production when compared to RANKL only cells.Antioxidant proteins, Nrf2, HO-1 and NQO1 were shown to be upregulated while the ROS inducing protein, Nox1, was downregulated by TUG-891.Gene silencing revealed that TUG-891 exerted its effects specifically through GPR120.This study reveals that GPR120 signalling may inhibit osteoclast formation and resorption through inhibition on ROS production.", "concepts": ["Chemistry", "Cell biology", "Internal medicine", "Endocrinology", "Biochemistry", "Biology", "Medicine"], "domain": "chemistry"}
{"id": "https://openalex.org/W4220685687", "title": "European Association of Urology Guidelines on Renal Cell Carcinoma: The 2022 Update", "abstract": "The European Association of Urology (EAU) Renal Cell Carcinoma (RCC) Guideline Panel has prepared evidence-based guidelines and recommendations for the management of RCC. To present a summary of the 2022 RCC guideline, which is based on a standardised methodology including systematic reviews (SRs) and provides transparent and reliable evidence for the management of RCC. For the 2022 update, a new literature search was carried out with a cutoff date of May 28, 2021, covering the Medline, EMBASE, and Cochrane databases. The data search focused on randomised controlled trials (RCTs) and retrospective or controlled comparator-arm studies, SRs, and meta-analyses. Evidence synthesis was conducted using modified GRADE criteria as outlined for all the EAU guidelines. All chapters of the RCC guideline were updated on the basis of a structured literature assessment, and clinical practice recommendations were developed. The majority of the studies included were retrospective with matched or unmatched cohorts and were based on single- or multi-institution data or national registries. The exception was systemic treatment of metastatic RCC, for which there are several large RCTs, resulting in recommendations that are based on higher levels of evidence. The 2022 RCC guidelines have been updated by a multidisciplinary panel of experts using the highest methodological standards. These guidelines provide the most reliable contemporary evidence base for the management of RCC in 2022. The European Association of Urology panel for guidelines on kidney cancer has thoroughly evaluated the research data available to establish up-to-date international standards for the care of patients with kidney cancer.", "concepts": ["Medicine", "Internal medicine", "Family medicine", "Pathology", "Political science", "Law"], "domain": "social_sciences"}
{"id": "https://openalex.org/W3143063265", "title": "Sensitive protein alignments at tree-of-life scale using DIAMOND", "abstract": "Abstract We are at the beginning of a genomic revolution in which all known species are planned to be sequenced. Accessing such data for comparative analyses is crucial in this new age of data-driven biology. Here, we introduce an improved version of DIAMOND that greatly exceeds previous search performances and harnesses supercomputing to perform tree-of-life scale protein alignments in hours, while matching the sensitivity of the gold standard BLASTP.", "concepts": ["Computer science", "Computational biology", "Biology", "Data mining", "Genetics", "Mathematics", "Chemistry", "Statistics"], "domain": "chemistry"}
{"id": "https://openalex.org/W3005212621", "title": "Remdesivir and chloroquine effectively inhibit the recently emerged novel coronavirus (2019-nCoV) in vitro", "abstract": "In December 2019, a novel pneumonia caused by a previously unknown pathogen emerged in Wuhan, a city of 11 million people in central China.The initial cases were linked to exposures in a seafood market in Wuhan. 1 As of January 27, 2020, the Chinese authorities reported 2835 confirmed cases in mainland China, including 81 deaths.Additionally, 19 confirmed cases were identified in Hong Kong, Macao and Taiwan, and 39 imported cases were identified in Thailand, Japan, South Korea, United States, Vietnam, Singapore, Nepal, France, Australia and Canada.The pathogen was soon identified as a novel coronavirus (2019-nCoV), which is closely related to sever acute respiratory syndrome CoV (SARS-CoV). 2 Currently, there is no specific treatment against the new virus.Therefore, identifying effective antiviral agents to combat the disease is urgently needed.An efficient approach to drug discovery is to test whether the existing antiviral drugs are effective in treating related viral infections.The 2019-nCoV belongs to Betacoronavirus which also contains SARS-CoV and Middle East respiratory syndrome CoV (MERS-CoV).Several drugs, such as ribavirin, interferon, lopinavir-ritonavir, corticosteroids, have been used in patients with SARS or MERS, although the efficacy of some drugs remains controversial. 3In this study, we evaluated the antiviral efficiency of five FAD-approved drugs including ribavirin, penciclovir, nitazoxanide, nafamostat, chloroquine and two well-known broad-spectrum antiviral drugs remdesivir (GS-5734) and favipiravir (T-705) against a clinical isolate of 2019-nCoV in vitro.Standard assays were carried out to measure the effects of these compounds on the cytotoxicity, virus yield and infection rates of 2019-nCoVs.Firstly, the cytotoxicity of the candidate compounds in Vero E6 cells (ATCC-1586) was determined by the CCK8 assay.Then, Vero E6 cells were infected with nCoV-2019BetaCoV/Wuhan/WIV04/2019 2 at a multiplicity of infection (MOI) of 0.05 in the presence of varying concentrations of the test drugs.DMSO was used in the controls.Efficacies were evaluated by quantification of viral copy numbers in the cell supernatant via quantitative real-time RT-PCR (qRT-PCR) and confirmed with visualization of virus nucleoprotein (NP) expression through immunofluorescence microscopy at 48 h post infection (p.i.) (cytopathic effect was not obvious at this time point of infection).Among the seven tested drugs, high concentrations of three nucleoside analogs including ribavirin (half-maximal effective concentration (EC 50 ) = 109.50μM, halfcytotoxic concentration (CC 50 ) > 400 μM, selectivity index (SI) > 3.65), penciclovir (EC 50 = 95.96μM, CC 50 > 400 μM, SI > 4.17) and favipiravir (EC 50 = 61.88μM, CC 50 > 400 μM, SI > 6.46) were required to reduce the viral infection (Fig. 1a and Supplementary information, Fig. S1).However, favipiravir has been shown", "concepts": ["Virology", "Biology", "Medicine", "Immunology", "Internal medicine"], "domain": "environmental_science"}
{"id": "https://openalex.org/W3005104290", "title": "The biology <b>,</b> function <b>,</b> and biomedical applications of exosomes", "abstract": "Clinical uses of cellular communication Exosomes are a type of extracellular vesicle that contain constituents (protein, DNA, and RNA) of the cells that secrete them. They are taken up by distant cells, where they can affect cell function and behavior. Intercellular communication through exosomes seems to be involved in the pathogenesis of various disorders, including cancer, neurodegeneration, and inflammatory diseases. In a Review, Kalluri and LeBleu discuss the biogenesis and function of exosomes in disease, highlighting areas where more research is needed. They also discuss the potential clinical applications of exosome profiling for diagnostics and exosome-mediated delivery of therapeutics to target disease cells. Science , this issue p. eaau6977", "concepts": ["Biology", "Computational biology", "Cell biology", "Genetics"], "domain": "environmental_science"}
{"id": "https://openalex.org/W3159296886", "title": "Hydrogen energy systems: A critical review of technologies, applications, trends and challenges", "abstract": "The global energy transition towards a carbon neutral society requires a profound transformation of electricity generation and consumption, as well as of electric power systems. Hydrogen has an important potential to accelerate the process of scaling up clean and renewable energy, however its integration in power systems remains little studied. This paper reviews the current progress and outlook of hydrogen technologies and their application in power systems for hydrogen production, re-electrification and storage. The characteristics of electrolysers and fuel cells are demonstrated with experimental data and the deployments of hydrogen for energy storage, power-to-gas, co- and tri-generation and transportation are investigated using examples from worldwide projects. The current techno-economic status of these technologies and applications is presented, in which cost, efficiency and durability are identified as the main critical aspects. This is also confirmed by the results of a statistical analysis of the literature. Finally, conclusions show that continuous efforts on performance improvements, scale ramp-up, technical prospects and political support are required to enable a cost-competitive hydrogen economy.", "concepts": ["Process engineering", "Computer science", "Environmental science", "Engineering", "Electrical engineering", "Chemistry", "Physical chemistry", "Operating system"], "domain": "chemistry"}
{"id": "https://openalex.org/W3011371150", "title": "2019 ESC Guidelines for the diagnosis and management of chronic coronary syndromes", "abstract": "Coronary artery disease (CAD) is a pathological process characterized by atherosclerotic plaque accumulation in the epicardial arteries, whether obstructive or non-obstructive. This process can be modified by lifestyle adjustments, pharmacological therapies, and invasive interventions designed to achieve disease stabilization or regression. The disease can have long, stable periods but can also become unstable at any time, typically due to an acute atherothrombotic event caused by plaque rupture or erosion. However, the disease is chronic, most often progressive, and hence serious, even in clinically apparently silent periods. The dynamic nature of the CAD process results in various clinical presentations, which can be conveniently categorized as either acute coronary syndromes (ACS) or chronic coronary syndromes (CCS). The Guidelines presented here refer to the management of patients with CCS. The natural history of CCS is illustrated in Figure 1.", "concepts": ["Medicine", "Intensive care medicine", "Cardiology", "Internal medicine"], "domain": "medicine"}
{"id": "https://openalex.org/W4391994727", "title": "Plant-Derived Natural Products: A Source for Drug Discovery and Development", "abstract": "For thousands of years, nature has been a source of medical substances, and an astounding numeral of contemporary remedies have been identified from natural origins. Plants have long been used as folk herbal medicines to treat various disorders, and their different natural products have inspired the design, discovery, and development of new drugs. With the invention of recent molecular targets based on proteins, there is a growing need for fresh chemical diversification in screening. Natural products will play a vital part in supplying this need via the continuous exploration of global biodiversity, the majority of which remains unexplored. Even though drug discovery from medicinal plants remains an important source of novel therapeutic leads, various hurdles exist, including identifying and executing suitable high-throughput screening bioassays, scaling up the supply of bioactive molecules, and acquiring plant materials. Investigating these natural resources takes multi-disciplinary, nationwide, and global partnerships in design, synthesis, discovery, and drug development techniques. This review article discusses current advancements and future approaches for discovering natural items such as health- and wellness-promoting remedies. It also summarizes strategies to unify the therapeutic use of plant-derived natural products worldwide to support future drug discoveries derived from plant sources.", "concepts": ["Biology", "Pharmacology", "Geography", "Bioinformatics", "Archaeology"], "domain": "computer_science"}
{"id": "https://openalex.org/W3001195213", "title": "Detection of 2019 novel coronavirus (2019-nCoV) by real-time RT-PCR", "abstract": "Background The ongoing outbreak of the recently emerged novel coronavirus (2019-nCoV) poses a challenge for public health laboratories as virus isolates are unavailable while there is growing evidence that the outbreak is more widespread than initially thought, and international spread through travellers does already occur. Aim We aimed to develop and deploy robust diagnostic methodology for use in public health laboratory settings without having virus material available. Methods Here we present a validated diagnostic workflow for 2019-nCoV, its design relying on close genetic relatedness of 2019-nCoV with SARS coronavirus, making use of synthetic nucleic acid technology. Results The workflow reliably detects 2019-nCoV, and further discriminates 2019-nCoV from SARS-CoV. Through coordination between academic and public laboratories, we confirmed assay exclusivity based on 297 original clinical specimens containing a full spectrum of human respiratory viruses. Control material is made available through European Virus Archive – Global (EVAg), a European Union infrastructure project. Conclusion The present study demonstrates the enormous response capacity achieved through coordination of academic and public laboratories in national and European research networks.", "concepts": ["Virology", "Biology", "Medicine", "Computer science", "Business", "Pathology", "Database", "Economic policy"], "domain": "environmental_science"}
{"id": "https://openalex.org/W3107527779", "title": "The STRING database in 2021: customizable protein–protein networks, and functional characterization of user-uploaded gene/measurement sets", "abstract": "Cellular life depends on a complex web of functional associations between biomolecules. Among these associations, protein–protein interactions are particularly important due to their versatility, specificity and adaptability. The STRING database aims to integrate all known and predicted associations between proteins, including both physical interactions as well as functional associations. To achieve this, STRING collects and scores evidence from a number of sources: (i) automated text mining of the scientific literature, (ii) databases of interaction experiments and annotated complexes/pathways, (iii) computational interaction predictions from co-expression and from conserved genomic context and (iv) systematic transfers of interaction evidence from one organism to another. STRING aims for wide coverage; the upcoming version 11.5 of the resource will contain more than 14 000 organisms. In this update paper, we describe changes to the text-mining system, a new scoring-mode for physical interactions, as well as extensive user interface features for customizing, extending and sharing protein networks. In addition, we describe how to query STRING with genome-wide, experimental data, including the automated detection of enriched functionalities and potential biases in the user's query data. The STRING resource is available online, at https://string-db.org/.", "concepts": ["Biology", "Computational biology", "Database", "Genetics", "Computer science", "World Wide Web", "Physics", "Quantum mechanics"], "domain": "physics"}
{"id": "https://openalex.org/W2950504429", "title": "Reflecting on reflexive thematic analysis", "abstract": "Since initially writing on thematic analysis in 2006, the popularity of the method we outlined has exploded, the variety of TA approaches have expanded, and, not least, our thinking has developed and shifted. In this reflexive commentary, we look back at some of the unspoken assumptions that informed how we wrote our 2006 paper. We connect some of these un-identified assumptions, and developments in the method over the years, with some conceptual mismatches and confusions we see in published TA studies. In order to facilitate better TA practice, we reflect on how our thinking has evolved – and in some cases sedimented – since the publication of our 2006 paper, and clarify and revise some of the ways we phrased or conceptualised TA, and the elements of, and processes around, a method we now prefer to call reflexive TA.", "concepts": ["Epistemology", "Sociology", "Computer science", "Data science", "Psychology", "Philosophy", "Social science", "Social psychology"], "domain": "psychology"}
{"id": "https://openalex.org/W4390583258", "title": "Navigating the confluence of artificial intelligence and education for sustainable development in the era of industry 4.0: Challenges, opportunities, and ethical dimensions", "abstract": "The emergence of Industry 4.0 marks a transformative era for businesses and industries, characterized by advanced technologies like automation, Internet of Things (IoT), artificial intelligence (AI), smart factories, and cyber-physical systems. This revolution promises significant advantages, including enhanced productivity, sustainable progress, and heightened resilience. However, the integration of Industry 4.0 is challenged by the need for a skilled workforce with expertise in areas such as information technology and data analytics. Higher education institutions (HEIs) play a vital role in equipping future professionals with these skills, necessitating curriculum updates and infrastructure enhancements. Simultaneously, the importance of education for sustainable development (ESD) has been underscored by global initiatives like the Sustainable Development Goals (SDGs). ESD instills a sense of responsibility for economic, ecological, and equitable well-being. As digital technologies blur the lines between industries, education faces the challenge of adapting to evolving demands. The integration of AI tools in education has emerged as a catalyst for reshaping learning experiences, fostering innovation, and preparing individuals for the digital age. AI chatbots such as ChatGPT have garnered widespread attention and possess the potential to revolutionize various aspects of education. However, their integration raises ethical concerns, necessitates curriculum redesign, requires strategies for continuous learning, and demands alignment with industry standards. While the potential of AI integration in education is promising, there is a notable gap in the existing literature when it comes to exploring the ethical implications, the influence of AI on ESD, the impact on the structure of Blooms Taxonomy, collaboration between academia and industry, strategies for continuous learning, and the effective integration of AI tools for personalized learning. This paper aims to critically examine the integration of AI tools, with a specific emphasis on ChatGPT, in education within the context of ESD. It delves into the transformative potential, ethical considerations, imperatives for continuous learning, and the role of industry partnerships. By providing insights and strategies, this paper contributes to the ongoing discussion about the evolving nature of education in a technologically driven world, equipping academic institutions to navigate the complexities and opportunities associated with AI integration in education more effectively.", "concepts": ["Engineering ethics", "Knowledge management", "Engineering", "Business", "Engineering management", "Sociology", "Political science", "Computer science"], "domain": "economics"}
{"id": "https://openalex.org/W4400591407", "title": "Prediction of Daily Climate Using Long Short-Term Memory (LSTM) Model", "abstract": "Climaate prediction plays a vital role in various sectors, including agriculture, disaster management, and urban planning. Traditional methods for climate forecasting often rely on complex physical models, which require substantial computational resources and may not accurately capture local weather patterns. This study explores the potential of Long Short-Term Memory (LSTM) networks, a type of recurrent neural network, for predicting daily climate variables such as temperature, precipitation, and humidity. Utilizing historical climate data from the city of Delhi, we developed an LSTM model to forecast short-term climate trends. The model consists of two LSTM layers followed by three Dense layers and is compiled with the Adam optimizer, mean squared error loss, and mean absolute error as a metric. Our results demonstrate the model's capability to capture temporal dependencies in climate data, achieving a satisfactory level of accuracy in temperature forecasting. This research underscores the potential of machine learning techniques, particularly LSTM networks, in enhancing climate prediction and contributing to more informed decision-making in weather-sensitive sectors.", "concepts": ["Computer science", "Climatology", "Artificial intelligence", "Meteorology", "Environmental science", "Econometrics", "Psychology", "Geography"], "domain": "mathematics"}
{"id": "https://openalex.org/W2912654919", "title": "Global, regional, and national incidence, prevalence, and years lived with disability for 354 diseases and injuries for 195 countries and territories, 1990–2017: a systematic analysis for the Global Burden of Disease Study 2017", "abstract": "Background: The Global Burden of Diseases, Injuries, and Risk Factors Study 2017 (GBD 2017) includes a comprehensive assessment of incidence, prevalence, and years lived with disability (YLDs) for 354 causes in 195 countries and territories from 1990 to 2017. Previous GBD studies have shown how the decline of mortality rates from 1990 to 2016 has led to an increase in life expectancy, an ageing global population, and an expansion of the non-fatal burden of disease and injury. These studies have also shown how a substantial portion of the world's population experiences non-fatal health loss with considerable heterogeneity among different causes, locations, ages, and sexes. Ongoing objectives of the GBD study include increasing the level of estimation detail, improving analytical strategies, and increasing the amount of high-quality data. Methods: We estimated incidence and prevalence for 354 diseases and injuries and 3484 sequelae. We used an updated and extensive body of literature studies, survey data, surveillance data, inpatient admission records, outpatient visit records, and health insurance claims, and additionally used results from cause of death models to inform estimates using a total of 68 781 data sources. Newly available clinical data from India, Iran, Japan, Jordan, Nepal, China, Brazil, Norway, and Italy were incorporated, as well as updated claims data from the USA and new claims data from Taiwan (province of China) and Singapore. We used DisMod-MR 2.1, a Bayesian meta-regression tool, as the main method of estimation, ensuring consistency between rates of incidence, prevalence, remission, and cause of death for each condition. YLDs were estimated as the product of a prevalence estimate and a disability weight for health states of each mutually exclusive sequela, adjusted for comorbidity. We updated the Socio-demographic Index (SDI), a summary development indicator of income per capita, years of schooling, and total fertility rate. Additionally, we calculated differences between male and female YLDs to identify divergent trends across sexes. GBD 2017 complies with the Guidelines for Accurate and Transparent Health Estimates Reporting. Findings: Globally, for females, the causes with the greatest age-standardised prevalence were oral disorders, headache disorders, and haemoglobinopathies and haemolytic anaemias in both 1990 and 2017. For males, the causes with the greatest age-standardised prevalence were oral disorders, headache disorders, and tuberculosis including latent tuberculosis infection in both 1990 and 2017. In terms of YLDs, low back pain, headache disorders, and dietary iron deficiency were the leading Level 3 causes of YLD counts in 1990, whereas low back pain, headache disorders, and depressive disorders were the leading causes in 2017 for both sexes combined. All-cause age-standardised YLD rates decreased by 3·9% (95% uncertainty interval [UI] 3·1-4·6) from 1990 to 2017; however, the all-age YLD rate increased by 7·2% (6·0-8·4) while the total sum of global YLDs increased from 562 million (421-723) to 853 million (642-1100). The increases for males and females were similar, with increases in all-age YLD rates of 7·9% (6·6-9·2) for males and 6·5% (5·4-7·7) for females. We found significant differences between males and females in terms of age-standardised prevalence estimates for multiple causes. The causes with the greatest relative differences between sexes in 2017 included substance use disorders (3018 cases [95% UI 2782-3252] per 100 000 in males vs 1400 [1279-1524] per 100 000 in females), transport injuries (3322 [3082-3583] vs 2336 [2154-2535]), and self-harm and interpersonal violence (3265 [2943-3630] vs 5643 [5057-6302]). Interpretation: Global all-cause age-standardised YLD rates have improved only slightly over a period spanning nearly three decades. However, the magnitude of the non-fatal disease burden has expanded globally, with increasing numbers of people who have a wide spectrum of conditions. A subset of conditions has remained globally pervasive since 1990, whereas other conditions have displayed more dynamic trends, with different ages, sexes, and geographies across the globe experiencing varying burdens and trends of health loss. This study emphasises how global improvements in premature mortality for select conditions have led to older populations with complex and potentially expensive diseases, yet also highlights global achievements in certain domains of disease and injury.", "concepts": ["Medicine", "Environmental health", "Demography", "Geography", "Pathology", "Physics", "Sociology", "Optics"], "domain": "physics"}
{"id": "https://openalex.org/W4400928626", "title": "Analysis of Cylinder Comp Product Quality Control with Proposed Improvements at PT. Jakarta Automotive", "abstract": "In the era of globalization, the manufacturing industry faces its biggest challenge, namely the demands of consumer needs with high quality standards. Various kinds of waste often occur in the production process, one of which is caused by a poor layout of facilities, for example the arrangement of machines on the production line that is not suitable. This is a problem in the production process of machining cylinder comp at PT. Jakarta Automotive. With the aim of finding out the factors that cause product defects in machining cylinder comp and finding design of improvement proposals to reduce the defects that occur, this study uses a quantitative method to find DPMO and sigma values as an analysis of the cause of the problem. The result of this study was the discovery of less than optimal engine layout settings that caused TAP NG defects in the product. So that a design of a proposed improvement was made in the form of a change in the engine layout. In conclusion, in this study, it was identified that the non-optimal engine layout was the cause of the high defects. Therefore, improvements are proposed in the form of changing the engine layout on the production line with the aim of reducing the level of defects caused by a less than optimal layout.", "concepts": ["Manufacturing engineering", "Computer science", "Automotive engineering", "Engineering", "Mechanical engineering", "Mathematics", "Philosophy", "Epistemology"], "domain": "economics"}
{"id": "https://openalex.org/W4317390883", "title": "FinnGen provides genetic insights from a well-phenotyped isolated population", "abstract": "Abstract Population isolates such as those in Finland benefit genetic research because deleterious alleles are often concentrated on a small number of low-frequency variants (0.1% ≤ minor allele frequency &lt; 5%). These variants survived the founding bottleneck rather than being distributed over a large number of ultrarare variants. Although this effect is well established in Mendelian genetics, its value in common disease genetics is less explored 1,2 . FinnGen aims to study the genome and national health register data of 500,000 Finnish individuals. Given the relatively high median age of participants (63 years) and the substantial fraction of hospital-based recruitment, FinnGen is enriched for disease end points. Here we analyse data from 224,737 participants from FinnGen and study 15 diseases that have previously been investigated in large genome-wide association studies (GWASs). We also include meta-analyses of biobank data from Estonia and the United Kingdom. We identified 30 new associations, primarily low-frequency variants, enriched in the Finnish population. A GWAS of 1,932 diseases also identified 2,733 genome-wide significant associations (893 phenome-wide significant (PWS), P &lt; 2.6 × 10 –11 ) at 2,496 (771 PWS) independent loci with 807 (247 PWS) end points. Among these, fine-mapping implicated 148 (73 PWS) coding variants associated with 83 (42 PWS) end points. Moreover, 91 (47 PWS) had an allele frequency of &lt;5% in non-Finnish European individuals, of which 62 (32 PWS) were enriched by more than twofold in Finland. These findings demonstrate the power of bottlenecked populations to find entry points into the biology of common diseases through low-frequency, high impact variants.", "concepts": ["Genetics", "Biology", "Medicine", "Environmental health"], "domain": "medicine"}
{"id": "https://openalex.org/W2921388585", "title": "Transcatheter Aortic-Valve Replacement with a Balloon-Expandable Valve in Low-Risk Patients", "abstract": "Among patients with aortic stenosis who are at intermediate or high risk for death with surgery, major outcomes are similar with transcatheter aortic-valve replacement (TAVR) and surgical aortic-valve replacement. There is insufficient evidence regarding the comparison of the two procedures in patients who are at low risk.", "concepts": ["Medicine", "Cardiology", "Internal medicine", "Surgery"], "domain": "medicine"}
{"id": "https://openalex.org/W4381598483", "title": "2023 ESH Guidelines for the management of arterial hypertension The Task Force for the management of arterial hypertension of the European Society of Hypertension", "abstract": "Document Reviewers: Luis Alcocer (Mexico), Christina Antza (Greece), Mustafa Arici (Turkey), Eduardo Barbosa (Brazil), Adel Berbari (Lebanon), Luís Bronze (Portugal), John Chalmers (Australia), Tine De Backer (Belgium), Alejandro de la Sierra (Spain), Kyriakos Dimitriadis (Greece), Dorota Drozdz (Poland), Béatrice Duly-Bouhanick (France), Brent M. Egan (USA), Serap Erdine (Turkey), Claudio Ferri (Italy), Slavomira Filipova (Slovak Republic), Anthony Heagerty (UK), Michael Hecht Olsen (Denmark), Dagmara Hering (Poland), Sang Hyun Ihm (South Korea), Uday Jadhav (India), Manolis Kallistratos (Greece), Kazuomi Kario (Japan), Vasilios Kotsis (Greece), Adi Leiba (Israel), Patricio López-Jaramillo (Colombia), Hans-Peter Marti (Norway), Terry McCormack (UK), Paolo Mulatero (Italy), Dike B. Ojji (Nigeria), Sungha Park (South Korea), Priit Pauklin (Estonia), Sabine Perl (Austria), Arman Postadzhian (Bulgaria), Aleksander Prejbisz (Poland), Venkata Ram (India), Ramiro Sanchez (Argentina), Markus Schlaich (Australia), Alta Schutte (Australia), Cristina Sierra (Spain), Sekib Sokolovic (Bosnia and Herzegovina), Jonas Spaak (Sweden), Dimitrios Terentes-Printzios (Greece), Bruno Trimarco (Italy), Thomas Unger (The Netherlands), Bert-Jan van den Born (The Netherlands), Anna Vachulova (Slovak Republic), Agostino Virdis (Italy), Jiguang Wang (China), Ulrich Wenzel (Germany), Paul Whelton (USA), Jiri Widimsky (Czech Republic), Jacek Wolf (Poland), Grégoire Wuerzner (Switzerland), Eugene Yang (USA), Yuqing Zhang (China).", "concepts": ["Medicine", "Ancient history", "Humanities", "Demography", "Geography", "Archaeology", "History", "Art"], "domain": "medicine"}
{"id": "https://openalex.org/W3157638995", "title": "The Chemistry of Reactive Oxygen Species (ROS) Revisited: Outlining Their Role in Biological Macromolecules (DNA, Lipids and Proteins) and Induced Pathologies", "abstract": "Living species are continuously subjected to all extrinsic forms of reactive oxidants and others that are produced endogenously. There is extensive literature on the generation and effects of reactive oxygen species (ROS) in biological processes, both in terms of alteration and their role in cellular signaling and regulatory pathways. Cells produce ROS as a controlled physiological process, but increasing ROS becomes pathological and leads to oxidative stress and disease. The induction of oxidative stress is an imbalance between the production of radical species and the antioxidant defense systems, which can cause damage to cellular biomolecules, including lipids, proteins and DNA. Cellular and biochemical experiments have been complemented in various ways to explain the biological chemistry of ROS oxidants. However, it is often unclear how this translates into chemical reactions involving redox changes. This review addresses this question and includes a robust mechanistic explanation of the chemical reactions of ROS and oxidative stress.", "concepts": ["Chemistry", "Biochemistry", "Cell biology", "Biophysics", "Biology", "Organic chemistry"], "domain": "chemistry"}
{"id": "https://openalex.org/W4327550249", "title": "Evolutionary-scale prediction of atomic-level protein structure with a language model", "abstract": "Recent advances in machine learning have leveraged evolutionary information in multiple sequence alignments to predict protein structure. We demonstrate direct inference of full atomic-level protein structure from primary sequence using a large language model. As language models of protein sequences are scaled up to 15 billion parameters, an atomic-resolution picture of protein structure emerges in the learned representations. This results in an order-of-magnitude acceleration of high-resolution structure prediction, which enables large-scale structural characterization of metagenomic proteins. We apply this capability to construct the ESM Metagenomic Atlas by predicting structures for >617 million metagenomic protein sequences, including >225 million that are predicted with high confidence, which gives a view into the vast breadth and diversity of natural proteins.", "concepts": ["Computer science", "Artificial intelligence", "Machine learning", "Computational biology", "Biology", "Genetics", "Geography", "Cartography"], "domain": "biology"}
{"id": "https://openalex.org/W2588003345", "title": "SoilGrids250m: Global gridded soil information based on machine learning", "abstract": "This paper describes the technical development and accuracy assessment of the most recent and improved version of the SoilGrids system at 250m resolution (June 2016 update). SoilGrids provides global predictions for standard numeric soil properties (organic carbon, bulk density, Cation Exchange Capacity (CEC), pH, soil texture fractions and coarse fragments) at seven standard depths (0, 5, 15, 30, 60, 100 and 200 cm), in addition to predictions of depth to bedrock and distribution of soil classes based on the World Reference Base (WRB) and USDA classification systems (ca. 280 raster layers in total). Predictions were based on ca. 150,000 soil profiles used for training and a stack of 158 remote sensing-based soil covariates (primarily derived from MODIS land products, SRTM DEM derivatives, climatic images and global landform and lithology maps), which were used to fit an ensemble of machine learning methods—random forest and gradient boosting and/or multinomial logistic regression—as implemented in the R packages ranger, xgboost, nnet and caret. The results of 10–fold cross-validation show that the ensemble models explain between 56% (coarse fragments) and 83% (pH) of variation with an overall average of 61%. Improvements in the relative accuracy considering the amount of variation explained, in comparison to the previous version of SoilGrids at 1 km spatial resolution, range from 60 to 230%. Improvements can be attributed to: (1) the use of machine learning instead of linear regression, (2) to considerable investments in preparing finer resolution covariate layers and (3) to insertion of additional soil profiles. Further development of SoilGrids could include refinement of methods to incorporate input uncertainties and derivation of posterior probability distributions (per pixel), and further automation of spatial modeling so that soil maps can be generated for potentially hundreds of soil variables. Another area of future research is the development of methods for multiscale merging of SoilGrids predictions with local and/or national gridded soil products (e.g. up to 50 m spatial resolution) so that increasingly more accurate, complete and consistent global soil information can be produced. SoilGrids are available under the Open Data Base License.", "concepts": ["Soil science", "Environmental science", "Computer science", "Remote sensing", "Artificial intelligence", "Cartography", "Mathematics", "Statistics"], "domain": "engineering"}
{"id": "https://openalex.org/W3196836501", "title": "Revisiting Event-Study Designs: Robust and Efficient Estimation", "abstract": "Abstract We develop a framework for difference-in-differences designs with staggered treatment adoption and heterogeneous causal effects. We show that conventional regression-based estimators fail to provide unbiased estimates of relevant estimands absent strong restrictions on treatment-effect homogeneity. We then derive the efficient estimator addressing this challenge, which takes an intuitive “imputation” form when treatment-effect heterogeneity is unrestricted. We characterize the asymptotic behaviour of the estimator, propose tools for inference, and develop tests for identifying assumptions. Our method applies with time-varying controls, in triple-difference designs, and with certain non-binary treatments. We show the practical relevance of our results in a simulation study and an application. Studying the consumption response to tax rebates in the U.S., we find that the notional marginal propensity to consume is between 8 and 11% in the first quarter—about half as large as benchmark estimates used to calibrate macroeconomic models—and predominantly occurs in the first month after the rebate.", "concepts": ["Econometrics", "Economics", "Computer science", "Statistics", "Mathematics", "Artificial intelligence", "Geodesy", "Finance"], "domain": "mathematics"}
{"id": "https://openalex.org/W4367595583", "title": "A Brief Overview of ChatGPT: The History, Status Quo and Potential Future Development", "abstract": "ChatGPT, an artificial intelligence generated content (AIGC) model developed by OpenAI, has attracted world-wide attention for its capability of dealing with challenging language understanding and generation tasks in the form of conversations. This paper briefly provides an overview on the history, status quo and potential future development of ChatGPT, helping to provide an entry point to think about ChatGPT. Specifically, from the limited open-accessed resources, we conclude the core techniques of ChatGPT, mainly including large-scale language models, in-context learning, reinforcement learning from human feedback and the key technical steps for developing Chat-GPT. We further analyze the pros and cons of ChatGPT and we rethink the duality of ChatGPT in various fields. Although it has been widely acknowledged that ChatGPT brings plenty of opportunities for various fields, mankind should still treat and use ChatGPT properly to avoid the potential threat, e.g., academic integrity and safety challenge. Finally, we discuss several open problems as the potential development of ChatGPT.", "concepts": ["Computer science", "Engineering ethics", "Risk analysis (engineering)", "Management science", "Data science", "Artificial intelligence", "Political science", "Engineering"], "domain": "social_sciences"}
{"id": "https://openalex.org/W4389437528", "title": "Education in the Era of Generative Artificial Intelligence (AI): Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning", "abstract": "Since its maiden release into the public domain on November 30, 2022, ChatGPT garnered more than one million subscribers within a week. The generative AI tool ⎼ChatGPT took the world by surprise with it sophisticated capacity to carry out remarkably complex tasks. The extraordinary abilities of ChatGPT to perform complex tasks within the field of education has caused mixed feelings among educators, as this advancement in AI seems to revolutionize existing educational praxis. This is an exploratory study that synthesizes recent extant literature to offer some potential benefits and drawbacks of ChatGPT in promoting teaching and learning. Benefits of ChatGPT include but are not limited to promotion of personalized and interactive learning, generating prompts for formative assessment activities that provide ongoing feedback to inform teaching and learning etc. The paper also highlights some inherent limitations in the ChatGPT such as generating wrong information, biases in data training, which may augment existing biases, privacy issues etc. The study offers recommendations on how ChatGPT could be leveraged to maximize teaching and learning. Policy makers, researchers, educators and technology experts could work together and start conversations on how these evolving generative AI tools could be used safely and constructively to improve education and support students’ learning.", "concepts": ["Computer science", "Artificial intelligence", "Knowledge management", "Psychology", "Mathematics education", "Political science", "Social psychology", "Mathematics"], "domain": "social_sciences"}
{"id": "https://openalex.org/W2899760200", "title": "The PRIDE database and related tools and resources in 2019: improving support for quantification data", "abstract": "The PRoteomics IDEntifications (PRIDE) database (https://www.ebi.ac.uk/pride/) is the world's largest data repository of mass spectrometry-based proteomics data, and is one of the founding members of the global ProteomeXchange (PX) consortium. In this manuscript, we summarize the developments in PRIDE resources and related tools since the previous update manuscript was published in Nucleic Acids Research in 2016. In the last 3 years, public data sharing through PRIDE (as part of PX) has definitely become the norm in the field. In parallel, data re-use of public proteomics data has increased enormously, with multiple applications. We first describe the new architecture of PRIDE Archive, the archival component of PRIDE. PRIDE Archive and the related data submission framework have been further developed to support the increase in submitted data volumes and additional data types. A new scalable and fault tolerant storage backend, Application Programming Interface and web interface have been implemented, as a part of an ongoing process. Additionally, we emphasize the improved support for quantitative proteomics data through the mzTab format. At last, we outline key statistics on the current data contents and volume of downloads, and how PRIDE data are starting to be disseminated to added-value resources including Ensembl, UniProt and Expression Atlas.", "concepts": ["Biology", "Database", "Computational biology", "Data science", "Bioinformatics", "Computer science", "Law", "Political science"], "domain": "biology"}
{"id": "https://openalex.org/W4366420437", "title": "What Is the Impact of ChatGPT on Education? A Rapid Review of the Literature", "abstract": "An artificial intelligence-based chatbot, ChatGPT, was launched in November 2022 and is capable of generating cohesive and informative human-like responses to user input. This rapid review of the literature aims to enrich our understanding of ChatGPT’s capabilities across subject domains, how it can be used in education, and potential issues raised by researchers during the first three months of its release (i.e., December 2022 to February 2023). A search of the relevant databases and Google Scholar yielded 50 articles for content analysis (i.e., open coding, axial coding, and selective coding). The findings of this review suggest that ChatGPT’s performance varied across subject domains, ranging from outstanding (e.g., economics) and satisfactory (e.g., programming) to unsatisfactory (e.g., mathematics). Although ChatGPT has the potential to serve as an assistant for instructors (e.g., to generate course materials and provide suggestions) and a virtual tutor for students (e.g., to answer questions and facilitate collaboration), there were challenges associated with its use (e.g., generating incorrect or fake information and bypassing plagiarism detectors). Immediate action should be taken to update the assessment methods and institutional policies in schools and universities. Instructor training and student education are also essential to respond to the impact of ChatGPT on the educational environment.", "concepts": ["Computer science", "Mathematics education", "Psychology", "Pedagogy", "World Wide Web", "Sociology", "Social science"], "domain": "psychology"}
{"id": "https://openalex.org/W2883251903", "title": "ape 5.0: an environment for modern phylogenetics and evolutionary analyses in R", "abstract": "After more than fifteen years of existence, the R package ape has continuously grown its contents, and has been used by a growing community of users. The release of version 5.0 has marked a leap towards a modern software for evolutionary analyses. Efforts have been put to improve efficiency, flexibility, support for 'big data' (R's long vectors), ease of use and quality check before a new release. These changes will hopefully make ape a useful software for the study of biodiversity and evolution in a context of increasing data quantity.ape is distributed through the Comprehensive R Archive Network: http://cran.r-project.org/package=ape. Further information may be found at http://ape-package.ird.fr/.", "concepts": ["Computer science", "Data science", "Biology", "Data mining", "Programming language", "Mathematics", "Statistics", "Paleontology"], "domain": "mathematics"}
{"id": "https://openalex.org/W2981869278", "title": "Dissecting racial bias in an algorithm used to manage the health of populations", "abstract": "Health systems rely on commercial prediction algorithms to identify and help patients with complex health needs. We show that a widely used algorithm, typical of this industry-wide approach and affecting millions of patients, exhibits significant racial bias: At a given risk score, Black patients are considerably sicker than White patients, as evidenced by signs of uncontrolled illnesses. Remedying this disparity would increase the percentage of Black patients receiving additional help from 17.7 to 46.5%. The bias arises because the algorithm predicts health care costs rather than illness, but unequal access to care means that we spend less money caring for Black patients than for White patients. Thus, despite health care cost appearing to be an effective proxy for health by some measures of predictive accuracy, large racial biases arise. We suggest that the choice of convenient, seemingly effective proxies for ground truth can be an important source of algorithmic bias in many contexts.", "concepts": ["Computer science", "Actuarial science", "Medicine", "Algorithm", "Psychology", "Machine learning", "Economics", "Political science"], "domain": "medicine"}
{"id": "https://openalex.org/W4402275599", "title": "Implementing Blockchain Technology for Optimized Supply Chain and Enhanced Sustainability", "abstract": "Supply chain efficiency, transparency, and sustainability can be enhanced using blockchain technology. Blockchain enables a company to accurately track raw material origin to finished products, which ensures standard quality and sustainability. Furthermore, blockchain improves partnerships between supply chain stakeholders by providing a confident, common platform for sharing data. The influence of implementing blockchain technology on supply chain sustainability includes reduced wastage, increased resource transparency, monitoring of social standards, and reduced operational costs. The challenges of blockchain implementation include scalability, incorporation with present systems, lack of expertise, safety and confidentiality, and regulatory uncertainty. Companies can tackle these challenges through collaborative approaches and technical improvements. In general, blockchain technology significantly enhances supply chain sustainability and efficiency, which provides opportunities for creative business solutions.", "concepts": ["Business", "Environmental economics", "Computer science", "Computer security", "Economics", "Marketing", "Ecology", "Biology"], "domain": "economics"}
{"id": "https://openalex.org/W2911489562", "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining", "abstract": "Biomedical text mining is becoming increasingly important as the number of biomedical documents rapidly grows. With the progress in natural language processing (NLP), extracting valuable information from biomedical literature has gained popularity among researchers, and deep learning has boosted the development of effective biomedical text mining models. However, directly applying the advancements in NLP to biomedical text mining often yields unsatisfactory results due to a word distribution shift from general domain corpora to biomedical corpora. In this article, we investigate how the recently introduced pre-trained language model BERT can be adapted for biomedical corpora. We introduce BioBERT (Bidirectional Encoder Representations from Transformers for Biomedical Text Mining), which is a domain-specific language representation model pre-trained on large-scale biomedical corpora. With almost the same architecture across tasks, BioBERT largely outperforms BERT and previous state-of-the-art models in a variety of biomedical text mining tasks when pre-trained on biomedical corpora. While BERT obtains performance comparable to that of previous state-of-the-art models, BioBERT significantly outperforms them on the following three representative biomedical text mining tasks: biomedical named entity recognition (0.62% F1 score improvement), biomedical relation extraction (2.80% F1 score improvement) and biomedical question answering (12.24% MRR improvement). Our analysis results show that pre-training BERT on biomedical corpora helps it to understand complex biomedical texts. We make the pre-trained weights of BioBERT freely available at https://github.com/naver/biobert-pretrained, and the source code for fine-tuning BioBERT available at https://github.com/dmis-lab/biobert.", "concepts": ["Computer science", "Artificial intelligence", "Natural language processing", "Mathematical analysis", "Mathematics", "Management", "Political science", "Law"], "domain": "economics"}
{"id": "https://openalex.org/W3105982350", "title": "Double-slit photoelectron interference in strong-field ionization of the neon dimer", "abstract": "Wave-particle duality is an inherent peculiarity of the quantum world. The double-slit experiment has been frequently used for understanding different aspects of this fundamental concept. The occurrence of interference rests on the lack of which-way information and on the absence of decoherence mechanisms, which could scramble the wave fronts. In this letter, we report on the observation of two-center interference in the molecular frame photoelectron momentum distribution upon ionization of the neon dimer by a strong laser field. Postselection of ions, which were measured in coincidence with electrons, allowed choosing the symmetry of the continuum electronic wave function, leading to observation of both, gerade and ungerade, types of interference.", "concepts": ["Physics", "Atomic physics", "Quantum mechanics", "Electrical engineering", "Engineering", "Mathematics", "Finance", "Pure mathematics"], "domain": "mathematics"}
{"id": "https://openalex.org/W2974260792", "title": "Dapagliflozin in Patients with Heart Failure and Reduced Ejection Fraction", "abstract": "BACKGROUND: In patients with type 2 diabetes, inhibitors of sodium-glucose cotransporter 2 (SGLT2) reduce the risk of a first hospitalization for heart failure, possibly through glucose-independent mechanisms. More data are needed regarding the effects of SGLT2 inhibitors in patients with established heart failure and a reduced ejection fraction, regardless of the presence or absence of type 2 diabetes. METHODS: In this phase 3, placebo-controlled trial, we randomly assigned 4744 patients with New York Heart Association class II, III, or IV heart failure and an ejection fraction of 40% or less to receive either dapagliflozin (at a dose of 10 mg once daily) or placebo, in addition to recommended therapy. The primary outcome was a composite of worsening heart failure (hospitalization or an urgent visit resulting in intravenous therapy for heart failure) or cardiovascular death. RESULTS: Over a median of 18.2 months, the primary outcome occurred in 386 of 2373 patients (16.3%) in the dapagliflozin group and in 502 of 2371 patients (21.2%) in the placebo group (hazard ratio, 0.74; 95% confidence interval [CI], 0.65 to 0.85; P<0.001). A first worsening heart failure event occurred in 237 patients (10.0%) in the dapagliflozin group and in 326 patients (13.7%) in the placebo group (hazard ratio, 0.70; 95% CI, 0.59 to 0.83). Death from cardiovascular causes occurred in 227 patients (9.6%) in the dapagliflozin group and in 273 patients (11.5%) in the placebo group (hazard ratio, 0.82; 95% CI, 0.69 to 0.98); 276 patients (11.6%) and 329 patients (13.9%), respectively, died from any cause (hazard ratio, 0.83; 95% CI, 0.71 to 0.97). Findings in patients with diabetes were similar to those in patients without diabetes. The frequency of adverse events related to volume depletion, renal dysfunction, and hypoglycemia did not differ between treatment groups. CONCLUSIONS: Among patients with heart failure and a reduced ejection fraction, the risk of worsening heart failure or death from cardiovascular causes was lower among those who received dapagliflozin than among those who received placebo, regardless of the presence or absence of diabetes. (Funded by AstraZeneca; DAPA-HF ClinicalTrials.gov number, NCT03036124.).", "concepts": ["Cardiology", "Internal medicine", "Medicine", "Chemistry", "Endocrinology", "Chromatography"], "domain": "medicine"}
{"id": "https://openalex.org/W4401552709", "title": "Circuit Breaker", "abstract": "In the realm of microservices architecture, ensuring reliability and resilience is paramount due to the distributed nature and interdependencies of services. A key pattern employed to enhance system robustness is the circuit breaker. When a microservice experiences failures, the circuit breaker pattern detects these faults and transitions between three states: closed, open, and half-open. During this period, requests are automatically redirected or fail fast, preventing additional strain on the troubled service. Once the service stabilizes, the circuit breaker transitions to the half-open state, where it allows a limited number of test requests to verify recovery. If these succeed, the circuit breaker closes, restoring normal operation. This abstract explores the implementation, benefits, and challenges of circuit breakers in microservices, emphasizing their role in maintaining high availability and robust performance in modern distributed systems.", "concepts": ["Computer science", "Reliability engineering", "Engineering", "Electrical engineering", "Operating system", "Biochemistry", "Chemistry", "Physics"], "domain": "chemistry"}
{"id": "https://openalex.org/W2911892655", "title": "The role of renewable energy in the global energy transformation", "abstract": "This paper explores the technical and economic characteristics of an accelerated energy transition to 2050, using new datasets for renewable energy. The analysis indicates that energy efficiency and renewable energy technologies are the core elements of that transition, and their synergies are likewise important. Favourable economics, ubiquitous resources, scalable technology, and significant socio-economic benefits underpin such a transition. Renewable energy can supply two-thirds of the total global energy demand, and contribute to the bulk of the greenhouse gas emissions reduction that is needed between now and 2050 for limiting average global surface temperature increase below 2 °C. Enabling policy and regulatory frameworks will need to be adjusted to mobilise the six-fold acceleration of renewables growth that is needed, with the highest growth estimated for wind and solar PV technologies, complemented by a high level of energy efficiency. Still, to ensure the eventual elimination of carbon dioxide emissions will require new technology and innovation, notably for the transport and manufacturing sectors, which remain largely ignored in the international debate. More attention is needed for emerging infrastructure issues such as charging infrastructure and other sector coupling implications.", "concepts": ["Environmental economics", "Natural resource economics", "Business", "Economics", "Engineering", "Statistics", "Mathematics", "Electrical engineering"], "domain": "economics"}
{"id": "https://openalex.org/W4211191293", "title": "Heart Disease and Stroke Statistics—2023 Update: A Report From the American Heart Association", "abstract": "Background: The American Heart Association, in conjunction with the National Institutes of Health, annually reports the most up-to-date statistics related to heart disease, stroke, and cardiovascular risk factors, including core health behaviors (smoking, physical activity, diet, and weight) and health factors (cholesterol, blood pressure, and glucose control) that contribute to cardiovascular health. The Statistical Update presents the latest data on a range of major clinical heart and circulatory disease conditions (including stroke, congenital heart disease, rhythm disorders, subclinical atherosclerosis, coronary heart disease, heart failure, valvular disease, venous disease, and peripheral artery disease) and the associated outcomes (including quality of care, procedures, and economic costs). Methods: The American Heart Association, through its Epidemiology and Prevention Statistics Committee, continuously monitors and evaluates sources of data on heart disease and stroke in the United States to provide the most current information available in the annual Statistical Update with review of published literature through the year before writing. The 2023 Statistical Update is the product of a full year’s worth of effort in 2022 by dedicated volunteer clinicians and scientists, committed government professionals, and American Heart Association staff members. The American Heart Association strives to further understand and help heal health problems inflicted by structural racism, a public health crisis that can significantly damage physical and mental health and perpetuate disparities in access to health care, education, income, housing, and several other factors vital to healthy lives. This year’s edition includes additional COVID-19 (coronavirus disease 2019) publications, as well as data on the monitoring and benefits of cardiovascular health in the population, with an enhanced focus on health equity across several key domains. Results: Each of the chapters in the Statistical Update focuses on a different topic related to heart disease and stroke statistics. Conclusions: The Statistical Update represents a critical resource for the lay public, policymakers, media professionals, clinicians, health care administrators, researchers, health advocates, and others seeking the best available data on these factors and conditions.", "concepts": ["Medicine", "Gerontology", "Intensive care medicine", "Internal medicine", "Mechanical engineering", "Engineering"], "domain": "medicine"}
{"id": "https://openalex.org/W4362521115", "title": "The SCARE 2023 guideline: updating consensus Surgical CAse REport (SCARE) guidelines", "abstract": "The Surgical CAse REport (SCARE) guidelines were first published in 2016 as a tool for surgeons to document and report their surgical cases in a standardised and comprehensive manner. However, with advances in technology and changes in the healthcare landscape, it is important to revise and update these guidelines to ensure they remain relevant and valuable for surgeons.The updated guidelines were produced through a Delphi consensus exercise. Members of the SCARE 2020 guidelines Delphi group, editorial board members, and peer reviewers were invited to participate. Potential contributors were contacted by e-mail. An online survey was completed to indicate their agreement with the proposed changes to the guideline items.A total of 54 participants were invited to participate and 44 (81.5%) completed the survey. There was a high degree of agreement among reviewers, with 36 items (83.7%) meeting the threshold for inclusion.Through a completed Delphi consensus exercise we present the SCARE 2023 guidelines. This will provide surgeons with a comprehensive and up-to-date tool for documenting and reporting their surgical cases while highlighting the importance of patient-centred care.", "concepts": ["Medicine", "Family medicine", "Medical education", "Pathology", "Statistics", "Mathematics", "Computer science", "Political science"], "domain": "biology"}
{"id": "https://openalex.org/W2193503481", "title": "Overview of the Coupled Model Intercomparison Project Phase 6 (CMIP6) experimental design and organization", "abstract": "Abstract. By coordinating the design and distribution of global climate model simulations of the past, current, and future climate, the Coupled Model Intercomparison Project (CMIP) has become one of the foundational elements of climate science. However, the need to address an ever-expanding range of scientific questions arising from more and more research communities has made it necessary to revise the organization of CMIP. After a long and wide community consultation, a new and more federated structure has been put in place. It consists of three major elements: (1) a handful of common experiments, the DECK (Diagnostic, Evaluation and Characterization of Klima) and CMIP historical simulations (1850–near present) that will maintain continuity and help document basic characteristics of models across different phases of CMIP; (2) common standards, coordination, infrastructure, and documentation that will facilitate the distribution of model outputs and the characterization of the model ensemble; and (3) an ensemble of CMIP-Endorsed Model Intercomparison Projects (MIPs) that will be specific to a particular phase of CMIP (now CMIP6) and that will build on the DECK and CMIP historical simulations to address a large range of specific questions and fill the scientific gaps of the previous CMIP phases. The DECK and CMIP historical simulations, together with the use of CMIP data standards, will be the entry cards for models participating in CMIP. Participation in CMIP6-Endorsed MIPs by individual modelling groups will be at their own discretion and will depend on their scientific interests and priorities. With the Grand Science Challenges of the World Climate Research Programme (WCRP) as its scientific backdrop, CMIP6 will address three broad questions: – How does the Earth system respond to forcing? – What are the origins and consequences of systematic model biases? – How can we assess future climate changes given internal climate variability, predictability, and uncertainties in scenarios? This CMIP6 overview paper presents the background and rationale for the new structure of CMIP, provides a detailed description of the DECK and CMIP6 historical simulations, and includes a brief introduction to the 21 CMIP6-Endorsed MIPs.", "concepts": ["Computer science", "Systems engineering", "Environmental science", "Operations research", "Geology", "Engineering", "Programming language", "Aerospace engineering"], "domain": "engineering"}
{"id": "https://openalex.org/W2805983714", "title": "The MR-Base platform supports systematic causal inference across the human phenome", "abstract": "Results from genome-wide association studies (GWAS) can be used to infer causal relationships between phenotypes, using a strategy known as 2-sample Mendelian randomization (2SMR) and bypassing the need for individual-level data. However, 2SMR methods are evolving rapidly and GWAS results are often insufficiently curated, undermining efficient implementation of the approach. We therefore developed MR-Base ( http://www.mrbase.org ): a platform that integrates a curated database of complete GWAS results (no restrictions according to statistical significance) with an application programming interface, web app and R packages that automate 2SMR. The software includes several sensitivity analyses for assessing the impact of horizontal pleiotropy and other violations of assumptions. The database currently comprises 11 billion single nucleotide polymorphism-trait associations from 1673 GWAS and is updated on a regular basis. Integrating data with software ensures more rigorous application of hypothesis-driven analyses and allows millions of potential causal relationships to be efficiently evaluated in phenome-wide association studies.", "concepts": ["Computer science", "Data mining", "Computational biology", "Data science", "Bioinformatics", "Biology", "Genetics", "Artificial intelligence"], "domain": "biology"}
{"id": "https://openalex.org/W2798336535", "title": "<i>Gaia</i> Data Release 2", "abstract": "Context. We present the second Gaia data release, Gaia DR2, consisting of astrometry, photometry, radial velocities, and information on astrophysical parameters and variability, for sources brighter than magnitude 21. In addition epoch astrometry and photometry are provided for a modest sample of minor planets in the solar system. Aims. A summary of the contents of Gaia DR2 is presented, accompanied by a discussion on the differences with respect to Gaia DR1 and an overview of the main limitations which are still present in the survey. Recommendations are made on the responsible use of Gaia DR2 results. Methods. The raw data collected with the Gaia instruments during the first 22 months of the mission have been processed by the Gaia Data Processing and Analysis Consortium (DPAC) and turned into this second data release, which represents a major advance with respect to Gaia DR1 in terms of completeness, performance, and richness of the data products. Results. Gaia DR2 contains celestial positions and the apparent brightness in G for approximately 1.7 billion sources. For 1.3 billion of those sources, parallaxes and proper motions are in addition available. The sample of sources for which variability information is provided is expanded to 0 : 5 million stars. This data release contains four new elements: broad-band colour information in the form of the apparent brightness in the G(BP) (330-680 nm) and G(RP) (630-1050 nm) bands is available for 1.4 billion sources; median radial velocities for some 7 million sources are presented; for between 77 and 161 million sources estimates are provided of the stellar effective temperature, extinction, reddening, and radius and luminosity; and for a pre-selected list of 14 000 minor planets in the solar system epoch astrometry and photometry are presented. Finally, Gaia DR2 also represents a new materialisation of the celestial reference frame in the optical, the Gaia-CRF2, which is the first optical reference frame based solely on extragalactic sources. There are notable changes in the photometric system and the catalogue source list with respect to Gaia DR1, and we stress the need to consider the two data releases as independent. Conclusions. Gaia DR2 represents a major achievement for the Gaia mission, delivering on the long standing promise to provide parallaxes and proper motions for over 1 billion stars, and representing a first step in the availability of complementary radial velocity and source astrophysical information for a sample of stars in the Gaia survey which covers a very substantial fraction of the volume of our galaxy.", "concepts": ["Physics", "Astrophysics", "Astronomy"], "domain": "physics"}
{"id": "https://openalex.org/W4399083018", "title": "Intelligent Clinical Documentation: Harnessing Generative AI for Patient-Centric Clinical Note Generation", "abstract": "Comprehensive clinical documentation is crucial for effective healthcare delivery, yet it poses a significant burden on healthcare professionals, leading to burnout, increased medical errors, and compromised patient safety. This paper explores the potential of generative AI (Artificial Intelligence) to streamline the clinical documentation process, specifically focusing on generating SOAP (Subjective, Objective, Assessment, Plan) and BIRP (Behavior, Intervention, Response, Plan) notes. We present a case study demonstrating the application of natural language processing (NLP) and automatic speech recognition (ASR) technologies to transcribe patient-clinician interactions, coupled with advanced prompting techniques to generate draft clinical notes using large language models (LLMs). The study highlights the benefits of this approach, including time savings, improved documentation quality, and enhanced patient-centered care. Additionally, we discuss ethical considerations, such as maintaining patient confidentiality and addressing model biases, underscoring the need for responsible deployment of generative AI in healthcare settings. The findings suggest that generative AI has the potential to revolutionize clinical documentation practices, alleviating administrative burdens and enabling healthcare professionals to focus more on direct patient care.", "concepts": ["Computer science", "Medicine", "Artificial intelligence", "Nursing", "Computer security", "Software engineering", "Programming language", "Economics"], "domain": "economics"}
{"id": "https://openalex.org/W4210588784", "title": "Climate Change 2021—The Physical Science Basis", "abstract": "Abstract The Intergovernmental Panel on Climate Change (IPCC) is the United Nations body responsible for assessing the science related to climate change. The Sixth Report from IPCC Working Group 1 published in August 2021 paints a very sombre picture for the future. This report was commented on in a news item by the International Science Council (ISC) on behalf of its members, of which IUPAC is a founding member.", "concepts": ["Political science", "Geography", "International trade", "Business", "Ecology", "Chemistry", "Biology", "Organic chemistry"], "domain": "chemistry"}
{"id": "https://openalex.org/W1495403436", "title": "Ethnographic Interview", "abstract": "Part I. Ethnographic Research: Ethnography and Culture. Language and Field Work. Informants. Part II. The Developmental Research Sequences: Locating an Informant. Interviewing an Informant. Making an Ethnographic Record. Asking Descriptive Questions. Analyzing Ethnographic Interviews. Making a Domain Analysis. Asking Structural Questions. Making a Taxonomic Analysis. Asking Contrast Questions. Making a Componential Analysis. Discovering Cultural Themes. Writing an Ethnography. Notes. Appendices: A Taxonomy of Ethnographic Questions. Developmental Research Sequence Writing Tasks. The Development Research Sequence Method. Bibliography. Index.", "concepts": ["Linguistics", "Sociology", "Anthropology", "Psychology", "Biology", "Philosophy", "Botany"], "domain": "materials_science"}
{"id": "https://openalex.org/W3183475563", "title": "Highly accurate protein structure prediction for the human proteome", "abstract": "Abstract Protein structures can provide invaluable information, both for reasoning about biological processes and for enabling interventions such as structure-based drug development or targeted mutagenesis. After decades of effort, 17% of the total residues in human protein sequences are covered by an experimentally determined structure 1 . Here we markedly expand the structural coverage of the proteome by applying the state-of-the-art machine learning method, AlphaFold 2 , at a scale that covers almost the entire human proteome (98.5% of human proteins). The resulting dataset covers 58% of residues with a confident prediction, of which a subset (36% of all residues) have very high confidence. We introduce several metrics developed by building on the AlphaFold model and use them to interpret the dataset, identifying strong multi-domain predictions as well as regions that are likely to be disordered. Finally, we provide some case studies to illustrate how high-quality predictions could be used to generate biological hypotheses. We are making our predictions freely available to the community and anticipate that routine large-scale and high-accuracy structure prediction will become an important tool that will allow new questions to be addressed from a structural perspective.", "concepts": ["Computer science", "Computational biology", "Machine learning", "Data science", "Data mining", "Bioinformatics", "Chemistry", "Biology"], "domain": "chemistry"}
{"id": "https://openalex.org/W4399939545", "title": "A DNA barcoding framework for taxonomic verification in the Darwin Tree of Life Project", "abstract": "Biodiversity genomics research requires reliable organismal identification, which can be difficult based on morphology alone. DNA-based identification using DNA barcoding can provide confirmation of species identity and resolve taxonomic issues but is rarely used in studies generating reference genomes. Here, we describe the development and implementation of DNA barcoding for the Darwin Tree of Life Project (DToL), which aims to sequence and assemble high quality reference genomes for all eukaryotic species in Britain and Ireland. We present a standardised framework for DNA barcode sequencing and data interpretation that is then adapted for diverse organismal groups. DNA barcoding data from over 12,000 DToL specimens has identified up to 20% of samples requiring additional verification, with 2% of seed plants and 3.5% of animal specimens subsequently having their names changed. We also make recommendations for future developments using new sequencing approaches and streamlined bioinformatic approaches.", "concepts": ["Evolutionary biology", "Genealogy", "Biology", "Computer science", "History", "Mathematics", "Genetics", "Software engineering"], "domain": "mathematics"}
{"id": "https://openalex.org/W1809873675", "title": "Journal of Machine Learning Technologies", "abstract": "The Journal of Machine Learning Technologies, ISSN: 2229–3981 & ISSN: 2229-399X, aims to publish all the latest and outstanding research articles, reviews and letters in all areas of Machine Learning Technologie. Each issue contains a series of timely, in-depth written articles by leaders in the field, covering a wide range of the integration of multidimensional challenges of research including integration issues of Machine Learning Technologie.", "concepts": ["Computer science", "Data science", "Artificial intelligence", "World Wide Web", "Political science", "Mathematics", "Pure mathematics", "Law"], "domain": "mathematics"}
{"id": "https://openalex.org/W4386958277", "title": "Revolutionizing healthcare: the role of artificial intelligence in clinical practice", "abstract": "Abstract Introduction Healthcare systems are complex and challenging for all stakeholders, but artificial intelligence (AI) has transformed various fields, including healthcare, with the potential to improve patient care and quality of life. Rapid AI advancements can revolutionize healthcare by integrating it into clinical practice. Reporting AI’s role in clinical practice is crucial for successful implementation by equipping healthcare providers with essential knowledge and tools. Research Significance This review article provides a comprehensive and up-to-date overview of the current state of AI in clinical practice, including its potential applications in disease diagnosis, treatment recommendations, and patient engagement. It also discusses the associated challenges, covering ethical and legal considerations and the need for human expertise. By doing so, it enhances understanding of AI’s significance in healthcare and supports healthcare organizations in effectively adopting AI technologies. Materials and Methods The current investigation analyzed the use of AI in the healthcare system with a comprehensive review of relevant indexed literature, such as PubMed/Medline, Scopus, and EMBASE, with no time constraints but limited to articles published in English. The focused question explores the impact of applying AI in healthcare settings and the potential outcomes of this application. Results Integrating AI into healthcare holds excellent potential for improving disease diagnosis, treatment selection, and clinical laboratory testing. AI tools can leverage large datasets and identify patterns to surpass human performance in several healthcare aspects. AI offers increased accuracy, reduced costs, and time savings while minimizing human errors. It can revolutionize personalized medicine, optimize medication dosages, enhance population health management, establish guidelines, provide virtual health assistants, support mental health care, improve patient education, and influence patient-physician trust. Conclusion AI can be used to diagnose diseases, develop personalized treatment plans, and assist clinicians with decision-making. Rather than simply automating tasks, AI is about developing technologies that can enhance patient care across healthcare settings. However, challenges related to data privacy, bias, and the need for human expertise must be addressed for the responsible and effective implementation of AI in healthcare.", "concepts": ["Medicine", "Artificial intelligence", "Computer science", "Political science", "Law", "Economics", "Economic growth"], "domain": "social_sciences"}
{"id": "https://openalex.org/W2888589263", "title": "2018 ESC/ESH Guidelines for the management of arterial hypertension", "abstract": "The ESC/ESH Guidelines represent the views of the ESC and ESH and were produced after careful consideration of the scientific and medical knowledge and the evidence available at the time of their dating.The ESC and ESH are not responsible in the event of any contradiction, discrepancy, and/or ambiguity between the ESC/ESH Guidelines and any other official", "concepts": ["Medicine", "Intensive care medicine", "Family medicine", "Medical emergency", "Epistemology", "Philosophy", "Linguistics"], "domain": "materials_science"}
{"id": "https://openalex.org/W4393115925", "title": "A review of convolutional neural networks in computer vision", "abstract": "Abstract In computer vision, a series of exemplary advances have been made in several areas involving image classification, semantic segmentation, object detection, and image super-resolution reconstruction with the rapid development of deep convolutional neural network (CNN). The CNN has superior features for autonomous learning and expression, and feature extraction from original input data can be realized by means of training CNN models that match practical applications. Due to the rapid progress in deep learning technology, the structure of CNN is becoming more and more complex and diverse. Consequently, it gradually replaces the traditional machine learning methods. This paper presents an elementary understanding of CNN components and their functions, including input layers, convolution layers, pooling layers, activation functions, batch normalization, dropout, fully connected layers, and output layers. On this basis, this paper gives a comprehensive overview of the past and current research status of the applications of CNN models in computer vision fields, e.g., image classification, object detection, and video prediction. In addition, we summarize the challenges and solutions of the deep CNN, and future research directions are also discussed.", "concepts": ["Computer science", "Artificial intelligence", "Computer vision"], "domain": "computer_science"}
{"id": "https://openalex.org/W4362521115", "title": "The SCARE 2023 guideline: updating consensus Surgical CAse REport (SCARE) guidelines", "abstract": "The Surgical CAse REport (SCARE) guidelines were first published in 2016 as a tool for surgeons to document and report their surgical cases in a standardised and comprehensive manner. However, with advances in technology and changes in the healthcare landscape, it is important to revise and update these guidelines to ensure they remain relevant and valuable for surgeons.The updated guidelines were produced through a Delphi consensus exercise. Members of the SCARE 2020 guidelines Delphi group, editorial board members, and peer reviewers were invited to participate. Potential contributors were contacted by e-mail. An online survey was completed to indicate their agreement with the proposed changes to the guideline items.A total of 54 participants were invited to participate and 44 (81.5%) completed the survey. There was a high degree of agreement among reviewers, with 36 items (83.7%) meeting the threshold for inclusion.Through a completed Delphi consensus exercise we present the SCARE 2023 guidelines. This will provide surgeons with a comprehensive and up-to-date tool for documenting and reporting their surgical cases while highlighting the importance of patient-centred care.", "concepts": ["Medicine", "Family medicine", "Medical education", "Pathology", "Statistics", "Mathematics", "Computer science", "Political science"], "domain": "medicine"}
{"id": "https://openalex.org/W4327946446", "title": "ChatGPT Utility in Healthcare Education, Research, and Practice: Systematic Review on the Promising Perspectives and Valid Concerns", "abstract": "ChatGPT is an artificial intelligence (AI)-based conversational large language model (LLM). The potential applications of LLMs in health care education, research, and practice could be promising if the associated valid concerns are proactively examined and addressed. The current systematic review aimed to investigate the utility of ChatGPT in health care education, research, and practice and to highlight its potential limitations. Using the PRIMSA guidelines, a systematic search was conducted to retrieve English records in PubMed/MEDLINE and Google Scholar (published research or preprints) that examined ChatGPT in the context of health care education, research, or practice. A total of 60 records were eligible for inclusion. Benefits of ChatGPT were cited in 51/60 (85.0%) records and included: (1) improved scientific writing and enhancing research equity and versatility; (2) utility in health care research (efficient analysis of datasets, code generation, literature reviews, saving time to focus on experimental design, and drug discovery and development); (3) benefits in health care practice (streamlining the workflow, cost saving, documentation, personalized medicine, and improved health literacy); and (4) benefits in health care education including improved personalized learning and the focus on critical thinking and problem-based learning. Concerns regarding ChatGPT use were stated in 58/60 (96.7%) records including ethical, copyright, transparency, and legal issues, the risk of bias, plagiarism, lack of originality, inaccurate content with risk of hallucination, limited knowledge, incorrect citations, cybersecurity issues, and risk of infodemics. The promising applications of ChatGPT can induce paradigm shifts in health care education, research, and practice. However, the embrace of this AI chatbot should be conducted with extreme caution considering its potential limitations. As it currently stands, ChatGPT does not qualify to be listed as an author in scientific articles unless the ICMJE/COPE guidelines are revised or amended. An initiative involving all stakeholders in health care education, research, and practice is urgently needed. This will help to set a code of ethics to guide the responsible use of ChatGPT among other LLMs in health care and academia.", "concepts": ["Medical education", "Psychology", "Medicine", "Computer science", "Political science", "Paleontology", "Computer security", "Database"], "domain": "social_sciences"}
{"id": "https://openalex.org/W4391514872", "title": "Autoencoders and their applications in machine learning: a survey", "abstract": "Abstract Autoencoders have become a hot researched topic in unsupervised learning due to their ability to learn data features and act as a dimensionality reduction method. With rapid evolution of autoencoder methods, there has yet to be a complete study that provides a full autoencoders roadmap for both stimulating technical improvements and orienting research newbies to autoencoders. In this paper, we present a comprehensive survey of autoencoders, starting with an explanation of the principle of conventional autoencoder and their primary development process. We then provide a taxonomy of autoencoders based on their structures and principles and thoroughly analyze and discuss the related models. Furthermore, we review the applications of autoencoders in various fields, including machine vision, natural language processing, complex network, recommender system, speech process, anomaly detection, and others. Lastly, we summarize the limitations of current autoencoder algorithms and discuss the future directions of the field.", "concepts": ["Computer science", "Artificial intelligence", "Machine learning", "Mathematics", "Pure mathematics", "Operating system"], "domain": "computer_science"}
{"id": "https://openalex.org/W4394828156", "title": "ChatGPT for Robotics: Design Principles and Model Abilities", "abstract": "This paper presents an experimental study regarding the use of OpenAI's ChatGPT [1] for robotics applications. We outline a strategy that combines design principles for prompt engineering and the creation of a high-level function library which allows ChatGPT to adapt to different robotics tasks, simulators, and form factors. We focus our evaluations on the effectiveness of different prompt engineering techniques and dialog strategies towards the execution of various types of robotics tasks. We explore ChatGPT's ability to use free-form dialog, parse XML tags, and to synthesize code, in addition to the use of task-specific prompting functions and closed-loop reasoning through dialogues. Our study encompasses a range of tasks within the robotics domain, from basic logical, geometrical, and mathematical reasoning all the way to complex domains such as aerial navigation, manipulation, and embodied agents. We show that ChatGPT can be effective at solving several of such tasks, while allowing users to interact with it primarily via natural language instructions. In addition to these studies, we introduce an open-sourced research tool called <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">PromptCraft</i> , which contains a platform where researchers can collaboratively upload and vote on examples of good prompting schemes for robotics applications, as well as a sample robotics simulator with ChatGPT integration, making it easier for users to get started with using ChatGPT for robotics. Videos and blog: aka.ms/ChatGPT-Robotics PromptCraft, AirSim-ChatGPT code: https://github.com/microsoft/PromptCraft-Robotics.", "concepts": ["Artificial intelligence", "Computer science", "Human–computer interaction", "World Wide Web", "Mathematical analysis", "Mathematics"], "domain": "computer_science"}
{"id": "https://openalex.org/W2900569176", "title": "STRING v11: protein–protein association networks with increased coverage, supporting functional discovery in genome-wide experimental datasets", "abstract": "Proteins and their functional interactions form the backbone of the cellular machinery. Their connectivity network needs to be considered for the full understanding of biological phenomena, but the available information on protein-protein associations is incomplete and exhibits varying levels of annotation granularity and reliability. The STRING database aims to collect, score and integrate all publicly available sources of protein-protein interaction information, and to complement these with computational predictions. Its goal is to achieve a comprehensive and objective global network, including direct (physical) as well as indirect (functional) interactions. The latest version of STRING (11.0) more than doubles the number of organisms it covers, to 5090. The most important new feature is an option to upload entire, genome-wide datasets as input, allowing users to visualize subsets as interaction networks and to perform gene-set enrichment analysis on the entire input. For the enrichment analysis, STRING implements well-known classification systems such as Gene Ontology and KEGG, but also offers additional, new classification systems based on high-throughput text-mining as well as on a hierarchical clustering of the association network itself. The STRING resource is available online at https://string-db.org/.", "concepts": ["Biology", "Computational biology", "Computer science", "Data mining", "Machine learning", "Genetics", "Physics", "Quantum mechanics"], "domain": "biology"}
{"id": "https://openalex.org/W2981869278", "title": "Dissecting racial bias in an algorithm used to manage the health of populations", "abstract": "Health systems rely on commercial prediction algorithms to identify and help patients with complex health needs. We show that a widely used algorithm, typical of this industry-wide approach and affecting millions of patients, exhibits significant racial bias: At a given risk score, Black patients are considerably sicker than White patients, as evidenced by signs of uncontrolled illnesses. Remedying this disparity would increase the percentage of Black patients receiving additional help from 17.7 to 46.5%. The bias arises because the algorithm predicts health care costs rather than illness, but unequal access to care means that we spend less money caring for Black patients than for White patients. Thus, despite health care cost appearing to be an effective proxy for health by some measures of predictive accuracy, large racial biases arise. We suggest that the choice of convenient, seemingly effective proxies for ground truth can be an important source of algorithmic bias in many contexts.", "concepts": ["Computer science", "Actuarial science", "Medicine", "Algorithm", "Psychology", "Machine learning", "Economics", "Political science"], "domain": "economics"}
{"id": "https://openalex.org/W4285585446", "title": "Metaverse beyond the hype: Multidisciplinary perspectives on emerging challenges, opportunities, and agenda for research, practice and policy", "abstract": "The metaverse has the potential to extend the physical world using augmented and virtual reality technologies allowing users to seamlessly interact within real and simulated environments using avatars and holograms. Virtual environments and immersive games (such as, Second Life, Fortnite, Roblox and VRChat) have been described as antecedents of the metaverse and offer some insight to the potential socio-economic impact of a fully functional persistent cross platform metaverse. Separating the hype and \"meta…\" rebranding from current reality is difficult, as \"big tech\" paints a picture of the transformative nature of the metaverse and how it will positively impact people in their work, leisure, and social interaction. The potential impact on the way we conduct business, interact with brands and others, and develop shared experiences is likely to be transformational as the distinct lines between physical and digital are likely to be somewhat blurred from current perceptions. However, although the technology and infrastructure does not yet exist to allow the development of new immersive virtual worlds at scale - one that our avatars could transcend across platforms, researchers are increasingly examining the transformative impact of the metaverse. Impacted sectors include marketing, education, healthcare as well as societal effects relating to social interaction factors from widespread adoption, and issues relating to trust, privacy, bias, disinformation, application of law as well as psychological aspects linked to addiction and impact on vulnerable people. This study examines these topics in detail by combining the informed narrative and multi-perspective approach from experts with varied disciplinary backgrounds on many aspects of the metaverse and its transformational impact. The paper concludes by proposing a future research agenda that is valuable for researchers, professionals and policy makers alike.", "concepts": ["Sociology", "Public relations", "Computer science", "Human–computer interaction", "Political science", "Pedagogy", "Artificial intelligence"], "domain": "social_sciences"}
{"id": "https://openalex.org/W2955311731", "title": "Manajemen Sumber Daya Manusia", "abstract": "The purpose of this study was to determine human resource management in the Madrasah Aliyah Al-Mathitiriyah Rupit District. This type of research is qualitative research with descriptive analytical methods, namely methods that attempt to systematically explain the discussion material originating from various sources for later analysis in order to obtain results as a conclusion. Research Results, principals are very instrumental in increasing and motivating teachers, staff / employees, in improving student achievement, which has been effective and conditional. In providing opportunities and opportunities for the teachers to take part in education and training held by the government and provide opportunities for teachers to continue their higher level of study, Conclusion, the head of MA Al-Mathiriyah carries out, plans, and professionals, as well as field experts, and able to give awards, and provide penalties, if it violates the teacher's code of ethics.&#x0D; Keywords: Human Resource Management, Performance", "concepts": ["Psychology", "Medical education", "Pedagogy", "Political science", "Public relations", "Business", "Knowledge management", "Computer science"], "domain": "medicine"}
{"id": "https://openalex.org/W3154258817", "title": "ADMETlab 2.0: an integrated online platform for accurate and comprehensive predictions of ADMET properties", "abstract": "Because undesirable pharmacokinetics and toxicity of candidate compounds are the main reasons for the failure of drug development, it has been widely recognized that absorption, distribution, metabolism, excretion and toxicity (ADMET) should be evaluated as early as possible. In silico ADMET evaluation models have been developed as an additional tool to assist medicinal chemists in the design and optimization of leads. Here, we announced the release of ADMETlab 2.0, a completely redesigned version of the widely used AMDETlab web server for the predictions of pharmacokinetics and toxicity properties of chemicals, of which the supported ADMET-related endpoints are approximately twice the number of the endpoints in the previous version, including 17 physicochemical properties, 13 medicinal chemistry properties, 23 ADME properties, 27 toxicity endpoints and 8 toxicophore rules (751 substructures). A multi-task graph attention framework was employed to develop the robust and accurate models in ADMETlab 2.0. The batch computation module was provided in response to numerous requests from users, and the representation of the results was further optimized. The ADMETlab 2.0 server is freely available, without registration, at https://admetmesh.scbdd.com/.", "concepts": ["Computer science", "Computational biology", "Biology", "Pharmacology", "World Wide Web", "Biochemistry", "Chemistry", "Organic chemistry"], "domain": "chemistry"}
{"id": "https://openalex.org/W3029661147", "title": "The mutational constraint spectrum quantified from variation in 141,456 humans", "abstract": "Abstract Genetic variants that inactivate protein-coding genes are a powerful source of information about the phenotypic consequences of gene disruption: genes that are crucial for the function of an organism will be depleted of such variants in natural populations, whereas non-essential genes will tolerate their accumulation. However, predicted loss-of-function variants are enriched for annotation errors, and tend to be found at extremely low frequencies, so their analysis requires careful variant annotation and very large sample sizes 1 . Here we describe the aggregation of 125,748 exomes and 15,708 genomes from human sequencing studies into the Genome Aggregation Database (gnomAD). We identify 443,769 high-confidence predicted loss-of-function variants in this cohort after filtering for artefacts caused by sequencing and annotation errors. Using an improved model of human mutation rates, we classify human protein-coding genes along a spectrum that represents tolerance to inactivation, validate this classification using data from model organisms and engineered human cells, and show that it can be used to improve the power of gene discovery for both common and rare diseases.", "concepts": ["Biology", "Computational biology", "Genetics"], "domain": "environmental_science"}
{"id": "https://openalex.org/W2911892655", "title": "The role of renewable energy in the global energy transformation", "abstract": "This paper explores the technical and economic characteristics of an accelerated energy transition to 2050, using new datasets for renewable energy. The analysis indicates that energy efficiency and renewable energy technologies are the core elements of that transition, and their synergies are likewise important. Favourable economics, ubiquitous resources, scalable technology, and significant socio-economic benefits underpin such a transition. Renewable energy can supply two-thirds of the total global energy demand, and contribute to the bulk of the greenhouse gas emissions reduction that is needed between now and 2050 for limiting average global surface temperature increase below 2 °C. Enabling policy and regulatory frameworks will need to be adjusted to mobilise the six-fold acceleration of renewables growth that is needed, with the highest growth estimated for wind and solar PV technologies, complemented by a high level of energy efficiency. Still, to ensure the eventual elimination of carbon dioxide emissions will require new technology and innovation, notably for the transport and manufacturing sectors, which remain largely ignored in the international debate. More attention is needed for emerging infrastructure issues such as charging infrastructure and other sector coupling implications.", "concepts": ["Environmental economics", "Natural resource economics", "Business", "Economics", "Engineering", "Statistics", "Mathematics", "Electrical engineering"], "domain": "medicine"}
{"id": "https://openalex.org/W2970684805", "title": "RoB 2: a revised tool for assessing risk of bias in randomised trials", "abstract": "Assessment of risk of bias is regarded as an essential component of a systematic review on the effects of an intervention. The most commonly used tool for randomised trials is the Cochrane risk-of-bias tool. We updated the tool to respond to developments in understanding how bias arises in randomised trials, and to address user feedback on and limitations of the original tool.", "concepts": ["Medicine", "Computer science", "Medical physics", "Internal medicine", "Political science", "Law"], "domain": "medicine"}
{"id": "https://openalex.org/W3180677679", "title": "Removal of heavy metal ions from wastewater: a comprehensive and critical review", "abstract": "Abstract Removal of heavy metal ions from wastewater is of prime importance for a clean environment and human health. Different reported methods were devoted to heavy metal ions removal from various wastewater sources. These methods could be classified into adsorption-, membrane-, chemical-, electric-, and photocatalytic-based treatments. This paper comprehensively and critically reviews and discusses these methods in terms of used agents/adsorbents, removal efficiency, operating conditions, and the pros and cons of each method. Besides, the key findings of the previous studies reported in the literature are summarized. Generally, it is noticed that most of the recent studies have focused on adsorption techniques. The major obstacles of the adsorption methods are the ability to remove different ion types concurrently, high retention time, and cycling stability of adsorbents. Even though the chemical and membrane methods are practical, the large-volume sludge formation and post-treatment requirements are vital issues that need to be solved for chemical techniques. Fouling and scaling inhibition could lead to further improvement in membrane separation. However, pre-treatment and periodic cleaning of membranes incur additional costs. Electrical-based methods were also reported to be efficient; however, industrial-scale separation is needed in addition to tackling the issue of large-volume sludge formation. Electric- and photocatalytic-based methods are still less mature. More attention should be drawn to using real wastewaters rather than synthetic ones when investigating heavy metals removal. Future research studies should focus on eco-friendly, cost-effective, and sustainable materials and methods.", "concepts": ["Environmental science", "Waste management", "Process engineering", "Biochemical engineering", "Materials science", "Chemistry", "Environmental engineering", "Environmental chemistry"], "domain": "chemistry"}
{"id": "https://openalex.org/W4360980141", "title": "Examining Science Education in ChatGPT: An Exploratory Study of Generative Artificial Intelligence", "abstract": "Abstract The advent of generative artificial intelligence (AI) offers transformative potential in the field of education. The study explores three main areas: (1) How did ChatGPT answer questions related to science education? (2) What are some ways educators could utilise ChatGPT in their science pedagogy? and (3) How has ChatGPT been utilised in this study, and what are my reflections about its use as a research tool? This exploratory research applies a self-study methodology to investigate the technology. Impressively, ChatGPT’s output often aligned with key themes in the research. However, as it currently stands, ChatGPT runs the risk of positioning itself as the ultimate epistemic authority, where a single truth is assumed without a proper grounding in evidence or presented with sufficient qualifications. Key ethical concerns associated with AI include its potential environmental impact, issues related to content moderation, and the risk of copyright infringement. It is important for educators to model responsible use of ChatGPT, prioritise critical thinking, and be clear about expectations. ChatGPT is likely to be a useful tool for educators designing science units, rubrics, and quizzes. Educators should critically evaluate any AI-generated resource and adapt it to their specific teaching contexts. ChatGPT was used as a research tool for assistance with editing and to experiment with making the research narrative clearer. The intention of the paper is to act as a catalyst for a broader conversation about the use of generative AI in science education.", "concepts": ["Engineering ethics", "Computer science", "Sociology", "Psychology", "Pedagogy", "Artificial intelligence", "Engineering", "Linguistics"], "domain": "psychology"}
{"id": "https://openalex.org/W2604316091", "title": "River plastic emissions to the world’s oceans", "abstract": "Abstract Plastics in the marine environment have become a major concern because of their persistence at sea, and adverse consequences to marine life and potentially human health. Implementing mitigation strategies requires an understanding and quantification of marine plastic sources, taking spatial and temporal variability into account. Here we present a global model of plastic inputs from rivers into oceans based on waste management, population density and hydrological information. Our model is calibrated against measurements available in the literature. We estimate that between 1.15 and 2.41 million tonnes of plastic waste currently enters the ocean every year from rivers, with over 74% of emissions occurring between May and October. The top 20 polluting rivers, mostly located in Asia, account for 67% of the global total. The findings of this study provide baseline data for ocean plastic mass balance exercises, and assist in prioritizing future plastic debris monitoring and mitigation strategies.", "concepts": ["Environmental science", "Environmental resource management", "Oceanography", "Meteorology", "Environmental engineering", "Geography", "Waste management", "Geology"], "domain": "engineering"}
{"id": "https://openalex.org/W3003668884", "title": "Early Transmission Dynamics in Wuhan, China, of Novel Coronavirus–Infected Pneumonia", "abstract": "The initial cases of novel coronavirus (2019-nCoV)-infected pneumonia (NCIP) occurred in Wuhan, Hubei Province, China, in December 2019 and January 2020. We analyzed data on the first 425 confirmed cases in Wuhan to determine the epidemiologic characteristics of NCIP.We collected information on demographic characteristics, exposure history, and illness timelines of laboratory-confirmed cases of NCIP that had been reported by January 22, 2020. We described characteristics of the cases and estimated the key epidemiologic time-delay distributions. In the early period of exponential growth, we estimated the epidemic doubling time and the basic reproductive number.Among the first 425 patients with confirmed NCIP, the median age was 59 years and 56% were male. The majority of cases (55%) with onset before January 1, 2020, were linked to the Huanan Seafood Wholesale Market, as compared with 8.6% of the subsequent cases. The mean incubation period was 5.2 days (95% confidence interval [CI], 4.1 to 7.0), with the 95th percentile of the distribution at 12.5 days. In its early stages, the epidemic doubled in size every 7.4 days. With a mean serial interval of 7.5 days (95% CI, 5.3 to 19), the basic reproductive number was estimated to be 2.2 (95% CI, 1.4 to 3.9).On the basis of this information, there is evidence that human-to-human transmission has occurred among close contacts since the middle of December 2019. Considerable efforts to reduce transmission will be required to control outbreaks if similar dynamics apply elsewhere. Measures to prevent or reduce transmission should be implemented in populations at risk. (Funded by the Ministry of Science and Technology of China and others.).", "concepts": ["Virology", "Medicine", "Geography", "Computer science", "Telecommunications", "Physics", "Internal medicine", "Acoustics"], "domain": "physics"}
{"id": "https://openalex.org/W2120575449", "title": "Julia: A Fresh Approach to Numerical Computing", "abstract": "Bridging cultures that have often been distant, Julia combines expertise from the diverse fields of computer science and computational science to create a new approach to numerical computing. Julia is designed to be easy and fast and questions notions generally held to be “laws of nature\" by practitioners of numerical computing: \\beginlist \\item High-level dynamic programs have to be slow. \\item One must prototype in one language and then rewrite in another language for speed or deployment. \\item There are parts of a system appropriate for the programmer, and other parts that are best left untouched as they have been built by the experts. \\endlist We introduce the Julia programming language and its design---a dance between specialization and abstraction. Specialization allows for custom treatment. Multiple dispatch, a technique from computer science, picks the right algorithm for the right circumstance. Abstraction, which is what good computation is really about, recognizes what remains the same after differences are stripped away. Abstractions in mathematics are captured as code through another technique from computer science, generic programming. Julia shows that one can achieve machine performance without sacrificing human convenience.", "concepts": ["Computer science", "Programming language", "Theoretical computer science", "Computer network", "Philosophy", "Epistemology"], "domain": "materials_science"}
{"id": "https://openalex.org/W4383312437", "title": "A comprehensive AI policy education framework for university teaching and learning", "abstract": "Abstract This study aims to develop an AI education policy for higher education by examining the perceptions and implications of text generative AI technologies. Data was collected from 457 students and 180 teachers and staff across various disciplines in Hong Kong universities, using both quantitative and qualitative research methods. Based on the findings, the study proposes an AI Ecological Education Policy Framework to address the multifaceted implications of AI integration in university teaching and learning. This framework is organized into three dimensions: Pedagogical, Governance, and Operational. The Pedagogical dimension concentrates on using AI to improve teaching and learning outcomes, while the Governance dimension tackles issues related to privacy, security, and accountability. The Operational dimension addresses matters concerning infrastructure and training. The framework fosters a nuanced understanding of the implications of AI integration in academic settings, ensuring that stakeholders are aware of their responsibilities and can take appropriate actions accordingly.", "concepts": ["Sociology", "Knowledge management", "Engineering ethics", "Computer science", "Mathematics education", "Public relations", "Political science", "Psychology"], "domain": "psychology"}
{"id": "https://openalex.org/W4400837307", "title": "Quality Control to Reduce Appearance Defects at PT. Musical Instrument", "abstract": "This research was conducted at PT. Musical Instruments that aim to analyze quality control to reduce appearance defects in piano products on the assembling production line. The problem faced by the company is the high level of product defects which has an impact on decreasing quality and customer satisfaction. The research method used is Six sigma with a DMAIC (Define, Measure, Analyze, Improve, Control) approach. This type of research is quantitative, with data collected in the form of the number of production defects in pianos. To analyze the causes of defects, a fishbone diagram with 4M + 1E factors is used, namely Man, Machine, Method, Material, and Environment. The results of the analysis show that the main factors causing appearance defects in piano products include incompatibility with work methods, lack of worker training, use of non-standard materials, suboptimal jig conditions, and unsupportive working environment. Based on these findings, improvement proposals are given in the form of improving standard operating procedures, regular training for workers, the use of high-quality materials, regular maintenance and calibration of jigs, and improvement of work environment conditions. The implementation of this improvement proposal is expected to reduce the number of appearance defects in piano products, improve product quality, and meet the quality standards expected by PT. Musical instrument.", "concepts": ["Computer science", "Reliability engineering", "Manufacturing engineering", "Operations management", "Engineering", "Mathematics", "Artificial intelligence", "Mechanical engineering"], "domain": "economics"}
{"id": "https://openalex.org/W4395010444", "title": "ProTox 3.0: a webserver for the prediction of toxicity of chemicals", "abstract": "Abstract Interaction with chemicals, present in drugs, food, environments, and consumer goods, is an integral part of our everyday life. However, depending on the amount and duration, such interactions can also result in adverse effects. With the increase in computational methods, the in silico methods can offer significant benefits to both regulatory needs and requirements for risk assessments and the pharmaceutical industry to assess the safety profile of a chemical. Here, we present ProTox 3.0, which incorporates molecular similarity and machine-learning models for the prediction of 61 toxicity endpoints such as acute toxicity, organ toxicity, clinical toxicity, molecular-initiating events (MOE), adverse outcomes (Tox21) pathways, several other toxicological endpoints and toxicity off-targets. All the ProTox 3.0 models are validated on independent external sets and have shown strong performance. ProTox envisages itself as a complete, freely available computational platform for in silico toxicity prediction for toxicologists, regulatory agencies, computational chemists, and medicinal chemists. The ProTox 3.0 webserver is free and open to all users, and there is no login requirement and can be accessed via https://tox.charite.de. The web server takes a 2D chemical structure as input and reports the toxicological profile of the compound for each endpoint with a confidence score and overall toxicity radar plot and network plot.", "concepts": ["Biology", "Computational biology", "Toxicology", "Bioinformatics", "Pharmacology", "Biochemical engineering", "Computer science", "World Wide Web"], "domain": "computer_science"}
{"id": "https://openalex.org/W2884561390", "title": "Focal Loss for Dense Object Detection", "abstract": "The highest accuracy object detectors to date are based on a two-stage approach popularized by R-CNN, where a classifier is applied to a sparse set of candidate object locations. In contrast, one-stage detectors that are applied over a regular, dense sampling of possible object locations have the potential to be faster and simpler, but have trailed the accuracy of two-stage detectors thus far. In this paper, we investigate why this is the case. We discover that the extreme foreground-background class imbalance encountered during training of dense detectors is the central cause. We propose to address this class imbalance by reshaping the standard cross entropy loss such that it down-weights the loss assigned to well-classified examples. Our novel Focal Loss focuses training on a sparse set of hard examples and prevents the vast number of easy negatives from overwhelming the detector during training. To evaluate the effectiveness of our loss, we design and train a simple dense detector we call RetinaNet. Our results show that when trained with the focal loss, RetinaNet is able to match the speed of previous one-stage detectors while surpassing the accuracy of all existing state-of-the-art two-stage detectors. Code is at: https://github.com/facebookresearch/Detectron.", "concepts": ["Computer science", "Artificial intelligence", "Computer vision", "Telecommunications", "Programming language"], "domain": "biology"}
{"id": "https://openalex.org/W2311203695", "title": "MEGA7: Molecular Evolutionary Genetics Analysis Version 7.0 for Bigger Datasets", "abstract": "Abstract We present the latest version of the Molecular Evolutionary Genetics Analysis (M ega ) software, which contains many sophisticated methods and tools for phylogenomics and phylomedicine. In this major upgrade, M ega has been optimized for use on 64-bit computing systems for analyzing larger datasets. Researchers can now explore and analyze tens of thousands of sequences in M ega . The new version also provides an advanced wizard for building timetrees and includes a new functionality to automatically predict gene duplication events in gene family trees. The 64-bit M ega is made available in two interfaces: graphical and command line. The graphical user interface (GUI) is a native Microsoft Windows application that can also be used on Mac OS X. The command line M ega is available as native applications for Windows, Linux, and Mac OS X. They are intended for use in high-throughput and scripted analysis. Both versions are available from www.megasoftware.net free of charge.", "concepts": ["Biology", "Evolutionary biology", "Computational biology", "Genetics"], "domain": "environmental_science"}
{"id": "https://openalex.org/W4324046518", "title": "Chatting and cheating: Ensuring academic integrity in the era of ChatGPT", "abstract": "The use of artificial intelligence in academia is a hot topic in the education field. ChatGPT is an AI tool that offers a range of benefits, including increased student engagement, collaboration, and accessibility. However, is also raises concerns regarding academic honesty and plagiarism. This paper examines the opportunities and challenges of using ChatGPT in higher education, and discusses the potential risks and rewards of these tools. The paper also considers the difficulties of detecting and preventing academic dishonesty, and suggests strategies that universities can adopt to ensure ethical and responsible use of these tools. These strategies include developing policies and procedures, providing training and support, and using various methods to detect and prevent cheating. The paper concludes that while the use of AI in higher education presents both opportunities and challenges, universities can effectively address these concerns by taking a proactive and ethical approach to the use of these tools.", "concepts": ["Engineering ethics", "Public relations", "Psychology", "Political science", "Engineering", "Social psychology", "Mathematics", "Law"], "domain": "psychology"}
{"id": "https://openalex.org/W2890019883", "title": "Design and Mechanisms of Asymmetric Supercapacitors", "abstract": "Ongoing technological advances in diverse fields including portable electronics, transportation, and green energy are often hindered by the insufficient capability of energy-storage devices. By taking advantage of two different electrode materials, asymmetric supercapacitors can extend their operating voltage window beyond the thermodynamic decomposition voltage of electrolytes while enabling a solution to the energy storage limitations of symmetric supercapacitors. This review provides comprehensive knowledge to this field. We first look at the essential energy-storage mechanisms and performance evaluation criteria for asymmetric supercapacitors to understand the wide-ranging research conducted in this area. Then we move to the recent progress made for the design and fabrication of electrode materials and the overall structure of asymmetric supercapacitors in different categories. We also highlight several key scientific challenges and present our perspectives on enhancing the electrochemical performance of future asymmetric supercapacitors.", "concepts": ["Nanotechnology", "Chemistry", "Computer science", "Materials science", "Physics", "Computer security", "Physical chemistry", "Quantum mechanics"], "domain": "physics"}
{"id": "https://openalex.org/W4401916766", "title": "A comprehensive electron wavefunction analysis toolbox for chemists, Multiwfn", "abstract": "Analysis of electron wavefunction is a key component of quantum chemistry investigations and is indispensable for the practical research of many chemical problems. After more than ten years of active development, the wavefunction analysis program Multiwfn has accumulated very rich functions, and its application scope has covered numerous aspects of theoretical chemical research, including charge distribution, chemical bond, electron localization and delocalization, aromaticity, intramolecular and intermolecular interactions, electronic excitation, and response property. This article systematically introduces the features and functions of the latest version of Multiwfn and provides many representative examples. Through this article, readers will be able to fully understand the characteristics and recognize the unique value of Multiwfn. The source code and precompiled executable files of Multiwfn, as well as the manual containing a detailed introduction to theoretical backgrounds and very rich tutorials, can all be downloaded for free from the Multiwfn website (http://sobereva.com/multiwfn).", "concepts": ["Computer science", "Chemistry", "Physics", "Quantum mechanics", "Programming language", "Evolutionary biology", "Biology"], "domain": "chemistry"}
{"id": "https://openalex.org/W2575750030", "title": "Fast and accurate de novo genome assembly from long uncorrected reads", "abstract": "The assembly of long reads from Pacific Biosciences and Oxford Nanopore Technologies typically requires resource-intensive error-correction and consensus-generation steps to obtain high-quality assemblies. We show that the error-correction step can be omitted and that high-quality consensus sequences can be generated efficiently with a SIMD-accelerated, partial-order alignment-based, stand-alone consensus module called Racon. Based on tests with PacBio and Oxford Nanopore data sets, we show that Racon coupled with miniasm enables consensus genomes with similar or better quality than state-of-the-art methods while being an order of magnitude faster.", "concepts": ["Biology", "Computer science", "Computational biology", "Genetics", "Philosophy", "Epistemology"], "domain": "materials_science"}
{"id": "https://openalex.org/W3136918052", "title": "UniProt: a worldwide hub of protein knowledge", "abstract": "The UniProt Knowledgebase is a collection of sequences and annotations for over 120 million proteins across all branches of life. Detailed annotations extracted from the literature by expert curators have been collected for over half a million of these proteins. These annotations are supplemented by annotations provided by rule based automated systems, and those imported from other resources. In this article we describe significant updates that we have made over the last 2 years to the resource. We have greatly expanded the number of Reference Proteomes that we provide and in particular we have focussed on improving the number of viral Reference Proteomes. The UniProt website has been augmented with new data visualizations for the subcellular localization of proteins as well as their structure and interactions. UniProt resources are available under a CC-BY (4.0) license via the web at https://www.uniprot.org/.", "concepts": ["Biology", "Computational biology", "World Wide Web", "Bioinformatics", "Computer science", "Genetics", "Computer network", "Operating system"], "domain": "biology"}
{"id": "https://openalex.org/W2089277140", "title": "Acta Palaeontologica Polonica", "abstract": "Caudipteryx zoui is a small enigmatic theropod known from the Early Cretaceous Yixian Formation of the People's Republic of China. From the time of its initial description, this taxon has stimulated a great deal of ongoing debate regarding the phylogenetic relationship between non-avialan theropods and birds (Avialae) because it preserves structures that have been uncontroversially accepted as feathers (albeit aerodynamically unsuitable for flight). However, it has also been proposed that both the relative proportions of the hind limb bones (when compared with overall leg length), and the position of the center of mass in Caudipteryx are more similar to those seen in extant cusorial birds than they are to other non-avialan theropod dinosaurs. This conclusion has been used to imply that Caudipteryx may not have been correctly interpreted as a feathered non-avialan theropod, but instead that this taxon represents some kind of flightless bird. We review the evidence for this claim at the level of both the included fossil specimen data, and in terms of the validity of the results presented. There is no reason-phylogenetic, morphometric or otherwise-to conclude that Caudipteryx is anything other than a small non-avialan theropod dinosaur.", "concepts": ["Zoology", "Paleontology", "Biology", "Geography", "Geology"], "domain": "engineering"}
{"id": "https://openalex.org/W4381799391", "title": "Global, regional, and national burden of diabetes from 1990 to 2021, with projections of prevalence to 2050: a systematic analysis for the Global Burden of Disease Study 2021", "abstract": "Background: Diabetes is one of the leading causes of death and disability worldwide, and affects people regardless of country, age group, or sex. Using the most recent evidentiary and analytical framework from the Global Burden of Diseases, Injuries, and Risk Factors Study (GBD), we produced location-specific, age-specific, and sex-specific estimates of diabetes prevalence and burden from 1990 to 2021, the proportion of type 1 and type 2 diabetes in 2021, the proportion of the type 2 diabetes burden attributable to selected risk factors, and projections of diabetes prevalence through 2050. Methods: Estimates of diabetes prevalence and burden were computed in 204 countries and territories, across 25 age groups, for males and females separately and combined; these estimates comprised lost years of healthy life, measured in disability-adjusted life-years (DALYs; defined as the sum of years of life lost [YLLs] and years lived with disability [YLDs]). We used the Cause of Death Ensemble model (CODEm) approach to estimate deaths due to diabetes, incorporating 25 666 location-years of data from vital registration and verbal autopsy reports in separate total (including both type 1 and type 2 diabetes) and type-specific models. Other forms of diabetes, including gestational and monogenic diabetes, were not explicitly modelled. Total and type 1 diabetes prevalence was estimated by use of a Bayesian meta-regression modelling tool, DisMod-MR 2.1, to analyse 1527 location-years of data from the scientific literature, survey microdata, and insurance claims; type 2 diabetes estimates were computed by subtracting type 1 diabetes from total estimates. Mortality and prevalence estimates, along with standard life expectancy and disability weights, were used to calculate YLLs, YLDs, and DALYs. When appropriate, we extrapolated estimates to a hypothetical population with a standardised age structure to allow comparison in populations with different age structures. We used the comparative risk assessment framework to estimate the risk-attributable type 2 diabetes burden for 16 risk factors falling under risk categories including environmental and occupational factors, tobacco use, high alcohol use, high body-mass index (BMI), dietary factors, and low physical activity. Using a regression framework, we forecast type 1 and type 2 diabetes prevalence through 2050 with Socio-demographic Index (SDI) and high BMI as predictors, respectively. Findings: In 2021, there were 529 million (95% uncertainty interval [UI] 500–564) people living with diabetes worldwide, and the global age-standardised total diabetes prevalence was 6·1% (5·8–6·5). At the super-region level, the highest age-standardised rates were observed in north Africa and the Middle East (9·3% [8·7–9·9]) and, at the regional level, in Oceania (12·3% [11·5–13·0]). Nationally, Qatar had the world's highest age-specific prevalence of diabetes, at 76·1% (73·1–79·5) in individuals aged 75–79 years. Total diabetes prevalence—especially among older adults—primarily reflects type 2 diabetes, which in 2021 accounted for 96·0% (95·1–96·8) of diabetes cases and 95·4% (94·9–95·9) of diabetes DALYs worldwide. In 2021, 52·2% (25·5–71·8) of global type 2 diabetes DALYs were attributable to high BMI. The contribution of high BMI to type 2 diabetes DALYs rose by 24·3% (18·5–30·4) worldwide between 1990 and 2021. By 2050, more than 1·31 billion (1·22–1·39) people are projected to have diabetes, with expected age-standardised total diabetes prevalence rates greater than 10% in two super-regions: 16·8% (16·1–17·6) in north Africa and the Middle East and 11·3% (10·8–11·9) in Latin America and Caribbean. By 2050, 89 (43·6%) of 204 countries and territories will have an age-standardised rate greater than 10%. Interpretation: Diabetes remains a substantial public health issue. Type 2 diabetes, which makes up the bulk of diabetes cases, is largely preventable and, in some cases, potentially reversible if identified and managed early in the disease course. However, all evidence indicates that diabetes prevalence is increasing worldwide, primarily due to a rise in obesity caused by multiple factors. Preventing and controlling type 2 diabetes remains an ongoing challenge. It is essential to better understand disparities in risk factor profiles and diabetes burden across populations, to inform strategies to successfully control diabetes risk factors within the context of multiple and complex drivers. Funding: Bill & Melinda Gates Foundation.", "concepts": ["Medicine", "Environmental health", "Intensive care medicine", "Internal medicine", "Political science", "Pathology", "Endocrinology", "Law"], "domain": "medicine"}
{"id": "https://openalex.org/W2166152751", "title": "An update of the Angiosperm Phylogeny Group classification for the orders and families of flowering plants: APG IV", "abstract": "An update of the Angiosperm Phylogeny Group (APG) classification of the orders and families of angiosperms is presented. Several new orders are recognized: Boraginales, Dilleniales, Icacinales, Metteniusiales and Vahliales. This brings the total number of orders and families recognized in the APG system to 64 and 416, respectively. We propose two additional informal major clades, superrosids and superasterids, that each comprise the additional orders that are included in the larger clades dominated by the rosids and asterids. Families that made up potentially monofamilial orders, Dasypogonaceae and Sabiaceae, are instead referred to Arecales and Proteales, respectively. Two parasitic families formerly of uncertain positions are now placed: Cynomoriaceae in Saxifragales and Apodanthaceae in Cucurbitales. Although there is evidence that some families recognized in APG III are not monophyletic, we make no changes in Dioscoreales and Santalales relative to APG III and leave some genera in Lamiales unplaced (e.g. Peltanthera). These changes in familial circumscription and recognition have all resulted from new results published since APG III, except for some changes simply due to nomenclatural issues, which include substituting Asphodelaceae for Xanthorrhoeaceae (Asparagales) and Francoaceae for Melianthaceae (Geraniales); however, in Francoaceae we also include Bersamaceae, Ledocarpaceae, Rhynchothecaceae and Vivianiaceae. Other changes to family limits are not drastic or numerous and are mostly focused on some members of the lamiids, especially the former Icacinaceae that have long been problematic with several genera moved to the formerly monogeneric Metteniusaceae, but minor changes in circumscription include Aristolochiaceae (now including Lactoridaceae and Hydnoraceae; Aristolochiales), Maundiaceae (removed from Juncaginaceae; Alismatales), Restionaceae (now re-including Anarthriaceae and Centrolepidaceae; Poales), Buxaceae (now including Haptanthaceae; Buxales), Peraceae (split from Euphorbiaceae; Malpighiales), recognition of Petenaeaceae (Huerteales), Kewaceae, Limeaceae, Macarthuriaceae and Microteaceae (all Caryophyllales), Petiveriaceae split from Phytolaccaceae (Caryophyllales), changes to the generic composition of Ixonanthaceae and Irvingiaceae (with transfer of Allantospermum from the former to the latter; Malpighiales), transfer of Pakaraimaea (formerly Dipterocarpaceae) to Cistaceae (Malvales), transfer of Borthwickia, Forchhammeria, Stixis and Tirania (formerly all Capparaceae) to Resedaceae (Brassicales), Nyssaceae split from Cornaceae (Cornales), Pteleocarpa moved to Gelsemiaceae (Gentianales), changes to the generic composition of Gesneriaceae (Sanango moved from Loganiaceae) and Orobanchaceae (now including Lindenbergiaceae and Rehmanniaceae) and recognition of Mazaceae distinct from Phrymaceae (all Lamiales).", "concepts": ["Biology", "Botany", "Zoology", "Evolutionary biology", "Genetics", "Artificial intelligence", "Computer science"], "domain": "environmental_science"}
{"id": "https://openalex.org/W4393858312", "title": "Global burden of 288 causes of death and life expectancy decomposition in 204 countries and territories and 811 subnational locations, 1990–2021: a systematic analysis for the Global Burden of Disease Study 2021", "abstract": "Background: Regular, detailed reporting on population health by underlying cause of death is fundamental for public health decision making. Cause-specific estimates of mortality and the subsequent effects on life expectancy worldwide are valuable metrics to gauge progress in reducing mortality rates. These estimates are particularly important following large-scale mortality spikes, such as the COVID-19 pandemic. When systematically analysed, mortality rates and life expectancy allow comparisons of the consequences of causes of death globally and over time, providing a nuanced understanding of the effect of these causes on global populations. Methods: The Global Burden of Diseases, Injuries, and Risk Factors Study (GBD) 2021 cause-of-death analysis estimated mortality and years of life lost (YLLs) from 288 causes of death by age-sex-location-year in 204 countries and territories and 811 subnational locations for each year from 1990 until 2021. The analysis used 56 604 data sources, including data from vital registration and verbal autopsy as well as surveys, censuses, surveillance systems, and cancer registries, among others. As with previous GBD rounds, cause-specific death rates for most causes were estimated using the Cause of Death Ensemble model—a modelling tool developed for GBD to assess the out-of-sample predictive validity of different statistical models and covariate permutations and combine those results to produce cause-specific mortality estimates—with alternative strategies adapted to model causes with insufficient data, substantial changes in reporting over the study period, or unusual epidemiology. YLLs were computed as the product of the number of deaths for each cause-age-sex-location-year and the standard life expectancy at each age. As part of the modelling process, uncertainty intervals (UIs) were generated using the 2·5th and 97·5th percentiles from a 1000-draw distribution for each metric. We decomposed life expectancy by cause of death, location, and year to show cause-specific effects on life expectancy from 1990 to 2021. We also used the coefficient of variation and the fraction of population affected by 90% of deaths to highlight concentrations of mortality. Findings are reported in counts and age-standardised rates. Methodological improvements for cause-of-death estimates in GBD 2021 include the expansion of under-5-years age group to include four new age groups, enhanced methods to account for stochastic variation of sparse data, and the inclusion of COVID-19 and other pandemic-related mortality—which includes excess mortality associated with the pandemic, excluding COVID-19, lower respiratory infections, measles, malaria, and pertussis. For this analysis, 199 new country-years of vital registration cause-of-death data, 5 country-years of surveillance data, 21 country-years of verbal autopsy data, and 94 country-years of other data types were added to those used in previous GBD rounds. Findings: The leading causes of age-standardised deaths globally were the same in 2019 as they were in 1990; in descending order, these were, ischaemic heart disease, stroke, chronic obstructive pulmonary disease, and lower respiratory infections. In 2021, however, COVID-19 replaced stroke as the second-leading age-standardised cause of death, with 94·0 deaths (95% UI 89·2–100·0) per 100 000 population. The COVID-19 pandemic shifted the rankings of the leading five causes, lowering stroke to the third-leading and chronic obstructive pulmonary disease to the fourth-leading position. In 2021, the highest age-standardised death rates from COVID-19 occurred in sub-Saharan Africa (271·0 deaths [250·1–290·7] per 100 000 population) and Latin America and the Caribbean (195·4 deaths [182·1–211·4] per 100 000 population). The lowest age-standardised death rates from COVID-19 were in the high-income super-region (48·1 deaths [47·4–48·8] per 100 000 population) and southeast Asia, east Asia, and Oceania (23·2 deaths [16·3–37·2] per 100 000 population). Globally, life expectancy steadily improved between 1990 and 2019 for 18 of the 22 investigated causes. Decomposition of global and regional life expectancy showed the positive effect that reductions in deaths from enteric infections, lower respiratory infections, stroke, and neonatal deaths, among others have contributed to improved survival over the study period. However, a net reduction of 1·6 years occurred in global life expectancy between 2019 and 2021, primarily due to increased death rates from COVID-19 and other pandemic-related mortality. Life expectancy was highly variable between super-regions over the study period, with southeast Asia, east Asia, and Oceania gaining 8·3 years (6·7–9·9) overall, while having the smallest reduction in life expectancy due to COVID-19 (0·4 years). The largest reduction in life expectancy due to COVID-19 occurred in Latin America and the Caribbean (3·6 years). Additionally, 53 of the 288 causes of death were highly concentrated in locations with less than 50% of the global population as of 2021, and these causes of death became progressively more concentrated since 1990, when only 44 causes showed this pattern. The concentration phenomenon is discussed heuristically with respect to enteric and lower respiratory infections, malaria, HIV/AIDS, neonatal disorders, tuberculosis, and measles. Interpretation: Long-standing gains in life expectancy and reductions in many of the leading causes of death have been disrupted by the COVID-19 pandemic, the adverse effects of which were spread unevenly among populations. Despite the pandemic, there has been continued progress in combatting several notable causes of death, leading to improved global life expectancy over the study period. Each of the seven GBD super-regions showed an overall improvement from 1990 and 2021, obscuring the negative effect in the years of the pandemic. Additionally, our findings regarding regional variation in causes of death driving increases in life expectancy hold clear policy utility. Analyses of shifting mortality trends reveal that several causes, once widespread globally, are now increasingly concentrated geographically. These changes in mortality concentration, alongside further investigation of changing risks, interventions, and relevant policy, present an important opportunity to deepen our understanding of mortality-reduction strategies. Examining patterns in mortality concentration might reveal areas where successful public health interventions have been implemented. Translating these successes to locations where certain causes of death remain entrenched can inform policies that work to improve life expectancy for people everywhere. Funding: Bill & Melinda Gates Foundation.", "concepts": ["Environmental health", "Medicine", "Development economics", "Economics", "Pathology"], "domain": "economics"}
{"id": "https://openalex.org/W4390506881", "title": "Discovering biomarkers associated and predicting cardiovascular disease with high accuracy using a novel nexus of machine learning techniques for precision medicine", "abstract": "Abstract Personalized interventions are deemed vital given the intricate characteristics, advancement, inherent genetic composition, and diversity of cardiovascular diseases (CVDs). The appropriate utilization of artificial intelligence (AI) and machine learning (ML) methodologies can yield novel understandings of CVDs, enabling improved personalized treatments through predictive analysis and deep phenotyping. In this study, we proposed and employed a novel approach combining traditional statistics and a nexus of cutting-edge AI/ML techniques to identify significant biomarkers for our predictive engine by analyzing the complete transcriptome of CVD patients. After robust gene expression data pre-processing, we utilized three statistical tests (Pearson correlation, Chi-square test, and ANOVA) to assess the differences in transcriptomic expression and clinical characteristics between healthy individuals and CVD patients. Next, the recursive feature elimination classifier assigned rankings to transcriptomic features based on their relation to the case–control variable. The top ten percent of commonly observed significant biomarkers were evaluated using four unique ML classifiers (Random Forest, Support Vector Machine, Xtreme Gradient Boosting Decision Trees, and k-Nearest Neighbors). After optimizing hyperparameters, the ensembled models, which were implemented using a soft voting classifier, accurately differentiated between patients and healthy individuals. We have uncovered 18 transcriptomic biomarkers that are highly significant in the CVD population that were used to predict disease with up to 96% accuracy. Additionally, we cross-validated our results with clinical records collected from patients in our cohort. The identified biomarkers served as potential indicators for early detection of CVDs. With its successful implementation, our newly developed predictive engine provides a valuable framework for identifying patients with CVDs based on their biomarker profiles.", "concepts": ["Artificial intelligence", "Machine learning", "Computer science", "Medicine", "Mathematics", "Geometry", "Environmental health"], "domain": "mathematics"}
{"id": "https://openalex.org/W4381681857", "title": "A multisociety Delphi consensus statement on new fatty liver disease nomenclature", "abstract": "The principal limitations of the terms NAFLD and NASH are the reliance on exclusionary confounder terms and the use of potentially stigmatising language. This study set out to determine if content experts and patient advocates were in favor of a change in nomenclature and/or definition. A modified Delphi process was led by three large pan-national liver associations. The consensus was defined a priori as a supermajority (67%) vote. An independent committee of experts external to the nomenclature process made the final recommendation on the acronym and its diagnostic criteria. A total of 236 panelists from 56 countries participated in 4 online surveys and 2 hybrid meetings. Response rates across the 4 survey rounds were 87%, 83%, 83%, and 78%, respectively. Seventy-four percent of respondents felt that the current nomenclature was sufficiently flawed to consider a name change. The terms \"nonalcoholic\" and \"fatty\" were felt to be stigmatising by 61% and 66% of respondents, respectively. Steatotic liver disease was chosen as an overarching term to encompass the various aetiologies of steatosis. The term steatohepatitis was felt to be an important pathophysiological concept that should be retained. The name chosen to replace NAFLD was metabolic dysfunction-Associated steatotic liver disease. There was consensus to change the definition to include the presence of at least 1 of 5 cardiometabolic risk factors. Those with no metabolic parameters and no known cause were deemed to have cryptogenic steatotic liver disease. A new category, outside pure metabolic dysfunction-Associated steatotic liver disease, termed metabolic and alcohol related/associated liver disease (MetALD), was selected to describe those with metabolic dysfunction-Associated steatotic liver disease, who consume greater amounts of alcohol per week (140-350 g/wk and 210-420 g/wk for females and males, respectively). The new nomenclature and diagnostic criteria are widely supported and nonstigmatising, and can improve awareness and patient identification.", "concepts": ["Medicine", "Internal medicine", "Political science", "Biology", "Zoology", "Law"], "domain": "social_sciences"}
{"id": "https://openalex.org/W4324129606", "title": "Data quality in online human-subjects research: Comparisons between MTurk, Prolific, CloudResearch, Qualtrics, and SONA", "abstract": "With the proliferation of online data collection in human-subjects research, concerns have been raised over the presence of inattentive survey participants and non-human respondents (bots). We compared the quality of the data collected through five commonly used platforms. Data quality was indicated by the percentage of participants who meaningfully respond to the researcher’s question (high quality) versus those who only contribute noise (low quality). We found that compared to MTurk, Qualtrics, or an undergraduate student sample (i.e., SONA), participants on Prolific and CloudResearch were more likely to pass various attention checks, provide meaningful answers, follow instructions, remember previously presented information, have a unique IP address and geolocation, and work slowly enough to be able to read all the items. We divided the samples into high- and low-quality respondents and computed the cost we paid per high-quality respondent. Prolific ($1.90) and CloudResearch ($2.00) were cheaper than MTurk ($4.36) and Qualtrics ($8.17). SONA cost $0.00, yet took the longest to collect the data.", "concepts": ["Computer science", "Psychology", "World Wide Web", "Marketing", "Business", "Political science", "Philosophy", "Epistemology"], "domain": "psychology"}
{"id": "https://openalex.org/W2485420366", "title": "GLEAM v3: satellite-based land evaporation and root-zone soil moisture", "abstract": "<strong class=\"journal-contentHeaderColor\">Abstract.</strong> The Global Land Evaporation Amsterdam Model (GLEAM) is a set of algorithms dedicated to the estimation of terrestrial evaporation and root-zone soil moisture from satellite data. Ever since its development in 2011, the model has been regularly revised, aiming at the optimal incorporation of new satellite-observed geophysical variables, and improving the representation of physical processes. In this study, the next version of this model (v3) is presented. Key changes relative to the previous version include (1) a revised formulation of the evaporative stress, (2) an optimized drainage algorithm, and (3) a new soil moisture data assimilation system. GLEAM v3 is used to produce three new data sets of terrestrial evaporation and root-zone soil moisture, including a 36-year data set spanning 1980–2015, referred to as v3a (based on satellite-observed soil moisture, vegetation optical depth and snow-water equivalent, reanalysis air temperature and radiation, and a multi-source precipitation product), and two satellite-based data sets. The latter share most of their forcing, except for the vegetation optical depth and soil moisture, which are based on observations from different passive and active C- and L-band microwave sensors (European Space Agency Climate Change Initiative, ESA CCI) for the v3b data set (spanning 2003–2015) and observations from the Soil Moisture and Ocean Salinity (SMOS) satellite in the v3c data set (spanning 2011–2015). Here, these three data sets are described in detail, compared against analogous data sets generated using the previous version of GLEAM (v2), and validated against measurements from 91 eddy-covariance towers and 2325 soil moisture sensors across a broad range of ecosystems. Results indicate that the quality of the v3 soil moisture is consistently better than the one from v2: average correlations against in situ surface soil moisture measurements increase from 0.61 to 0.64 in the case of the v3a data set and the representation of soil moisture in the second layer improves as well, with correlations increasing from 0.47 to 0.53. Similar improvements are observed for the v3b and c data sets. Despite regional differences, the quality of the evaporation fluxes remains overall similar to the one obtained using the previous version of GLEAM, with average correlations against eddy-covariance measurements ranging between 0.78 and 0.81 for the different data sets. These global data sets of terrestrial evaporation and root-zone soil moisture are now openly available at <a href=\"www.GLEAM.eu\" target=\"_blank\">www.GLEAM.eu</a> and may be used for large-scale hydrological applications, climate studies, or research on land–atmosphere feedbacks.", "concepts": ["Environmental science", "Soil science", "Atmospheric sciences", "Meteorology", "Geology", "Geography", "Geotechnical engineering", "Physics"], "domain": "engineering"}
{"id": "https://openalex.org/W2981096252", "title": "A Vision of 6G Wireless Systems: Applications, Trends, Technologies, and Open Research Problems", "abstract": "The ongoing deployment of 5G cellular systems is continuously exposing the inherent limitations of this system, compared to its original premise as an enabler for Internet of Everything applications. These 5G drawbacks are spurring worldwide activities focused on defining the next-generation 6G wireless system that can truly integrate far-reaching applications ranging from autonomous systems to extended reality. Despite recent 6G initiatives (one example is the 6Genesis project in Finland), the fundamental architectural and performance components of 6G remain largely undefined. In this article, we present a holistic, forward-looking vision that defines the tenets of a 6G system. We opine that 6G will not be a mere exploration of more spectrum at high-frequency bands, but it will rather be a convergence of upcoming technological trends driven by exciting, underlying services. In this regard, we first identify the primary drivers of 6G systems, in terms of applications and accompanying technological trends. Then, we propose a new set of service classes and expose their target 6G performance requirements. We then identify the enabling technologies for the introduced 6G services and outline a comprehensive research agenda that leverages those technologies. We conclude by providing concrete recommendations for the roadmap toward 6G. Ultimately, the intent of this article is to serve as a basis for stimulating more out-of-the-box research around 6G.", "concepts": ["Computer science", "Telecommunications", "Data science", "World Wide Web", "Business", "Marketing", "Psychology", "Philosophy"], "domain": "psychology"}
{"id": "https://openalex.org/W4392349824", "title": "Antimicrobial resistance: Impacts, challenges, and future prospects", "abstract": "Antimicrobial resistance (AMR) is a critical global health issue driven by antibiotic misuse and overuse in various sectors, leading to the emergence of resistant microorganisms. The history of AMR dates back to the discovery of penicillin, with the rise of multidrug-resistant pathogens posing significant challenges to healthcare systems worldwide. The misuse of antibiotics in human and animal health, as well as in agriculture, contributes to the spread of resistance genes, creating a \"Silent Pandemic\" that could surpass other causes of mortality by 2050. AMR affects both humans and animals, with resistant pathogens posing challenges in treating infections. Various mechanisms, such as enzymatic modification and biofilm formation, enable microbes to withstand the effects of antibiotics. The lack of effective antibiotics threatens routine medical procedures and could lead to millions of deaths annually if left unchecked. The economic impact of AMR is substantial, with projected losses in the trillions of dollars and significant financial burdens on healthcare systems and agriculture. Artificial intelligence is being explored as a tool to combat AMR by improving diagnostics and treatment strategies, although challenges such as data quality and algorithmic biases exist. To address AMR effectively, a One Health approach that considers human, animal, and environmental factors is crucial. This includes enhancing surveillance systems, promoting stewardship programs, and investing in research and development for new antimicrobial options. Public awareness, education, and international collaboration are essential for combating AMR and preserving the efficacy of antibiotics for future generations.", "concepts": ["Business", "Intensive care medicine", "Risk analysis (engineering)", "Biotechnology", "Medicine", "Economic growth", "Biology", "Economics"], "domain": "economics"}
{"id": "https://openalex.org/W4317910584", "title": "ChatGPT: Bullshit spewer or the end of traditional assessments in higher education?", "abstract": "ChatGPT is the world’s most advanced chatbot thus far. Unlike other chatbots, it can create impressive prose within seconds, and it has created much hype and doomsday predictions when it comes to student assessment in higher education and a host of other matters. ChatGPT is a state-of-the-art language model (a variant of OpenAI’s Generative Pretrained Transformer (GPT) language model) designed to generate text that can be indistinguishable from text written by humans. It can engage in conversation with users in a seemingly natural and intuitive way. In this article, we briefly tell the story of OpenAI, the organisation behind ChatGPT. We highlight the fundamental change from a not-for-profit organisation to a commercial business model. In terms of our methods, we conducted an extensive literature review and experimented with this artificial intelligence (AI) software. Our literature review shows our review to be amongst the first peer-reviewed academic journal articles to explore ChatGPT and its relevance for higher education (especially assessment, learning and teaching). After a description of ChatGPT’s functionality and a summary of its strengths and limitations, we focus on the technology’s implications for higher education and discuss what is the future of learning, teaching and assessment in higher education in the context of AI chatbots such as ChatGPT. We position ChatGPT in the context of current Artificial Intelligence in Education (AIEd) research, discuss student-facing, teacher-facing and system-facing applications, and analyse opportunities and threats. We conclude the article with recommendations for students, teachers and higher education institutions. Many of them focus on assessment.", "concepts": ["Computer science", "Engineering ethics", "Artificial intelligence", "Pedagogy", "Psychology", "Engineering", "Political science", "Paleontology"], "domain": "social_sciences"}
{"id": "https://openalex.org/W4381893710", "title": "A multisociety Delphi consensus statement on new fatty liver disease nomenclature", "abstract": "The principal limitations of the terms NAFLD and NASH are the reliance on exclusionary confounder terms and the use of potentially stigmatising language. This study set out to determine if content experts and patient advocates were in favour of a change in nomenclature and/or definition. A modified Delphi process was led by three large pan-national liver associations. The consensus was defined a priori as a supermajority (67%) vote. An independent committee of experts external to the nomenclature process made the final recommendation on the acronym and its diagnostic criteria. A total of 236 panellists from 56 countries participated in 4 online surveys and 2 hybrid meetings. Response rates across the 4 survey rounds were 87%, 83%, 83%, and 78%, respectively. Seventy-four percent of respondents felt that the current nomenclature was sufficiently flawed to consider a name change. The terms “nonalcoholic” and “fatty” were felt to be stigmatising by 61% and 66% of respondents, respectively. Steatotic liver disease was chosen as an overarching term to encompass the various aetiologies of steatosis. The term steatohepatitis was felt to be an important pathophysiological concept that should be retained. The name chosen to replace NAFLD was metabolic dysfunction–associated steatotic liver disease (MASLD). There was consensus to change the definition to include the presence of at least 1 of 5 cardiometabolic risk factors. Those with no metabolic parameters and no known cause were deemed to have cryptogenic steatotic liver disease. A new category, outside pure metabolic dysfunction–associated steatotic liver disease, termed metabolic and alcohol related/associated liver disease (MetALD), was selected to describe those with metabolic dysfunction–associated steatotic liver disease, who consume greater amounts of alcohol per week (140–350 g/wk and 210–420 g/wk for females and males, respectively). The new nomenclature and diagnostic criteria are widely supported and non-stigmatising, and can improve awareness and patient identification.", "concepts": ["Medicine", "Internal medicine", "Biology", "Computer science", "Zoology", "Political science", "Law", "Programming language"], "domain": "social_sciences"}
{"id": "https://openalex.org/W3113178943", "title": "Global Burden of Cardiovascular Diseases and Risk Factors, 1990–2019", "abstract": "Cardiovascular diseases (CVDs), principally ischemic heart disease (IHD) and stroke, are the leading cause of global mortality and a major contributor to disability. This paper reviews the magnitude of total CVD burden, including 13 underlying causes of cardiovascular death and 9 related risk factors, using estimates from the Global Burden of Disease (GBD) Study 2019. GBD, an ongoing multinational collaboration to provide comparable and consistent estimates of population health over time, used all available population-level data sources on incidence, prevalence, case fatality, mortality, and health risks to produce estimates for 204 countries and territories from 1990 to 2019. Prevalent cases of total CVD nearly doubled from 271 million (95% uncertainty interval [UI]: 257 to 285 million) in 1990 to 523 million (95% UI: 497 to 550 million) in 2019, and the number of CVD deaths steadily increased from 12.1 million (95% UI:11.4 to 12.6 million) in 1990, reaching 18.6 million (95% UI: 17.1 to 19.7 million) in 2019. The global trends for disability-adjusted life years (DALYs) and years of life lost also increased significantly, and years lived with disability doubled from 17.7 million (95% UI: 12.9 to 22.5 million) to 34.4 million (95% UI:24.9 to 43.6 million) over that period. The total number of DALYs due to IHD has risen steadily since 1990, reaching 182 million (95% UI: 170 to 194 million) DALYs, 9.14 million (95% UI: 8.40 to 9.74 million) deaths in the year 2019, and 197 million (95% UI: 178 to 220 million) prevalent cases of IHD in 2019. The total number of DALYs due to stroke has risen steadily since 1990, reaching 143 million (95% UI: 133 to 153 million) DALYs, 6.55 million (95% UI: 6.00 to 7.02 million) deaths in the year 2019, and 101 million (95% UI: 93.2 to 111 million) prevalent cases of stroke in 2019. Cardiovascular diseases remain the leading cause of disease burden in the world. CVD burden continues its decades-long rise for almost all countries outside high-income countries, and alarmingly, the age-standardized rate of CVD has begun to rise in some locations where it was previously declining in high-income countries. There is an urgent need to focus on implementing existing cost-effective policies and interventions if the world is to meet the targets for Sustainable Development Goal 3 and achieve a 30% reduction in premature mortality due to noncommunicable diseases.", "concepts": ["Medicine", "Demography", "Environmental health", "Physics", "Nursing", "Pathology", "Sociology", "Optics"], "domain": "physics"}
{"id": "https://openalex.org/W4320495408", "title": "Chatting about ChatGPT: how may AI and GPT impact academia and libraries?", "abstract": "Purpose This paper aims to provide an overview of key definitions related to ChatGPT, a public tool developed by OpenAI, and its underlying technology, Generative Pretrained Transformer (GPT). Design/methodology/approach This paper includes an interview with ChatGPT on its potential impact on academia and libraries. The interview discusses the benefits of ChatGPT such as improving search and discovery, reference and information services; cataloging and metadata generation; and content creation, as well as the ethical considerations that need to be taken into account, such as privacy and bias. Findings ChatGPT has considerable power to advance academia and librarianship in both anxiety-provoking and exciting new ways. However, it is important to consider how to use this technology responsibly and ethically, and to uncover how we, as professionals, can work alongside this technology to improve our work, rather than to abuse it or allow it to abuse us in the race to create new scholarly knowledge and educate future professionals. Originality/value This paper discusses the history and technology of GPT, including its generative pretrained transformer model, its ability to perform a wide range of language-based tasks and how ChatGPT uses this technology to function as a sophisticated chatbot.", "concepts": ["Computer science", "World Wide Web", "Knowledge management", "Data science", "Psychology", "Artificial intelligence", "Social psychology"], "domain": "psychology"}
{"id": "https://openalex.org/W2801702920", "title": "Best Practices for Developing and Validating Scales for Health, Social, and Behavioral Research: A Primer", "abstract": "Scale development and validation are critical to much of the work in the health, social, and behavioral sciences. However, the constellation of techniques required for scale development and evaluation can be onerous, jargon-filled, unfamiliar, and resource-intensive. Further, it is often not a part of graduate training. Therefore, our goal was to concisely review the process of scale development in as straightforward a manner as possible, both to facilitate the development of new, valid, and reliable scales, and to help improve existing ones. To do this, we have created a primer for best practices for scale development in measuring complex phenomena. This is not a systematic review, but rather the amalgamation of technical literature and lessons learned from our experiences spent creating or adapting a number of scales over the past several decades. We identified three phases that span nine steps. In the first phase, items are generated and the validity of their content is assessed. In the second phase, the scale is constructed. Steps in scale construction include pre-testing the questions, administering the survey, reducing the number of items, and understanding how many factors the scale captures. In the third phase, scale evaluation, the number of dimensions is tested, reliability is tested, and validity is assessed. We have also added examples of best practices to each step. In sum, this primer will equip both scientists and practitioners to understand the ontology and methodology of scale development and validation, thereby facilitating the advancement of our understanding of a range of health, social, and behavioral outcomes.", "concepts": ["Computer science", "Data science", "Management science", "Psychology", "Engineering", "Computer network", "Developmental psychology", "Philosophy"], "domain": "physics"}
{"id": "https://openalex.org/W3183857127", "title": "2019 ESC/EAS Guidelines for the management of dyslipidaemias: lipid modification to reduce cardiovascular risk", "abstract": "The ESC/EAS Guidelines represent the views of the ESC and EAS, and were produced after careful consideration of the scientific and medical knowledge, and the evidence available at the time of their publication.The ESC and EAS is not responsible in the event of any contradiction, discrepancy, and/or ambiguity between the ESC/EAS Guidelines and any other official recommendations or guidelines issued by the relevant public health authorities, in particular in relation to good use of healthcare or therapeutic strategies.Health professionals are encouraged to take the ESC/EAS Guidelines fully into account when exercising their clinical judgment, as well as in the determination and the implementation of preventive, diagnostic, or therapeutic medical strategies; however, the ESC/EAS Guidelines do not override, in any way whatsoever, the individual responsibility of health professionals to make appropriate and accurate decisions in consideration of each patient's health condition and in consultation with that patient and, where appropriate and/or necessary, the patient's caregiver.Nor do the ESC/EAS Guidelines exempt health professionals from taking into full and careful consideration the relevant official updated recommendations or guidelines issued by the competent public health authorities, in order to manage each patient's case in light of the scientifically accepted data pursuant to their respective ethical and professional obligations.It is also the health professional's responsibility to verify the applicable rules and regulations relating to drugs and medical devices at the time of prescription.", "concepts": ["Medicine", "Medical emergency", "Public relations", "Nursing", "Law", "Linguistics", "Philosophy", "Political science"], "domain": "medicine"}
{"id": "https://openalex.org/W2996597775", "title": "To saturate or not to saturate? Questioning data saturation as a useful concept for thematic analysis and sample-size rationales", "abstract": "The concept of data saturation, defined as 'information redundancy' or the point at which no new themes or codes 'emerge' from data, is widely referenced in thematic analysis (TA) research in sport and exercise, and beyond. Several researchers have sought to 'operationalise' data saturation and provide concrete guidance on how many interviews, or focus groups, are enough to achieve some degree of data saturation in TA research. Our disagreement with such attempts to 'capture' data saturation for TA led us to this commentary. Here, we contribute to critical discussions of the saturation concept in qualitative research by interrogating the assumptions around the practice and procedures of TA that inform these data saturation 'experiments', and the conceptualisation of saturation as information redundancy. We argue that although the concepts of data-, thematic- or code-saturation, and even meaning-saturation, are coherent with the neo-positivist, discovery-oriented, meaning excavation project of coding reliability types of TA, they are not consistent with the values and assumptions of reflexive TA. We encourage sport and exercise and other researchers using reflexive TA to dwell with uncertainty and recognise that meaning is generated through interpretation of, not excavated from, data, and therefore judgements about 'how many' data items, and when to stop data collection, are inescapably situated and subjective, and cannot be determined (wholly) in advance of analysis.", "concepts": ["Computer science", "Epistemology", "Psychology", "Sociology", "Mathematics", "Social science", "Combinatorics", "Philosophy"], "domain": "psychology"}
{"id": "https://openalex.org/W4327946446", "title": "ChatGPT Utility in Healthcare Education, Research, and Practice: Systematic Review on the Promising Perspectives and Valid Concerns", "abstract": "ChatGPT is an artificial intelligence (AI)-based conversational large language model (LLM). The potential applications of LLMs in health care education, research, and practice could be promising if the associated valid concerns are proactively examined and addressed. The current systematic review aimed to investigate the utility of ChatGPT in health care education, research, and practice and to highlight its potential limitations. Using the PRIMSA guidelines, a systematic search was conducted to retrieve English records in PubMed/MEDLINE and Google Scholar (published research or preprints) that examined ChatGPT in the context of health care education, research, or practice. A total of 60 records were eligible for inclusion. Benefits of ChatGPT were cited in 51/60 (85.0%) records and included: (1) improved scientific writing and enhancing research equity and versatility; (2) utility in health care research (efficient analysis of datasets, code generation, literature reviews, saving time to focus on experimental design, and drug discovery and development); (3) benefits in health care practice (streamlining the workflow, cost saving, documentation, personalized medicine, and improved health literacy); and (4) benefits in health care education including improved personalized learning and the focus on critical thinking and problem-based learning. Concerns regarding ChatGPT use were stated in 58/60 (96.7%) records including ethical, copyright, transparency, and legal issues, the risk of bias, plagiarism, lack of originality, inaccurate content with risk of hallucination, limited knowledge, incorrect citations, cybersecurity issues, and risk of infodemics. The promising applications of ChatGPT can induce paradigm shifts in health care education, research, and practice. However, the embrace of this AI chatbot should be conducted with extreme caution considering its potential limitations. As it currently stands, ChatGPT does not qualify to be listed as an author in scientific articles unless the ICMJE/COPE guidelines are revised or amended. An initiative involving all stakeholders in health care education, research, and practice is urgently needed. This will help to set a code of ethics to guide the responsible use of ChatGPT among other LLMs in health care and academia.", "concepts": ["Medical education", "Psychology", "Medicine", "Computer science", "Political science", "Paleontology", "Computer security", "Database"], "domain": "psychology"}
{"id": "https://openalex.org/W2900569176", "title": "STRING v11: protein–protein association networks with increased coverage, supporting functional discovery in genome-wide experimental datasets", "abstract": "Proteins and their functional interactions form the backbone of the cellular machinery. Their connectivity network needs to be considered for the full understanding of biological phenomena, but the available information on protein-protein associations is incomplete and exhibits varying levels of annotation granularity and reliability. The STRING database aims to collect, score and integrate all publicly available sources of protein-protein interaction information, and to complement these with computational predictions. Its goal is to achieve a comprehensive and objective global network, including direct (physical) as well as indirect (functional) interactions. The latest version of STRING (11.0) more than doubles the number of organisms it covers, to 5090. The most important new feature is an option to upload entire, genome-wide datasets as input, allowing users to visualize subsets as interaction networks and to perform gene-set enrichment analysis on the entire input. For the enrichment analysis, STRING implements well-known classification systems such as Gene Ontology and KEGG, but also offers additional, new classification systems based on high-throughput text-mining as well as on a hierarchical clustering of the association network itself. The STRING resource is available online at https://string-db.org/.", "concepts": ["Biology", "Computational biology", "Computer science", "Data mining", "Machine learning", "Genetics", "Physics", "Quantum mechanics"], "domain": "physics"}
{"id": "https://openalex.org/W2917207851", "title": "The Galaxy platform for accessible, reproducible and collaborative biomedical analyses: 2018 update", "abstract": "Galaxy (homepage: https://galaxyproject.org, main public server: https://usegalaxy.org) is a web-based scientific analysis platform used by tens of thousands of scientists across the world to analyze large biomedical datasets such as those found in genomics, proteomics, metabolomics and imaging. Started in 2005, Galaxy continues to focus on three key challenges of data-driven biomedical science: making analyses accessible to all researchers, ensuring analyses are completely reproducible, and making it simple to communicate analyses so that they can be reused and extended. During the last two years, the Galaxy team and the open-source community around Galaxy have made substantial improvements to Galaxy's core framework, user interface, tools, and training materials. Framework and user interface improvements now enable Galaxy to be used for analyzing tens of thousands of datasets, and >5500 tools are now available from the Galaxy ToolShed. The Galaxy community has led an effort to create numerous high-quality tutorials focused on common types of genomic analyses. The Galaxy developer and user communities continue to grow and be integral to Galaxy's development. The number of Galaxy public servers, developers contributing to the Galaxy framework and its tools, and users of the main Galaxy server have all increased substantially.", "concepts": ["Computer science", "Astrophysics", "Data science", "World Wide Web", "Physics", "Parallel computing", "Optics"], "domain": "physics"}
{"id": "https://openalex.org/W3176970273", "title": "Lipid Nanoparticles─From Liposomes to mRNA Vaccine Delivery, a Landscape of Research Diversity and Advancement", "abstract": "Lipid nanoparticles (LNPs) have emerged across the pharmaceutical industry as promising vehicles to deliver a variety of therapeutics. Currently in the spotlight as vital components of the COVID-19 mRNA vaccines, LNPs play a key role in effectively protecting and transporting mRNA to cells. Liposomes, an early version of LNPs, are a versatile nanomedicine delivery platform. A number of liposomal drugs have been approved and applied to medical practice. Subsequent generations of lipid nanocarriers, such as solid lipid nanoparticles, nanostructured lipid carriers, and cationic lipid–nucleic acid complexes, exhibit more complex architectures and enhanced physical stabilities. With their ability to encapsulate and deliver therapeutics to specific locations within the body and to release their contents at a desired time, LNPs provide a valuable platform for treatment of a variety of diseases. Here, we present a landscape of LNP-related scientific publications, including patents and journal articles, based on analysis of the CAS Content Collection, the largest human-curated collection of published scientific knowledge. Rising trends are identified, such as nanostructured lipid carriers and solid lipid nanoparticles becoming the preferred platforms for numerous formulations. Recent advancements in LNP formulations as drug delivery platforms, such as antitumor and nucleic acid therapeutics and vaccine delivery systems, are discussed. Challenges and growth opportunities are also evaluated in other areas, such as medical imaging, cosmetics, nutrition, and agrochemicals. This report is intended to serve as a useful resource for those interested in LNP nanotechnologies, their applications, and the global research effort for their development.", "concepts": ["Nanotechnology", "Chemistry", "Computational biology", "Biology", "Materials science"], "domain": "chemistry"}
{"id": "https://openalex.org/W3193297191", "title": "Empagliflozin in Heart Failure with a Preserved Ejection Fraction", "abstract": "Sodium–glucose cotransporter 2 inhibitors reduce the risk of hospitalization for heart failure in patients with heart failure and a reduced ejection fraction, but their effects in patients with heart failure and a preserved ejection fraction are uncertain.", "concepts": ["Cardiology", "Internal medicine", "Medicine", "Chemistry", "Endocrinology", "Chromatography"], "domain": "chemistry"}
{"id": "https://openalex.org/W2889326414", "title": "UMAP: Uniform Manifold Approximation and Projection", "abstract": "Uniform Manifold Approximation and Projection (UMAP) is a dimension reduction technique that can be used for visualisation similarly to t-SNE, but also for general non-linear dimension reduction.UMAP has a rigorous mathematical foundation, but is simple to use, with a scikit-learn compatible API.UMAP is among the fastest manifold learning implementations available -significantly faster than most t-SNE implementations.UMAP supports a number of useful features, including the ability to use labels (or partial labels) for supervised (or semi-supervised) dimension reduction, and the ability to transform new unseen data into a pretrained embedding space.", "concepts": ["Mathematics", "Computer science", "Geometry", "Algorithm", "Engineering", "Mechanical engineering"], "domain": "biology"}
{"id": "https://openalex.org/W2779282391", "title": "Microplastics and Nanoplastics in Aquatic Environments: Aggregation, Deposition, and Enhanced Contaminant Transport", "abstract": "Plastic litter is widely acknowledged as a global environmental threat, and poor management and disposal lead to increasing levels in the environment. Of recent concern is the degradation of plastics from macro- to micro- and even to nanosized particles smaller than 100 nm in size. At the nanoscale, plastics are difficult to detect and can be transported in air, soil, and water compartments. While the impact of plastic debris on marine and fresh waters and organisms has been studied, the loads, transformations, transport, and fate of plastics in terrestrial and subsurface environments are largely overlooked. In this Critical Review, we first present estimated loads of plastics in different environmental compartments. We also provide a critical review of the current knowledge vis-à-vis nanoplastic (NP) and microplastic (MP) aggregation, deposition, and contaminant cotransport in the environment. Important factors that affect aggregation and deposition in natural subsurface environments are identified and critically analyzed. Factors affecting contaminant sorption onto plastic debris are discussed, and we show how polyethylene generally exhibits a greater sorption capacity than other plastic types. Finally, we highlight key knowledge gaps that need to be addressed to improve our ability to predict the risks associated with these ubiquitous contaminants in the environment by understanding their mobility, aggregation behavior and their potential to enhance the transport of other pollutants.", "concepts": ["Environmental science", "Environmental chemistry", "Environmental engineering", "Chemistry", "Ecology", "Geology", "Biology", "Paleontology"], "domain": "engineering"}
{"id": "https://openalex.org/W2791453970", "title": "Heart Disease and Stroke Statistics—2018 Update: A Report From the American Heart Association", "abstract": "Each chapter listed in the Table of Contents (see next page) is a hyperlink to that chapter. The reader clicks the chapter name to access that chapter.\n\nEach chapter listed here is a hyperlink. Click on the chapter name to be taken to that chapter. \n\nEach year, the American Heart Association (AHA), in conjunction with the Centers for Disease Control and Prevention, the National Institutes of Health, and other government agencies, brings together in a single document the most up-to-date statistics related to heart disease, stroke, and the cardiovascular risk factors listed in the AHA’s My Life Check - Life’s Simple 7 (Figure1), which include core health behaviors (smoking, physical activity, diet, and weight) and health factors (cholesterol, blood pressure [BP], and glucose control) that contribute to cardiovascular health. The Statistical Update represents …", "concepts": ["Medicine", "Gerontology", "Family medicine", "Internal medicine", "World Wide Web", "Mechanical engineering", "Linguistics", "Philosophy"], "domain": "biology"}
{"id": "https://openalex.org/W2513506562", "title": "VSEARCH: a versatile open source tool for metagenomics", "abstract": "VSEARCH is an open source and free of charge multithreaded 64-bit tool for processing and preparing metagenomics, genomics and population genomics nucleotide sequence data. It is designed as an alternative to the widely used USEARCH tool (Edgar, 2010) for which the source code is not publicly available, algorithm details are only rudimentarily described, and only a memory-confined 32-bit version is freely available for academic use.When searching nucleotide sequences, VSEARCH uses a fast heuristic based on words shared by the query and target sequences in order to quickly identify similar sequences, a similar strategy is probably used in USEARCH. VSEARCH then performs optimal global sequence alignment of the query against potential target sequences, using full dynamic programming instead of the seed-and-extend heuristic used by USEARCH. Pairwise alignments are computed in parallel using vectorisation and multiple threads.VSEARCH includes most commands for analysing nucleotide sequences available in USEARCH version 7 and several of those available in USEARCH version 8, including searching (exact or based on global alignment), clustering by similarity (using length pre-sorting, abundance pre-sorting or a user-defined order), chimera detection (reference-based or de novo), dereplication (full length or prefix), pairwise alignment, reverse complementation, sorting, and subsampling. VSEARCH also includes commands for FASTQ file processing, i.e., format detection, filtering, read quality statistics, and merging of paired reads. Furthermore, VSEARCH extends functionality with several new commands and improvements, including shuffling, rereplication, masking of low-complexity sequences with the well-known DUST algorithm, a choice among different similarity definitions, and FASTQ file format conversion. VSEARCH is here shown to be more accurate than USEARCH when performing searching, clustering, chimera detection and subsampling, while on a par with USEARCH for paired-ends read merging. VSEARCH is slower than USEARCH when performing clustering and chimera detection, but significantly faster when performing paired-end reads merging and dereplication. VSEARCH is available at https://github.com/torognes/vsearch under either the BSD 2-clause license or the GNU General Public License version 3.0.VSEARCH has been shown to be a fast, accurate and full-fledged alternative to USEARCH. A free and open-source versatile tool for sequence analysis is now available to the metagenomics community.", "concepts": ["Computer science", "Data mining", "Biology", "Artificial intelligence", "Programming language", "Genetics"], "domain": "environmental_science"}
{"id": "https://openalex.org/W4393353064", "title": "The Role of AI in Hospitals and Clinics: Transforming Healthcare in the 21st Century", "abstract": "As healthcare systems around the world face challenges such as escalating costs, limited access, and growing demand for personalized care, artificial intelligence (AI) is emerging as a key force for transformation. This review is motivated by the urgent need to harness AI’s potential to mitigate these issues and aims to critically assess AI’s integration in different healthcare domains. We explore how AI empowers clinical decision-making, optimizes hospital operation and management, refines medical image analysis, and revolutionizes patient care and monitoring through AI-powered wearables. Through several case studies, we review how AI has transformed specific healthcare domains and discuss the remaining challenges and possible solutions. Additionally, we will discuss methodologies for assessing AI healthcare solutions, ethical challenges of AI deployment, and the importance of data privacy and bias mitigation for responsible technology use. By presenting a critical assessment of AI’s transformative potential, this review equips researchers with a deeper understanding of AI’s current and future impact on healthcare. It encourages an interdisciplinary dialogue between researchers, clinicians, and technologists to navigate the complexities of AI implementation, fostering the development of AI-driven solutions that prioritize ethical standards, equity, and a patient-centered approach.", "concepts": ["Medicine", "Computer science", "Political science", "Law"], "domain": "computer_science"}
{"id": "https://openalex.org/W2750168540", "title": "Guidance on Conducting a Systematic Literature Review", "abstract": "Literature reviews establish the foundation of academic inquires. However, in the planning field, we lack rigorous systematic reviews. In this article, through a systematic search on the methodology of literature review, we categorize a typology of literature reviews, discuss steps in conducting a systematic literature review, and provide suggestions on how to enhance rigor in literature reviews in planning education and research.", "concepts": ["Management science", "Engineering ethics", "Sociology", "Political science", "Epistemology", "Computer science", "Engineering", "Artificial intelligence"], "domain": "materials_science"}
{"id": "https://openalex.org/W2998840182", "title": "U1 snRNP regulates cancer cell migration and invasion in vitro", "abstract": "Abstract Stimulated cells and cancer cells have widespread shortening of mRNA 3’-untranslated regions (3’UTRs) and switches to shorter mRNA isoforms due to usage of more proximal polyadenylation signals (PASs) in introns and last exons. U1 snRNP (U1), vertebrates’ most abundant non-coding (spliceosomal) small nuclear RNA, silences proximal PASs and its inhibition with antisense morpholino oligonucleotides (U1 AMO) triggers widespread premature transcription termination and mRNA shortening. Here we show that low U1 AMO doses increase cancer cells’ migration and invasion in vitro by up to 500%, whereas U1 over-expression has the opposite effect. In addition to 3’UTR length, numerous transcriptome changes that could contribute to this phenotype are observed, including alternative splicing, and mRNA expression levels of proto-oncogenes and tumor suppressors. These findings reveal an unexpected role for U1 homeostasis (available U1 relative to transcription) in oncogenic and activated cell states, and suggest U1 as a potential target for their modulation.", "concepts": ["Biology", "Cell biology", "Molecular biology", "Genetics", "Linguistics", "Philosophy"], "domain": "environmental_science"}
{"id": "https://openalex.org/W4399900763", "title": "IoT Solutions in Agriculture: Enhancing Efficiency and Productivity", "abstract": "The agricultural sector is on the brink of a transformative era with the emergence of Internet of Things (IoT) technologies. This paper delves into integrating IoT solutions in agriculture, focusing on how these technologies can significantly enhance efficiency, productivity, and sustainability. It explores various IoT applications, including precision farming, automated irrigation, soil monitoring, and pest control, and discusses their benefits and challenges. The study underlines the immense potential of IoT in shaping the future of agriculture by harnessing real-time data, advanced analytics, and intelligent decision-making systems.", "concepts": ["Agricultural engineering", "Business", "Agricultural economics", "Industrial organization", "Computer science", "Economics", "Engineering", "Geography"], "domain": "economics"}
{"id": "https://openalex.org/W4221040930", "title": "Measuring Geopolitical Risk", "abstract": "We present a news-based measure of adverse geopolitical events and associated risks. The geopolitical risk (GPR) index spikes around the two world wars, at the beginning of the Korean War, during the Cuban Missile Crisis, and after 9/11. Higher geopolitical risk foreshadows lower investment and employment and is associated with higher disaster probability and larger downside risks. The adverse consequences of the GPR index are driven by both the threat and the realization of adverse geopolitical events. We complement our aggregate measures with industry- and firm-level indicators of geopolitical risk. Investment drops more in industries that are exposed to aggregate geopolitical risk. Higher firm-level geopolitical risk is associated with lower firm-level investment. (JEL C43, E32, F51, F52, G31, H56, N40)", "concepts": ["Economics", "Political science", "Law", "World Wide Web", "Computer science"], "domain": "social_sciences"}
{"id": "https://openalex.org/W4393183306", "title": "Loss of Life Transformer Prediction Based on Stacking Ensemble Improved by Genetic Algorithm By IJISRT", "abstract": "Prediction for loss of life transfomer is very important to ensure the reliability and efficiency of the power system. In this paper, an innovative model is proposed to improve the accuracy of lost of life transfomer prediction using stacking ensembles enhanced with genetic algorithm (GA). The aim is to develop a robust model to estimate the remaining life of a transformer in order to generally increase the reliability of the electrical energy distribution system. This approach involves integrating various machine learning models as a basic model, namely Support Vector Machines (SVM) and K-Nearest Neighbor (KNN). A stacking ensemble framework is then used to combine the predictions of these base models using a meta model namely Logistic Regression (LR). The results show a significant improvement in both transformers using stacking-GA, both TR-A and TR-B, with each prediction evaluation 99% and with a minimal error rate, namely approaching 0.the developed framework presents a promising solution for accurate and reliable transformer life prediction. By integrating a variety of basic models, applying improved stacking layouts using GA, these models offer valuable insights to improve maintenance strategies and system reliability in power grids.", "concepts": ["Computer science", "Algorithm", "Artificial intelligence", "Engineering", "Electrical engineering", "Chemistry", "Organic chemistry"], "domain": "chemistry"}
{"id": "https://openalex.org/W4400896559", "title": "Optimization of Raw Material Inventory using Always Better Control (ABC) Analysis and Economic Order Quantity (EOQ) Method Approach in the Warehouse of a Bolt Manufacturing Factory in Indonesia", "abstract": "There is a problem in the raw material procurement process at the Contractor Company, such as running out and excess stock of raw materials, as well as difficulties in determining how many raw materials to order that meet the company's economic value. Running out of raw material stock results in delays in production activities, while excess raw material stock can fill warehouse capacity, thereby increasing storage costs. To overcome this problem, research was carried out using a quantitative descriptive method to determine the level of production cost efficiency and production effectiveness level in order to achieve optimization of raw material supplies using Always Better Control (ABC) Analysis and the Economic Order Quantity (EOQ) Method at Bolt Companies. ABC analysis plays a role in determining which raw materials have the highest level of demand and the EOQ method plays a role in determining the amount of raw materials to be ordered in order to meet the company's economic value. The research results show that the combination of ABC Analysis and EOQ Method can reduce ordering costs and raw material inventory. There are 4 items out of 10 raw material items that are included in Category A or the most prioritized category. From the results of calculations using the EOQ method, the Bolt Company can save total orders and raw material inventory (TIC) in the period January to December 2023 amounting to IDR 2,147,403,-.", "concepts": ["Computer science", "Manufacturing engineering", "Operations management", "Operations research", "Engineering", "Business", "Chemistry", "Marketing"], "domain": "chemistry"}
{"id": "https://openalex.org/W4396723768", "title": "Augmenting large language models with chemistry tools", "abstract": "Abstract Large language models (LLMs) have shown strong performance in tasks across domains but struggle with chemistry-related problems. These models also lack access to external knowledge sources, limiting their usefulness in scientific applications. We introduce ChemCrow, an LLM chemistry agent designed to accomplish tasks across organic synthesis, drug discovery and materials design. By integrating 18 expert-designed tools and using GPT-4 as the LLM, ChemCrow augments the LLM performance in chemistry, and new capabilities emerge. Our agent autonomously planned and executed the syntheses of an insect repellent and three organocatalysts and guided the discovery of a novel chromophore. Our evaluation, including both LLM and expert assessments, demonstrates ChemCrow’s effectiveness in automating a diverse set of chemical tasks. Our work not only aids expert chemists and lowers barriers for non-experts but also fosters scientific advancement by bridging the gap between experimental and computational chemistry.", "concepts": ["Computer science", "Nanotechnology", "Data science", "Chemistry", "Engineering", "Programming language", "Mechanical engineering", "Computer network"], "domain": "computer_science"}
{"id": "https://openalex.org/W4402061574", "title": "Abstractive Text Summarization Using GAN", "abstract": "In the field of natural language processing, the task of writing long concepts into short expressions has attracted attention due to its ability to simplify the processing and understanding of information. While traditional transcription techniques are effective to some extent, they often fail to capture the essence and nuances of the original texts. This article explores a new approach to collecting abstract data using artificial neural networks (GANs), a class of deep learning models known for their ability to create patterns of real information. We describe the fundamentals of text collection through a comprehensive review of existing literature and methods and highlight the complexity of GAN-based text. Our goal is to transform complex text into context and meaning by combining the power of GANs with natural language understanding. We detail the design and training of an adaptive GAN model for the text recognition task. We also conduct various experiments and evaluations using established metrics such as ROUGE and BLEU scores to evaluate the effectiveness and efficiency of our approach. The results show that GANs can be used to improve the quality and consistency of generated content, data storage, data analysis paper, etc. It shows its promise in paving the way for advanced applications in fields. Through this research, we aim to contribute to the continued evolution of writing technology, providing insights and innovations that support the field to a new level of well-done.", "concepts": ["Computer science", "Artificial intelligence", "Natural language processing", "Psychology", "Paleontology", "Mathematics", "Management", "Pure mathematics"], "domain": "economics"}
{"id": "https://openalex.org/W2999417355", "title": "Cancer statistics, 2020", "abstract": "Abstract Each year, the American Cancer Society estimates the numbers of new cancer cases and deaths that will occur in the United States and compiles the most recent data on population‐based cancer occurrence. Incidence data (through 2016) were collected by the Surveillance, Epidemiology, and End Results Program; the National Program of Cancer Registries; and the North American Association of Central Cancer Registries. Mortality data (through 2017) were collected by the National Center for Health Statistics. In 2020, 1,806,590 new cancer cases and 606,520 cancer deaths are projected to occur in the United States. The cancer death rate rose until 1991, then fell continuously through 2017, resulting in an overall decline of 29% that translates into an estimated 2.9 million fewer cancer deaths than would have occurred if peak rates had persisted. This progress is driven by long‐term declines in death rates for the 4 leading cancers (lung, colorectal, breast, prostate); however, over the past decade (2008‐2017), reductions slowed for female breast and colorectal cancers, and halted for prostate cancer. In contrast, declines accelerated for lung cancer, from 3% annually during 2008 through 2013 to 5% during 2013 through 2017 in men and from 2% to almost 4% in women, spurring the largest ever single‐year drop in overall cancer mortality of 2.2% from 2016 to 2017. Yet lung cancer still caused more deaths in 2017 than breast, prostate, colorectal, and brain cancers combined. Recent mortality declines were also dramatic for melanoma of the skin in the wake of US Food and Drug Administration approval of new therapies for metastatic disease, escalating to 7% annually during 2013 through 2017 from 1% during 2006 through 2010 in men and women aged 50 to 64 years and from 2% to 3% in those aged 20 to 49 years; annual declines of 5% to 6% in individuals aged 65 years and older are particularly striking because rates in this age group were increasing prior to 2013. It is also notable that long‐term rapid increases in liver cancer mortality have attenuated in women and stabilized in men. In summary, slowing momentum for some cancers amenable to early detection is juxtaposed with notable gains for other common cancers.", "concepts": ["Medicine", "Demography", "Gerontology", "Oncology", "Internal medicine", "Environmental health", "Physics", "Sociology"], "domain": "physics"}
{"id": "https://openalex.org/W2889646458", "title": "Global cancer statistics 2018: GLOBOCAN estimates of incidence and mortality worldwide for 36 cancers in 185 countries", "abstract": "Abstract This article provides a status report on the global burden of cancer worldwide using the GLOBOCAN 2018 estimates of cancer incidence and mortality produced by the International Agency for Research on Cancer, with a focus on geographic variability across 20 world regions. There will be an estimated 18.1 million new cancer cases (17.0 million excluding nonmelanoma skin cancer) and 9.6 million cancer deaths (9.5 million excluding nonmelanoma skin cancer) in 2018. In both sexes combined, lung cancer is the most commonly diagnosed cancer (11.6% of the total cases) and the leading cause of cancer death (18.4% of the total cancer deaths), closely followed by female breast cancer (11.6%), prostate cancer (7.1%), and colorectal cancer (6.1%) for incidence and colorectal cancer (9.2%), stomach cancer (8.2%), and liver cancer (8.2%) for mortality. Lung cancer is the most frequent cancer and the leading cause of cancer death among males, followed by prostate and colorectal cancer (for incidence) and liver and stomach cancer (for mortality). Among females, breast cancer is the most commonly diagnosed cancer and the leading cause of cancer death, followed by colorectal and lung cancer (for incidence), and vice versa (for mortality); cervical cancer ranks fourth for both incidence and mortality. The most frequently diagnosed cancer and the leading cause of cancer death, however, substantially vary across countries and within each country depending on the degree of economic development and associated social and life style factors. It is noteworthy that high‐quality cancer registry data, the basis for planning and implementing evidence‐based cancer control programs, are not available in most low‐ and middle‐income countries. The Global Initiative for Cancer Registry Development is an international partnership that supports better estimation, as well as the collection and use of local data, to prioritize and evaluate national cancer control efforts. CA: A Cancer Journal for Clinicians 2018;0:1‐31. © 2018 American Cancer Society", "concepts": ["Medicine", "Oncology", "Internal medicine", "Physics", "Optics"], "domain": "physics"}
{"id": "https://openalex.org/W2799524357", "title": "MEGA X: Molecular Evolutionary Genetics Analysis across Computing Platforms", "abstract": "The Molecular Evolutionary Genetics Analysis (Mega) software implements many analytical methods and tools for phylogenomics and phylomedicine. Here, we report a transformation of Mega to enable cross-platform use on Microsoft Windows and Linux operating systems. Mega X does not require virtualization or emulation software and provides a uniform user experience across platforms. Mega X has additionally been upgraded to use multiple computing cores for many molecular evolutionary analyses. Mega X is available in two interfaces (graphical and command line) and can be downloaded from www.megasoftware.net free of charge.", "concepts": ["Biology", "Operating system", "Computer science", "Computational biology", "Genetics", "Physics", "Astronomy", "Economics"], "domain": "biology"}
{"id": "https://openalex.org/W2905811773", "title": "When to use and how to report the results of PLS-SEM", "abstract": "Purpose The purpose of this paper is to provide a comprehensive, yet concise, overview of the considerations and metrics required for partial least squares structural equation modeling (PLS-SEM) analysis and result reporting. Preliminary considerations are summarized first, including reasons for choosing PLS-SEM, recommended sample size in selected contexts, distributional assumptions, use of secondary data, statistical power and the need for goodness-of-fit testing. Next, the metrics as well as the rules of thumb that should be applied to assess the PLS-SEM results are covered. Besides presenting established PLS-SEM evaluation criteria, the overview includes the following new guidelines: PLSpredict (i.e., a novel approach for assessing a model’s out-of-sample prediction), metrics for model comparisons, and several complementary methods for checking the results’ robustness. Design/methodology/approach This paper provides an overview of previously and recently proposed metrics as well as rules of thumb for evaluating the research results based on the application of PLS-SEM. Findings Most of the previously applied metrics for evaluating PLS-SEM results are still relevant. Nevertheless, scholars need to be knowledgeable about recently proposed metrics (e.g. model comparison criteria) and methods (e.g. endogeneity assessment, latent class analysis and PLSpredict), and when and how to apply them to extend their analyses. Research limitations/implications Methodological developments associated with PLS-SEM are rapidly emerging. The metrics reported in this paper are useful for current applications, but must always be up to date with the latest developments in the PLS-SEM method. Originality/value In light of more recent research and methodological developments in the PLS-SEM domain, guidelines for the method’s use need to be continuously extended and updated. This paper is the most current and comprehensive summary of the PLS-SEM method and the metrics applied to assess its solutions.", "concepts": ["Computer science", "Data mining", "Artificial intelligence", "Machine learning", "Mathematics", "Statistics", "Algorithm", "Psychology"], "domain": "biology"}
{"id": "https://openalex.org/W4390829176", "title": "Balancing Privacy and Progress: A Review of Privacy Challenges, Systemic Oversight, and Patient Perceptions in AI-Driven Healthcare", "abstract": "Integrating Artificial Intelligence (AI) in healthcare represents a transformative shift with substantial potential for enhancing patient care. This paper critically examines this integration, confronting significant ethical, legal, and technological challenges, particularly in patient privacy, decision-making autonomy, and data integrity. A structured exploration of these issues focuses on Differential Privacy as a critical method for preserving patient confidentiality in AI-driven healthcare systems. We analyze the balance between privacy preservation and the practical utility of healthcare data, emphasizing the effectiveness of encryption, Differential Privacy, and mixed-model approaches. The paper navigates the complex ethical and legal frameworks essential for AI integration in healthcare. We comprehensively examine patient rights and the nuances of informed consent, along with the challenges of harmonizing advanced technologies like blockchain with the General Data Protection Regulation (GDPR). The issue of algorithmic bias in healthcare is also explored, underscoring the urgent need for effective bias detection and mitigation strategies to build patient trust. The evolving roles of decentralized data sharing, regulatory frameworks, and patient agency are discussed in depth. Advocating for an interdisciplinary, multi-stakeholder approach and responsive governance, the paper aims to align healthcare AI with ethical principles, prioritize patient-centered outcomes, and steer AI towards responsible and equitable enhancements in patient care.", "concepts": ["Business", "Internet privacy", "Knowledge management", "Political science", "Psychology", "Computer science", "Medicine", "Computer security"], "domain": "computer_science"}
{"id": "https://openalex.org/W2891378911", "title": "PRISMA Extension for Scoping Reviews (PRISMA-ScR): Checklist and Explanation", "abstract": "Scoping reviews, a type of knowledge synthesis, follow a systematic approach to map evidence on a topic and identify main concepts, theories, sources, and knowledge gaps. Although more scoping reviews are being done, their methodological and reporting quality need improvement. This document presents the PRISMA-ScR (Preferred Reporting Items for Systematic reviews and Meta-Analyses extension for Scoping Reviews) checklist and explanation. The checklist was developed by a 24-member expert panel and 2 research leads following published guidance from the EQUATOR (Enhancing the QUAlity and Transparency Of health Research) Network. The final checklist contains 20 essential reporting items and 2 optional items. The authors provide a rationale and an example of good reporting for each item. The intent of the PRISMA-ScR is to help readers (including researchers, publishers, commissioners, policymakers, health care providers, guideline developers, and patients or consumers) develop a greater understanding of relevant terminology, core concepts, and key items to report for scoping reviews.", "concepts": ["Medicine", "Medical education", "Management science", "Knowledge management", "Process management", "Psychology", "Computer science", "Engineering"], "domain": "biology"}
{"id": "https://openalex.org/W2738372003", "title": "Annual Review of Sociology", "abstract": "Outside of Indigenous studies, sociologists tend to treat land in the United States as governed exclusively by an entrenched private-property regime: Land is a commodity and an object for individual control. This review presents land in the United States ... Read More", "concepts": ["Geography", "Economic geography", "Sociology", "Political science", "Political economy", "Genealogy", "Social science", "Regional science"], "domain": "materials_science"}
{"id": "https://openalex.org/W4367368563", "title": "Manajemen Sumber Daya Manusia", "abstract": "Buku ini disusun oleh akademisi dan praktisi sesuai dengan kepakarannya masing-masing. Buku ini diharapkan dapat hadir memberikan kontribusi positif dalam ilmu pengetahuan khususnya Manajemen Sumber Daya Manusia yang merujuk kepada keilmuan bidang Manajemen. Luasnya permasalahan di bidang sumber daya manusia (SDM) mengharuskan organisasi membatasi ruang gerak dan aktivitasnya pada aspek-aspek penting dari manajemen sumber daya manusia itu sendiri. Oleh karena itu, pada penyusunan buku ini akan diuraikan masalah-masalah pokok dalam SDM dan batasan-batasannya. Dengan memahami proses dalam manajemen sumber daya manusia, pembaca khususnya mahasiswa S1 sebagai target dari buku ini diharapkan dapat merumuskan sebuah konsep utama dalam MSDM. Pada pendidikan strata satu (S1), pengajaran Manajemen Sumber Daya Manusia bertujuan memberikan dasar kemampuan bagi mahasiswa untuk menyusun proses perencanaan dan pengembangan sumber daya manusia.", "concepts": ["Humanities", "Political science", "Art"], "domain": "social_sciences"}
{"id": "https://openalex.org/W2592509339", "title": "<scp>ILAE</scp> classification of the epilepsies: Position paper of the <scp>ILAE</scp> Commission for Classification and Terminology", "abstract": "The International League Against Epilepsy (ILAE) Classification of the Epilepsies has been updated to reflect our gain in understanding of the epilepsies and their underlying mechanisms following the major scientific advances that have taken place since the last ratified classification in 1989. As a critical tool for the practicing clinician, epilepsy classification must be relevant and dynamic to changes in thinking, yet robust and translatable to all areas of the globe. Its primary purpose is for diagnosis of patients, but it is also critical for epilepsy research, development of antiepileptic therapies, and communication around the world. The new classification originates from a draft document submitted for public comments in 2013, which was revised to incorporate extensive feedback from the international epilepsy community over several rounds of consultation. It presents three levels, starting with seizure type, where it assumes that the patient is having epileptic seizures as defined by the new 2017 ILAE Seizure Classification. After diagnosis of the seizure type, the next step is diagnosis of epilepsy type, including focal epilepsy, generalized epilepsy, combined generalized, and focal epilepsy, and also an unknown epilepsy group. The third level is that of epilepsy syndrome, where a specific syndromic diagnosis can be made. The new classification incorporates etiology along each stage, emphasizing the need to consider etiology at each step of diagnosis, as it often carries significant treatment implications. Etiology is broken into six subgroups, selected because of their potential therapeutic consequences. New terminology is introduced such as developmental and epileptic encephalopathy. The term benign is replaced by the terms self-limited and pharmacoresponsive, to be used where appropriate. It is hoped that this new framework will assist in improving epilepsy care and research in the 21st century.", "concepts": ["Medicine", "Pediatrics", "Intensive care medicine", "Psychiatry", "Linguistics", "Philosophy"], "domain": "materials_science"}
{"id": "https://openalex.org/W4389437528", "title": "Education in the Era of Generative Artificial Intelligence (AI): Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning", "abstract": "Since its maiden release into the public domain on November 30, 2022, ChatGPT garnered more than one million subscribers within a week. The generative AI tool ⎼ChatGPT took the world by surprise with it sophisticated capacity to carry out remarkably complex tasks. The extraordinary abilities of ChatGPT to perform complex tasks within the field of education has caused mixed feelings among educators, as this advancement in AI seems to revolutionize existing educational praxis. This is an exploratory study that synthesizes recent extant literature to offer some potential benefits and drawbacks of ChatGPT in promoting teaching and learning. Benefits of ChatGPT include but are not limited to promotion of personalized and interactive learning, generating prompts for formative assessment activities that provide ongoing feedback to inform teaching and learning etc. The paper also highlights some inherent limitations in the ChatGPT such as generating wrong information, biases in data training, which may augment existing biases, privacy issues etc. The study offers recommendations on how ChatGPT could be leveraged to maximize teaching and learning. Policy makers, researchers, educators and technology experts could work together and start conversations on how these evolving generative AI tools could be used safely and constructively to improve education and support students’ learning.", "concepts": ["Computer science", "Artificial intelligence", "Knowledge management", "Psychology", "Mathematics education", "Political science", "Social psychology", "Mathematics"], "domain": "psychology"}
{"id": "https://openalex.org/W2579562509", "title": "Fluoroethylene Carbonate Additives to Render Uniform Li Deposits in Lithium Metal Batteries", "abstract": "Lithium (Li) metal has been considered as an important substitute for the graphite anode to further boost the energy density of Li‐ion batteries. However, Li dendrite growth during Li plating/stripping causes safety concern and poor lifespan of Li metal batteries (LMB). Herein, fluoroethylene carbonate (FEC) additives are used to form a LiF‐rich solid electrolyte interphase (SEI). The FEC‐induced SEI layer is compact and stable, and thus beneficial to obtain a uniform morphology of Li deposits. This uniform and dendrite‐free morphology renders a significantly improved Coulombic efficiency of 98% within 100 cycles in a Li | Cu half‐cell. When the FEC‐protected Li metal anode matches a high‐loading LiNi 0.5 Co 0.2 Mn 0.3 O 2 (NMC) cathode (12 mg cm −2 ), a high initial capacity of 154 mAh g −1 (1.9 mAh cm −2 ) at 180.0 mA g −1 is obtained. This LMB with conversion‐type Li metal anode and intercalation‐type NMC cathode affords an emerging energy storage system to probe the energy chemistry of Li metal protection and demonstrates the material engineering of batteries with very high energy density.", "concepts": ["Materials science", "Chemical engineering", "Inorganic chemistry", "Composite material", "Metallurgy", "Chemistry", "Medicine", "Physical chemistry"], "domain": "engineering"}
{"id": "https://openalex.org/W2898962279", "title": "Present and future Köppen-Geiger climate classification maps at 1-km resolution", "abstract": "Abstract We present new global maps of the Köppen-Geiger climate classification at an unprecedented 1-km resolution for the present-day (1980–2016) and for projected future conditions (2071–2100) under climate change. The present-day map is derived from an ensemble of four high-resolution, topographically-corrected climatic maps. The future map is derived from an ensemble of 32 climate model projections (scenario RCP8.5), by superimposing the projected climate change anomaly on the baseline high-resolution climatic maps. For both time periods we calculate confidence levels from the ensemble spread, providing valuable indications of the reliability of the classifications. The new maps exhibit a higher classification accuracy and substantially more detail than previous maps, particularly in regions with sharp spatial or elevation gradients. We anticipate the new maps will be useful for numerous applications, including species and vegetation distribution modeling. The new maps including the associated confidence maps are freely available via www.gloh2o.org/koppen .", "concepts": ["Climatology", "Environmental science", "Geography", "Cartography", "Physical geography", "Remote sensing", "Geology", "Mathematics"], "domain": "physics"}
{"id": "https://openalex.org/W2781525129", "title": "Cancer statistics, 2018", "abstract": "Abstract Each year, the American Cancer Society estimates the numbers of new cancer cases and deaths that will occur in the United States and compiles the most recent data on cancer incidence, mortality, and survival. Incidence data, available through 2014, were collected by the Surveillance, Epidemiology, and End Results Program; the National Program of Cancer Registries; and the North American Association of Central Cancer Registries. Mortality data, available through 2015, were collected by the National Center for Health Statistics. In 2018, 1,735,350 new cancer cases and 609,640 cancer deaths are projected to occur in the United States. Over the past decade of data, the cancer incidence rate (2005‐2014) was stable in women and declined by approximately 2% annually in men, while the cancer death rate (2006‐2015) declined by about 1.5% annually in both men and women. The combined cancer death rate dropped continuously from 1991 to 2015 by a total of 26%, translating to approximately 2,378,600 fewer cancer deaths than would have been expected if death rates had remained at their peak. Of the 10 leading causes of death, only cancer declined from 2014 to 2015. In 2015, the cancer death rate was 14% higher in non‐Hispanic blacks (NHBs) than non‐Hispanic whites (NHWs) overall (death rate ratio [DRR], 1.14; 95% confidence interval [95% CI], 1.13‐1.15), but the racial disparity was much larger for individuals aged &lt;65 years (DRR, 1.31; 95% CI, 1.29‐1.32) compared with those aged ≥65 years (DRR, 1.07; 95% CI, 1.06‐1.09) and varied substantially by state. For example, the cancer death rate was lower in NHBs than NHWs in Massachusetts for all ages and in New York for individuals aged ≥65 years, whereas for those aged &lt;65 years, it was 3 times higher in NHBs in the District of Columbia (DRR, 2.89; 95% CI, 2.16‐3.91) and about 50% higher in Wisconsin (DRR, 1.78; 95% CI, 1.56‐2.02), Kansas (DRR, 1.51; 95% CI, 1.25‐1.81), Louisiana (DRR, 1.49; 95% CI, 1.38‐1.60), Illinois (DRR, 1.48; 95% CI, 1.39‐1.57), and California (DRR, 1.45; 95% CI, 1.38‐1.54). Larger racial inequalities in young and middle‐aged adults probably partly reflect less access to high‐quality health care. CA Cancer J Clin 2018;68:7‐30 . © 2018 American Cancer Society .", "concepts": ["Medicine", "Demography", "Gerontology", "Internal medicine", "Physics", "Sociology", "Optics"], "domain": "physics"}
{"id": "https://openalex.org/W2899140785", "title": "Review of Particle Physics", "abstract": "The Review summarizes much of particle physics and cosmology. Using data from previous editions, plus 2,873 new measurements from 758 papers, we list, evaluate, and average measured properties of gauge bosons and the recently discovered Higgs boson, leptons, quarks, mesons, and baryons. We summarize searches for hypothetical particles such as supersymmetric particles, heavy bosons, axions, dark photons, etc. Particle properties and search limits are listed in Summary Tables. We give numerous tables, figures, formulae, and reviews of topics such as Higgs Boson Physics, Supersymmetry, Grand Unified Theories, Neutrino Mixing, Dark Energy, Dark Matter, Cosmology, Particle Detectors, Colliders, Probability and Statistics. Among the 118 reviews are many that are new or heavily revised, including a new review on Neutrinos in Cosmology.Starting with this edition, the Review is divided into two volumes. Volume 1 includes the Summary Tables and all review articles. Volume 2 consists of the Particle Listings. Review articles that were previously part of the Listings are now included in volume 1.The complete Review (both volumes) is published online on the website of the Particle Data Group (http://pdg.lbl.gov) and in a journal. Volume 1 is available in print as the PDG Book. A Particle Physics Booklet with the Summary Tables and essential tables, figures, and equations from selected review articles is also available.The 2018 edition of the Review of Particle Physics should be cited as: M. Tanabashi et al. (Particle Data Group), Phys. Rev. D 98, 030001 (2018).", "concepts": ["Physics", "Particle physics", "Theoretical physics", "Nuclear physics", "Astronomy", "Archaeology", "History"], "domain": "physics"}
{"id": "https://openalex.org/W2905218447", "title": "The role of hydrogen and fuel cells in the global energy system", "abstract": "Hydrogen has been ‘just around the corner’ for decades, but now offers serious alternatives for decarbonising global heat, power and transport.", "concepts": ["Environmental science", "Environmental economics", "Natural resource economics", "Engineering", "Economics", "Chemistry", "Electrical engineering", "Physics"], "domain": "physics"}
{"id": "https://openalex.org/W3107527779", "title": "The STRING database in 2021: customizable protein–protein networks, and functional characterization of user-uploaded gene/measurement sets", "abstract": "Cellular life depends on a complex web of functional associations between biomolecules. Among these associations, protein–protein interactions are particularly important due to their versatility, specificity and adaptability. The STRING database aims to integrate all known and predicted associations between proteins, including both physical interactions as well as functional associations. To achieve this, STRING collects and scores evidence from a number of sources: (i) automated text mining of the scientific literature, (ii) databases of interaction experiments and annotated complexes/pathways, (iii) computational interaction predictions from co-expression and from conserved genomic context and (iv) systematic transfers of interaction evidence from one organism to another. STRING aims for wide coverage; the upcoming version 11.5 of the resource will contain more than 14 000 organisms. In this update paper, we describe changes to the text-mining system, a new scoring-mode for physical interactions, as well as extensive user interface features for customizing, extending and sharing protein networks. In addition, we describe how to query STRING with genome-wide, experimental data, including the automated detection of enriched functionalities and potential biases in the user's query data. The STRING resource is available online, at https://string-db.org/.", "concepts": ["Biology", "Computational biology", "Database", "Genetics", "Computer science", "World Wide Web", "Physics", "Quantum mechanics"], "domain": "environmental_science"}
{"id": "https://openalex.org/W2883251903", "title": "ape 5.0: an environment for modern phylogenetics and evolutionary analyses in R", "abstract": "After more than fifteen years of existence, the R package ape has continuously grown its contents, and has been used by a growing community of users. The release of version 5.0 has marked a leap towards a modern software for evolutionary analyses. Efforts have been put to improve efficiency, flexibility, support for 'big data' (R's long vectors), ease of use and quality check before a new release. These changes will hopefully make ape a useful software for the study of biodiversity and evolution in a context of increasing data quantity.ape is distributed through the Comprehensive R Archive Network: http://cran.r-project.org/package=ape. Further information may be found at http://ape-package.ird.fr/.", "concepts": ["Computer science", "Data science", "Biology", "Data mining", "Programming language", "Mathematics", "Statistics", "Paleontology"], "domain": "biology"}
{"id": "https://openalex.org/W4400232689", "title": "Economic growth and income inequality", "abstract": "In recent years the problem of economic inequalities has become one of the most often discussed problems in economics. Even though from neoclassical perspective inequalities should not have negative impact on economy, still the relation between inequalities and economic growth is not obvious. Traditionally, the starting point in this discussion is Simon Kuznets concept, according to which inequality rises in the early phases of economic development and decreases as the growth takes place. The empirical verification of this concept has been investigated, but the evidence is ambiguous. In this context, re-examining Kuznets theory for socialist countries in Asian (i.e. China, Vietnam and Lao) is especially interesting because of the rapid economic growth yet still keeping authoritarian regime. Therefore the main aim of the study is to verify the relation between economic growth and income inequality in China, Lao and Vietnam in years 1990–2022 and assess whether the relation takes shape of so-called Kuznets curve. In order to achieve the goal the data analysis and basic econometric methods are used. The results generally support relations indicated by Kuznets except for Lao for which obtained result were not statistically significant. The findings keep the door open to further analyses aimed at the identification and exploration of more significant determinants that could conclusively verify the relation between inequalities and economic development. Most promising would be incorporating some institutional determinants as it was proposed in Acemoglu and Robinson works.", "concepts": ["Economics", "Development economics", "Economic system", "Econometrics", "Political science", "Geography", "Mathematics", "Mathematical analysis"], "domain": "mathematics"}
{"id": "https://openalex.org/W4241984066", "title": "American Geriatrics Society 2019 Updated AGS Beers Criteria® for Potentially Inappropriate Medication Use in Older Adults", "abstract": "The American Geriatrics Society (AGS) Beers Criteria® (AGS Beers Criteria®) for Potentially Inappropriate Medication (PIM) Use in Older Adults are widely used by clinicians, educators, researchers, healthcare administrators, and regulators. Since 2011, the AGS has been the steward of the criteria and has produced updates on a 3‐year cycle. The AGS Beers Criteria® is an explicit list of PIMs that are typically best avoided by older adults in most circumstances or under specific situations, such as in certain diseases or conditions. For the 2019 update, an interdisciplinary expert panel reviewed the evidence published since the last update (2015) to determine if new criteria should be added or if existing criteria should be removed or undergo changes to their recommendation, rationale, level of evidence, or strength of recommendation. J Am Geriatr Soc 67:674–694, 2019.", "concepts": ["Medicine", "Family medicine", "Gerontology", "Psychiatry", "Nursing", "Political science", "Law", "Economics"], "domain": "economics"}
{"id": "https://openalex.org/W2784350055", "title": "Carbon capture and storage (CCS): the way forward", "abstract": "Carbon capture and storage (CCS) is vital to climate change mitigation, and has application across the economy, in addition to facilitating atmospheric carbon dioxide removal resulting in emissions offsets and net negative emissions. This contribution reviews the state-of-the-art and identifies key challenges which must be overcome in order to pave the way for its large-scale deployment.", "concepts": ["Environmental science", "Environmental economics", "Environmental resource management", "Natural resource economics", "Computer science", "Business", "Computer security", "Chemistry"], "domain": "physics"}
{"id": "https://openalex.org/W4322719806", "title": "Colorectal cancer statistics, 2023", "abstract": "Abstract Colorectal cancer (CRC) is the second most common cause of cancer death in the United States. Every 3 years, the American Cancer Society provides an update of CRC statistics based on incidence from population‐based cancer registries and mortality from the National Center for Health Statistics. In 2023, approximately 153,020 individuals will be diagnosed with CRC and 52,550 will die from the disease, including 19,550 cases and 3750 deaths in individuals younger than 50 years. The decline in CRC incidence slowed from 3%–4% annually during the 2000s to 1% annually during 2011–2019, driven partly by an increase in individuals younger than 55 years of 1%–2% annually since the mid‐1990s. Consequently, the proportion of cases among those younger than 55 years increased from 11% in 1995 to 20% in 2019. Incidence since circa 2010 increased in those younger than 65 years for regional‐stage disease by about 2%–3% annually and for distant‐stage disease by 0.5%–3% annually, reversing the overall shift to earlier stage diagnosis that occurred during 1995 through 2005. For example, 60% of all new cases were advanced in 2019 versus 52% in the mid‐2000s and 57% in 1995, before widespread screening. There is also a shift to left‐sided tumors, with the proportion of rectal cancer increasing from 27% in 1995 to 31% in 2019. CRC mortality declined by 2% annually from 2011–2020 overall but increased by 0.5%–3% annually in individuals younger than 50 years and in Native Americans younger than 65 years. In summary, despite continued overall declines, CRC is rapidly shifting to diagnosis at a younger age, at a more advanced stage, and in the left colon/rectum. Progress against CRC could be accelerated by uncovering the etiology of rising incidence in generations born since 1950 and increasing access to high‐quality screening and treatment among all populations, especially Native Americans.", "concepts": ["Medicine", "Demography", "Gerontology", "Internal medicine", "Environmental health", "Physics", "Sociology", "Optics"], "domain": "medicine"}
{"id": "https://openalex.org/W4392741075", "title": "Evaluation metrics and statistical tests for machine learning", "abstract": "Abstract Research on different machine learning (ML) has become incredibly popular during the past few decades. However, for some researchers not familiar with statistics, it might be difficult to understand how to evaluate the performance of ML models and compare them with each other. Here, we introduce the most common evaluation metrics used for the typical supervised ML tasks including binary, multi-class, and multi-label classification, regression, image segmentation, object detection, and information retrieval. We explain how to choose a suitable statistical test for comparing models, how to obtain enough values of the metric for testing, and how to perform the test and interpret its results. We also present a few practical examples about comparing convolutional neural networks used to classify X-rays with different lung infections and detect cancer tumors in positron emission tomography images.", "concepts": ["Computer science", "Artificial intelligence", "Machine learning", "Statistics", "Mathematics", "Operations management", "Economics"], "domain": "mathematics"}
{"id": "https://openalex.org/W4321499901", "title": "What if the devil is my guardian angel: ChatGPT as a case study of using chatbots in education", "abstract": "Abstract Artificial Intelligence (AI) technologies have been progressing constantly and being more visible in different aspects of our lives. One recent phenomenon is ChatGPT, a chatbot with a conversational artificial intelligence interface that was developed by OpenAI. As one of the most advanced artificial intelligence applications, ChatGPT has drawn much public attention across the globe. In this regard, this study examines ChatGPT in education, among early adopters, through a qualitative instrumental case study. Conducted in three stages, the first stage of the study reveals that the public discourse in social media is generally positive and there is enthusiasm regarding its use in educational settings. However, there are also voices who are approaching cautiously using ChatGPT in educational settings. The second stage of the study examines the case of ChatGPT through lenses of educational transformation, response quality, usefulness, personality and emotion, and ethics. In the third and final stage of the study, the investigation of user experiences through ten educational scenarios revealed various issues, including cheating, honesty and truthfulness of ChatGPT, privacy misleading, and manipulation. The findings of this study provide several research directions that should be considered to ensure a safe and responsible adoption of chatbots, specifically ChatGPT, in education.", "concepts": ["Psychology", "Engineering ethics", "Computer science", "Social psychology", "Political science", "Artificial intelligence", "Engineering", "Epistemology"], "domain": "psychology"}
{"id": "https://openalex.org/W2982303713", "title": "Guidelines for the Early Management of Patients With Acute Ischemic Stroke: 2019 Update to the 2018 Guidelines for the Early Management of Acute Ischemic Stroke: A Guideline for Healthcare Professionals From the American Heart Association/American Stroke Association", "abstract": "Background and Purpose- The purpose of these guidelines is to provide an up-to-date comprehensive set of recommendations in a single document for clinicians caring for adult patients with acute arterial ischemic stroke. The intended audiences are prehospital care providers, physicians, allied health professionals, and hospital administrators. These guidelines supersede the 2013 Acute Ischemic Stroke (AIS) Guidelines and are an update of the 2018 AIS Guidelines. Methods- Members of the writing group were appointed by the American Heart Association (AHA) Stroke Council's Scientific Statements Oversight Committee, representing various areas of medical expertise. Members were not allowed to participate in discussions or to vote on topics relevant to their relations with industry. An update of the 2013 AIS Guidelines was originally published in January 2018. This guideline was approved by the AHA Science Advisory and Coordinating Committee and the AHA Executive Committee. In April 2018, a revision to these guidelines, deleting some recommendations, was published online by the AHA. The writing group was asked review the original document and revise if appropriate. In June 2018, the writing group submitted a document with minor changes and with inclusion of important newly published randomized controlled trials with >100 participants and clinical outcomes at least 90 days after AIS. The document was sent to 14 peer reviewers. The writing group evaluated the peer reviewers' comments and revised when appropriate. The current final document was approved by all members of the writing group except when relationships with industry precluded members from voting and by the governing bodies of the AHA. These guidelines use the American College of Cardiology/AHA 2015 Class of Recommendations and Level of Evidence and the new AHA guidelines format. Results- These guidelines detail prehospital care, urgent and emergency evaluation and treatment with intravenous and intra-arterial therapies, and in-hospital management, including secondary prevention measures that are appropriately instituted within the first 2 weeks. The guidelines support the overarching concept of stroke systems of care in both the prehospital and hospital settings. Conclusions- These guidelines provide general recommendations based on the currently available evidence to guide clinicians caring for adult patients with acute arterial ischemic stroke. In many instances, however, only limited data exist demonstrating the urgent need for continued research on treatment of acute ischemic stroke.", "concepts": ["Medicine", "Emergency medicine", "Intensive care medicine", "Medical emergency", "Cardiology", "Nursing", "Pathology", "Mechanical engineering"], "domain": "economics"}
{"id": "https://openalex.org/W3007643904", "title": "Cryo-EM structure of the 2019-nCoV spike in the prefusion conformation", "abstract": "The outbreak of a novel coronavirus (2019-nCoV) represents a pandemic threat that has been declared a public health emergency of international concern. The CoV spike (S) glycoprotein is a key target for vaccines, therapeutic antibodies, and diagnostics. To facilitate medical countermeasure development, we determined a 3.5-angstrom-resolution cryo–electron microscopy structure of the 2019-nCoV S trimer in the prefusion conformation. The predominant state of the trimer has one of the three receptor-binding domains (RBDs) rotated up in a receptor-accessible conformation. We also provide biophysical and structural evidence that the 2019-nCoV S protein binds angiotensin-converting enzyme 2 (ACE2) with higher affinity than does severe acute respiratory syndrome (SARS)-CoV S. Additionally, we tested several published SARS-CoV RBD-specific monoclonal antibodies and found that they do not have appreciable binding to 2019-nCoV S, suggesting that antibody cross-reactivity may be limited between the two RBDs. The structure of 2019-nCoV S should enable the rapid development and evaluation of medical countermeasures to address the ongoing public health crisis.", "concepts": ["Chemistry", "Virology", "Computational biology", "Biology", "Medicine", "Immunology", "Biochemistry", "Pathology"], "domain": "environmental_science"}
{"id": "https://openalex.org/W4315754639", "title": "Cancer statistics, 2023", "abstract": "Each year, the American Cancer Society estimates the numbers of new cancer cases and deaths in the United States and compiles the most recent data on population-based cancer occurrence and outcomes using incidence data collected by central cancer registries and mortality data collected by the National Center for Health Statistics. In 2023, 1,958,310 new cancer cases and 609,820 cancer deaths are projected to occur in the United States. Cancer incidence increased for prostate cancer by 3% annually from 2014 through 2019 after two decades of decline, translating to an additional 99,000 new cases; otherwise, however, incidence trends were more favorable in men compared to women. For example, lung cancer in women decreased at one half the pace of men (1.1% vs. 2.6% annually) from 2015 through 2019, and breast and uterine corpus cancers continued to increase, as did liver cancer and melanoma, both of which stabilized in men aged 50 years and older and declined in younger men. However, a 65% drop in cervical cancer incidence during 2012 through 2019 among women in their early 20s, the first cohort to receive the human papillomavirus vaccine, foreshadows steep reductions in the burden of human papillomavirus-associated cancers, the majority of which occur in women. Despite the pandemic, and in contrast with other leading causes of death, the cancer death rate continued to decline from 2019 to 2020 (by 1.5%), contributing to a 33% overall reduction since 1991 and an estimated 3.8 million deaths averted. This progress increasingly reflects advances in treatment, which are particularly evident in the rapid declines in mortality (approximately 2% annually during 2016 through 2020) for leukemia, melanoma, and kidney cancer, despite stable/increasing incidence, and accelerated declines for lung cancer. In summary, although cancer mortality rates continue to decline, future progress may be attenuated by rising incidence for breast, prostate, and uterine corpus cancers, which also happen to have the largest racial disparities in mortality.", "concepts": ["Medicine", "Demography", "Oncology", "Internal medicine", "Environmental health", "Physics", "Sociology", "Optics"], "domain": "medicine"}
{"id": "https://openalex.org/W4395669330", "title": "Fault Detection Method based on Artificial Neural Network for 330kV Nigerian Transmission Line", "abstract": "This research focused on identifying various types of faults occurring on 330kV transmission lines through the use of artificial neural networks (ANN). A MATLAB model for the Gwagwalada-Katampe 330kV transmission line in Nigeria was implemented to generate fault datasets. Voltage and current fault parameters were utilized to train and simulate the ANN network architecture selected for each stage of fault detection. Four types of faults were considered, along with a fifth condition representing no fault. The results illustrated the success of the developed model in identifying various fault conditions and system parameters on the Gwagwalada-Katampe 330kV transmission line, modelled using MATLAB Simulink.", "concepts": ["Computer science", "Artificial intelligence", "Engineering", "Telecommunications", "Electrical engineering", "Mathematics", "Biology", "Paleontology"], "domain": "mathematics"}
{"id": "https://openalex.org/W4399808102", "title": "Analysis of Work Measurement Using a Stopwatch in a Motorcycle Workshop", "abstract": "In realizing competitiveness, a company/ business organization must have operational excellence. Operational excellence is obtained through the provision of facilities in the form of tools or work systems that enable workers to operate them more efficiently and effectively, where efficiency and effectiveness are two things that produce productivity. Apart from many influencing factors, such as worker experience and knowledge, CV. XYZ – a work organization engaged in the repair of two-wheeled motorized vehicles – is also trying to create an advantage that allows them to increase their productivity. This research is a quantitative descriptive study, which takes time data from the two jobs most routinely carried out by CV. XYZ, namely changing engine oil and gear oil. This research was carried out with the aim of finding out the standard time needed for workers to complete their work and making recommendations for possible improvements to be implemented by CV management. XYZ, namely recommendations for the layout of work facilities and also the sequence of work processes. The measurement results show that the standard time required to complete the job of changing engine oil and garden oil is 372.68 seconds and 417.99 seconds, respectively. Creating an operational flow map (current FPC) shows that the average distance that workers need to travel while working on engine oil and garden oil is 22 meters. The results of the FPC recommendation provided show that the distance has decreased to 16.5 meters or 5.5 meters shorter.", "concepts": ["Computer science", "Aeronautics", "Engineering", "Statistics", "Mathematics", "Mechanical engineering"], "domain": "mathematics"}
{"id": "https://openalex.org/W4320009379", "title": "An assessment of the scientific merits of action research", "abstract": "This article describes the deficiencies of positivist science for generating knowledge for use in solving problems that members of organizations face. Action research is introduced as a method for correcting these deficiencies. When action research is tested against the criteria of positivist science, action research is found not to meet its critical tests. The appropriateness of positivist science is questioned as a basis for judging the scientific merits of action research. Action research can base its legitimacy as science in philosophical traditions that are different from those which legitimate positivist science. Criteria and methods of science appropriate to action research are offered.", "concepts": ["Epistemology", "Engineering ethics", "Sociology", "Political science", "Social science", "Engineering", "Philosophy", "Law"], "domain": "social_sciences"}
{"id": "https://openalex.org/W4401287805", "title": "Research on the Impact of Geopolitical Instability on Russian Trade", "abstract": "This study examines how global and country- specific geopolitical instability affects Russian trade using data from 1996 to 2021. A panel regression model analyzes trade between Russia and its 15 top trading partners, exploring both direct and indirect effects. The analysis focuses on how accumulated foreign direct investment (FDI) and exchange rate fluctuations mediate these relationships. The findings reveal that global geopolitical instability decrease Russian trade by 0.0558. Interestingly, this negative impact is partially mediated by a decrease in FDI (-0.0805). This aligns with the Structural Equation Modeling (SEM) results, which show a significant negative effect of global geopolitical instability on FDI (-1.209). This suggests that FDI acts as a key transmitter of the negative effects of global instability on Russian trade. The role of exchange rate fluctuations, however, is more complex. While the Sobel Test indicated a negative indirect effect, the SEM analysis shows a positive indirect effect through exchange rate fluctuations on trade. This suggests potentially countervailing effects of currency fluctuations, with depreciation potentially incentivizing exports while appreciation might make imports cheaper. The impact of country-specific geopolitical instability varies depending on the context. Industries like food products and textiles are significantly affected by geopolitical instability increase, while sectors such as fuels, metals and raw materials show resilience. Close trading partners are less affected by global instability but suffer from partner- specific instability. Geographically, Western Europe benefits from global instability but faces challenges from partner-specific instability, contrasting with Eastern Europe and Asia. Overall, this research contributes to the understanding of how geopolitical instability, mediated by FDI and exchange rates, shapes Russia's trade performance.", "concepts": ["International economics", "Economics", "International trade", "Monetary economics", "Political science", "Macroeconomics", "Geography", "Physics"], "domain": "economics"}
{"id": "https://openalex.org/W2564630286", "title": "ReCiPe2016: a harmonised life cycle impact assessment method at midpoint and endpoint level", "abstract": "Life cycle impact assessment (LCIA) translates emissions and resource extractions into a limited number of environmental impact scores by means of so-called characterisation factors. There are two mainstream ways to derive characterisation factors, i.e. at midpoint level and at endpoint level. To further progress LCIA method development, we updated the ReCiPe2008 method to its version of 2016. This paper provides an overview of the key elements of the ReCiPe2016 method. We implemented human health, ecosystem quality and resource scarcity as three areas of protection. Endpoint characterisation factors, directly related to the areas of protection, were derived from midpoint characterisation factors with a constant mid-to-endpoint factor per impact category. We included 17 midpoint impact categories. The update of ReCiPe provides characterisation factors that are representative for the global scale instead of the European scale, while maintaining the possibility for a number of impact categories to implement characterisation factors at a country and continental scale. We also expanded the number of environmental interventions and added impacts of water use on human health, impacts of water use and climate change on freshwater ecosystems and impacts of water use and tropospheric ozone formation on terrestrial ecosystems as novel damage pathways. Although significant effort has been put into the update of ReCiPe, there is still major improvement potential in the way impact pathways are modelled. Further improvements relate to a regionalisation of more impact categories, moving from local to global species extinction and adding more impact pathways. Life cycle impact assessment is a fast evolving field of research. ReCiPe2016 provides a state-of-the-art method to convert life cycle inventories to a limited number of life cycle impact scores on midpoint and endpoint level.", "concepts": ["Environmental science", "Environmental resource management", "Environmental economics", "Environmental planning", "Computer science", "Geography", "Ecology", "Economics"], "domain": "engineering"}
{"id": "https://openalex.org/W2617369555", "title": "Staying with the trouble: making kin in the Chthulucene", "abstract": "‘It matters what thoughts think thoughts. It matters what knowledges know knowledges. It matters what relations relate relations. It matters what worlds world worlds.’ These and other mantras thrum...", "concepts": ["Sociology", "Epistemology", "Environmental ethics", "Aesthetics", "Media studies", "Social science", "Philosophy"], "domain": "materials_science"}
{"id": "https://openalex.org/W4390605189", "title": "GWTC-2.1: Deep extended catalog of compact binary coalescences observed by LIGO and Virgo during the first half of the third observing run", "abstract": "The second Gravitational-Wave Transient Catalog, GWTC-2, reported on 39 compact binary coalescences observed by the Advanced LIGO and Advanced Virgo detectors between 1 April 2019 15∶00 UTC and 1 October 2019 15∶00 UTC. Here, we present GWTC-2.1, which reports on a deeper list of candidate events observed over the same period. We analyze the final version of the strain data over this period with improved calibration and better subtraction of excess noise, which has been publicly released. We employ three matched-filter search pipelines for candidate identification, and estimate the probability of astrophysical origin for each candidate event. While GWTC-2 used a false alarm rate threshold of 2 per year, we include in GWTC-2.1, 1201 candidates that pass a false alarm rate threshold of 2 per day. We calculate the source properties of a subset of 44 high-significance candidates that have a probability of astrophysical origin greater than 0.5. Of these candidates, 36 have been reported in GWTC-2. We also calculate updated source properties for all binary black hole events previously reported in GWTC-1. If the eight additional high-significance candidates presented here are astrophysical, the mass range of events that are unambiguously identified as binary black holes (both objects ≥3M⊙) is increased compared to GWTC-2, with total masses from ∼14M⊙ for GW190924_021846 to ∼182M⊙ for GW190426_190642. Source properties calculated using our default prior suggest that the primary components of two new candidate events (GW190403_051519 and GW190426_190642) fall in the mass gap predicted by pair-instability supernova theory. We also expand the population of binaries with significantly asymmetric mass ratios reported in GWTC-2 by an additional two events (the mass ratio is less than 0.65 and 0.44 at 90% probability for GW190403_051519 and GW190917_114630 respectively), and find that two of the eight new events have effective inspiral spins χeff>0 (at 90% credibility), while no binary is consistent with χeff<0 at the same significance. We provide updated estimates for rates of binary black hole and binary neutron star coalescence in the local Universe.2 MoreReceived 10 May 2022Accepted 13 June 2023DOI:https://doi.org/10.1103/PhysRevD.109.022001© 2024 American Physical SocietyPhysics Subject Headings (PhySH)Research AreasGravitational wave sourcesGravitational wavesPhysical SystemsAstronomical black holesBinary starsNeutron stars & pulsarsGravitation, Cosmology & Astrophysics", "concepts": ["Physics", "Astrophysics", "Astronomy", "Statistics", "Algorithm", "Computer science", "Arithmetic", "Mathematics"], "domain": "computer_science"}
{"id": "https://openalex.org/W4205617282", "title": "Geophysical Research Letters", "abstract": "Key Points Choice of sea ice thermodynamics does not lead to large differences in sea ice state due to compensating thermodynamic changes Antarctic Bottom Water production increases by 0.5 Sv and upper ocean becomes denser due to increasing salinity with mushy thermodynamics Wintertime air-sea fluxes, atmospheric low-level mixing, and low cloud cover all decrease with mushy thermodynamics", "concepts": ["Geology", "Geophysics", "Climatology", "Atmospheric sciences", "Environmental science", "Oceanography", "Physics", "Quantum mechanics"], "domain": "physics"}
{"id": "https://openalex.org/W2320983896", "title": "Epigenetic Regulations of GABAergic Neurotransmission: Relevance for Neurological Disorders and Epigenetic Therapy", "abstract": "Reelin, a large glycoprotein secreted by telencephalic GABAergic neurons, plays an important role in neuronal guidance embryonically and in synaptic plasticity postnatally. The reeler heterozygous mouse (+/rl) appears superficially normal but has been of interest as an animal model for psychosis since the discovery that reelin is 50% down-regulated in postmortem psychotic brain. Brain abnormalities in +/rl are similar to psychotic brain and include a reduction in glutamic acid de carboxylase 67 (GAD67), dendritic arbors and spine density in cortex and hippocampus, and abnormalities in synaptic function including long-term potentiation (LTP). In spite of these abnormalities, behavioral abnormalities in +/rl are subtle and controversial. Recent findings indicate that the reelin (RELN) and GAD67 promoters are hypermethylated in GABAergic neurons of psychotic postmortem brain and that DNA methyltransferase 1 (DNMT1) is up-regulated. Hypermethlyation of RELN and GAD67 promoters can be induced by treating mice with methionine, and these mice display brain and behavioral abnormalities similar to +/rl. Thus, an animal model that combines genetic heterozygocity with epigenesis holds promise for understanding the role of Reelin down-regulation in psychosis.", "concepts": ["Neuroscience", "Biology", "Psychology", "Psychiatry", "Cell biology", "Genetics", "Biochemistry"], "domain": "environmental_science"}
{"id": "https://openalex.org/W2955311731", "title": "Manajemen Sumber Daya Manusia", "abstract": "The purpose of this study was to determine human resource management in the Madrasah Aliyah Al-Mathitiriyah Rupit District. This type of research is qualitative research with descriptive analytical methods, namely methods that attempt to systematically explain the discussion material originating from various sources for later analysis in order to obtain results as a conclusion. Research Results, principals are very instrumental in increasing and motivating teachers, staff / employees, in improving student achievement, which has been effective and conditional. In providing opportunities and opportunities for the teachers to take part in education and training held by the government and provide opportunities for teachers to continue their higher level of study, Conclusion, the head of MA Al-Mathiriyah carries out, plans, and professionals, as well as field experts, and able to give awards, and provide penalties, if it violates the teacher's code of ethics.&#x0D; Keywords: Human Resource Management, Performance", "concepts": ["Psychology", "Medical education", "Pedagogy", "Political science", "Public relations", "Business", "Knowledge management", "Computer science"], "domain": "psychology"}
{"id": "https://openalex.org/W3012099172", "title": "Aerosol and Surface Stability of SARS-CoV-2 as Compared with SARS-CoV-1", "abstract": "Aerosol and Surface Stability of SARS-CoV-2 In this research letter, investigators report on the stability of SARS-CoV-2 and SARS-CoV-1 under experimental conditions. The viability of the two virus...", "concepts": ["Virology", "Environmental science", "Medicine", "Meteorology", "Physics", "Computer science", "Pathology", "Machine learning"], "domain": "physics"}
{"id": "https://openalex.org/W4360620450", "title": "Opinion Paper: “So what if ChatGPT wrote it?” Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy", "abstract": "Transformative artificially intelligent tools, such as ChatGPT, designed to generate sophisticated text indistinguishable from that produced by a human, are applicable across a wide range of contexts. The technology presents opportunities as well as, often ethical and legal, challenges, and has the potential for both positive and negative impacts for organisations, society, and individuals. Offering multi-disciplinary insight into some of these, this article brings together 43 contributions from experts in fields such as computer science, marketing, information systems, education, policy, hospitality and tourism, management, publishing, and nursing. The contributors acknowledge ChatGPT's capabilities to enhance productivity and suggest that it is likely to offer significant gains in the banking, hospitality and tourism, and information technology industries, and enhance business activities, such as management and marketing. Nevertheless, they also consider its limitations, disruptions to practices, threats to privacy and security, and consequences of biases, misuse, and misinformation. However, opinion is split on whether ChatGPT's use should be restricted or legislated. Drawing on these contributions, the article identifies questions requiring further research across three thematic areas: knowledge, transparency, and ethics; digital transformation of organisations and societies; and teaching, learning, and scholarly research. The avenues for further research include: identifying skills, resources, and capabilities needed to handle generative AI; examining biases of generative AI attributable to training datasets and processes; exploring business and societal contexts best suited for generative AI implementation; determining optimal combinations of human and generative AI for various tasks; identifying ways to assess accuracy of text produced by generative AI; and uncovering the ethical and legal issues in using generative AI across different contexts.", "concepts": ["Knowledge management", "Engineering ethics", "Sociology", "Public relations", "Political science", "Computer science", "Engineering", "Artificial intelligence"], "domain": "computer_science"}
{"id": "https://openalex.org/W2573821892", "title": "Global fire emissions estimates during 1997–2016", "abstract": "<strong class=\"journal-contentHeaderColor\">Abstract.</strong> Climate, land use, and other anthropogenic and natural drivers have the potential to influence fire dynamics in many regions. To develop a mechanistic understanding of the changing role of these drivers and their impact on atmospheric composition, long-term fire records are needed that fuse information from different satellite and in situ data streams. Here we describe the fourth version of the Global Fire Emissions Database (GFED) and quantify global fire emissions patterns during 1997–2016. The modeling system, based on the Carnegie–Ames–Stanford Approach (CASA) biogeochemical model, has several modifications from the previous version and uses higher quality input datasets. Significant upgrades include (1) new burned area estimates with contributions from small fires, (2) a revised fuel consumption parameterization optimized using field observations, (3) modifications that improve the representation of fuel consumption in frequently burning landscapes, and (4) fire severity estimates that better represent continental differences in burning processes across boreal regions of North America and Eurasia. The new version has a higher spatial resolution (0.25°) and uses a different set of emission factors that separately resolves trace gas and aerosol emissions from temperate and boreal forest ecosystems. Global mean carbon emissions using the burned area dataset with small fires (GFED4s) were 2.2 × 10<sup>15</sup> grams of carbon per year (Pg C yr<sup>−1</sup>) during 1997–2016, with a maximum in 1997 (3.0 Pg C yr<sup>−1</sup>) and minimum in 2013 (1.8 Pg C yr<sup>−1</sup>). These estimates were 11 % higher than our previous estimates (GFED3) during 1997–2011, when the two datasets overlapped. This net increase was the result of a substantial increase in burned area (37 %), mostly due to the inclusion of small fires, and a modest decrease in mean fuel consumption (−19 %) to better match estimates from field studies, primarily in savannas and grasslands. For trace gas and aerosol emissions, differences between GFED4s and GFED3 were often larger due to the use of revised emission factors. If small fire burned area was excluded (GFED4 without the <q>s</q> for small fires), average emissions were 1.5 Pg C yr<sup>−1</sup>. The addition of small fires had the largest impact on emissions in temperate North America, Central America, Europe, and temperate Asia. This small fire layer carries substantial uncertainties; improving these estimates will require use of new burned area products derived from high-resolution satellite imagery. Our revised dataset provides an internally consistent set of burned area and emissions that may contribute to a better understanding of multi-decadal changes in fire dynamics and their impact on the Earth system. GFED data are available from <a href=\"http://www.globalfiredata.org\" title=\"\" class=\"ref\">http://www.globalfiredata.org</a>.", "concepts": ["Environmental science", "Atmospheric sciences", "Climatology", "Meteorology", "Geology", "Physics", "Oceanography"], "domain": "engineering"}
{"id": "https://openalex.org/W2742330194", "title": "Fake News Detection on Social Media", "abstract": "Social media for news consumption is a double-edged sword. On the one hand, its low cost, easy access, and rapid dissemination of information lead people to seek out and consume news from social media. On the other hand, it enables the wide spread of \\fake news\", i.e., low quality news with intentionally false information. The extensive spread of fake news has the potential for extremely negative impacts on individuals and society. Therefore, fake news detection on social media has recently become an emerging research that is attracting tremendous attention. Fake news detection on social media presents unique characteristics and challenges that make existing detection algorithms from traditional news media ine ective or not applicable. First, fake news is intentionally written to mislead readers to believe false information, which makes it difficult and nontrivial to detect based on news content; therefore, we need to include auxiliary information, such as user social engagements on social media, to help make a determination. Second, exploiting this auxiliary information is challenging in and of itself as users' social engagements with fake news produce data that is big, incomplete, unstructured, and noisy. Because the issue of fake news detection on social media is both challenging and relevant, we conducted this survey to further facilitate research on the problem. In this survey, we present a comprehensive review of detecting fake news on social media, including fake news characterizations on psychology and social theories, existing algorithms from a data mining perspective, evaluation metrics and representative datasets. We also discuss related research areas, open problems, and future research directions for fake news detection on social media.", "concepts": ["Computer science", "Internet privacy", "Data science", "World Wide Web", "Advertising", "Artificial intelligence", "Business", "Philosophy"], "domain": "materials_science"}
{"id": "https://openalex.org/W2754967293", "title": "Global, regional, and national burden of neurological disorders, 1990–2016: a systematic analysis for the Global Burden of Disease Study 2016", "abstract": "Background: Neurological disorders are increasingly recognised as major causes of death and disability worldwide. The aim of this analysis from the Global Burden of Diseases, Injuries, and Risk Factors Study (GBD) 2016 is to provide the most comprehensive and up-to-date estimates of the global, regional, and national burden from neurological disorders. Methods: We estimated prevalence, incidence, deaths, and disability-adjusted life-years (DALYs; the sum of years of life lost [YLLs] and years lived with disability [YLDs]) by age and sex for 15 neurological disorder categories (tetanus, meningitis, encephalitis, stroke, brain and other CNS cancers, traumatic brain injury, spinal cord injury, Alzheimer's disease and other dementias, Parkinson's disease, multiple sclerosis, motor neuron diseases, idiopathic epilepsy, migraine, tension-type headache, and a residual category for other less common neurological disorders) in 195 countries from 1990 to 2016. DisMod-MR 2.1, a Bayesian meta-regression tool, was the main method of estimation of prevalence and incidence, and the Cause of Death Ensemble model (CODEm) was used for mortality estimation. We quantified the contribution of 84 risks and combinations of risk to the disease estimates for the 15 neurological disorder categories using the GBD comparative risk assessment approach. Findings: Globally, in 2016, neurological disorders were the leading cause of DALYs (276 million [95% UI 247–308]) and second leading cause of deaths (9·0 million [8·8–9·4]). The absolute number of deaths and DALYs from all neurological disorders combined increased (deaths by 39% [34–44] and DALYs by 15% [9–21]) whereas their age-standardised rates decreased (deaths by 28% [26–30] and DALYs by 27% [24–31]) between 1990 and 2016. The only neurological disorders that had a decrease in rates and absolute numbers of deaths and DALYs were tetanus, meningitis, and encephalitis. The four largest contributors of neurological DALYs were stroke (42·2% [38·6–46·1]), migraine (16·3% [11·7–20·8]), Alzheimer's and other dementias (10·4% [9·0–12·1]), and meningitis (7·9% [6·6–10·4]). For the combined neurological disorders, age-standardised DALY rates were significantly higher in males than in females (male-to-female ratio 1·12 [1·05–1·20]), but migraine, multiple sclerosis, and tension-type headache were more common and caused more burden in females, with male-to-female ratios of less than 0·7. The 84 risks quantified in GBD explain less than 10% of neurological disorder DALY burdens, except stroke, for which 88·8% (86·5–90·9) of DALYs are attributable to risk factors, and to a lesser extent Alzheimer's disease and other dementias (22·3% [11·8–35·1] of DALYs are risk attributable) and idiopathic epilepsy (14·1% [10·8–17·5] of DALYs are risk attributable). Interpretation: Globally, the burden of neurological disorders, as measured by the absolute number of DALYs, continues to increase. As populations are growing and ageing, and the prevalence of major disabling neurological disorders steeply increases with age, governments will face increasing demand for treatment, rehabilitation, and support services for neurological disorders. The scarcity of established modifiable risks for most of the neurological burden demonstrates that new knowledge is required to develop effective prevention and treatment strategies. Funding: Bill & Melinda Gates Foundation.", "concepts": ["Medicine", "Environmental health", "Pathology"], "domain": "medicine"}
{"id": "https://openalex.org/W3105982350", "title": "Double-slit photoelectron interference in strong-field ionization of the neon dimer", "abstract": "Wave-particle duality is an inherent peculiarity of the quantum world. The double-slit experiment has been frequently used for understanding different aspects of this fundamental concept. The occurrence of interference rests on the lack of which-way information and on the absence of decoherence mechanisms, which could scramble the wave fronts. In this letter, we report on the observation of two-center interference in the molecular frame photoelectron momentum distribution upon ionization of the neon dimer by a strong laser field. Postselection of ions, which were measured in coincidence with electrons, allowed choosing the symmetry of the continuum electronic wave function, leading to observation of both, gerade and ungerade, types of interference.", "concepts": ["Physics", "Atomic physics", "Quantum mechanics", "Electrical engineering", "Engineering", "Mathematics", "Finance", "Pure mathematics"], "domain": "physics"}
{"id": "https://openalex.org/W2725897987", "title": "Google Earth Engine: Planetary-scale geospatial analysis for everyone", "abstract": "Google Earth Engine is a cloud-based platform for planetary-scale geospatial analysis that brings Google's massive computational capabilities to bear on a variety of high-impact societal issues including deforestation, drought, disaster, disease, food security, water management, climate monitoring and environmental protection. It is unique in the field as an integrated platform designed to empower not only traditional remote sensing scientists, but also a much wider audience that lacks the technical capacity needed to utilize traditional supercomputers or large-scale commodity cloud computing resources.", "concepts": ["Remote sensing", "Computer science", "Data science", "Earth science", "Geography", "Engineering", "Geology", "Cartography"], "domain": "engineering"}
{"id": "https://openalex.org/W3014067025", "title": "Structure of the SARS-CoV-2 spike receptor-binding domain bound to the ACE2 receptor", "abstract": "A new and highly pathogenic coronavirus (severe acute respiratory syndrome coronavirus-2, SARS-CoV-2) caused an outbreak in Wuhan city, Hubei province, China, starting from December 2019 that quickly spread nationwide and to other countries around the world1-3. Here, to better understand the initial step of infection at an atomic level, we determined the crystal structure of the receptor-binding domain (RBD) of the spike protein of SARS-CoV-2 bound to the cell receptor ACE2. The overall ACE2-binding mode of the SARS-CoV-2 RBD is nearly identical to that of the SARS-CoV RBD, which also uses ACE2 as the cell receptor4. Structural analysis identified residues in the SARS-CoV-2 RBD that are essential for ACE2 binding, the majority of which either are highly conserved or share similar side chain properties with those in the SARS-CoV RBD. Such similarity in structure and sequence strongly indicate convergent evolution between the SARS-CoV-2 and SARS-CoV RBDs for improved binding to ACE2, although SARS-CoV-2 does not cluster within SARS and SARS-related coronaviruses1-3,5. The epitopes of two SARS-CoV antibodies that target the RBD are also analysed for binding to the SARS-CoV-2 RBD, providing insights into the future identification of cross-reactive antibodies.", "concepts": ["Computational biology", "Virology", "Biology", "Medicine", "Computer science", "Genetics", "Mathematics", "Internal medicine"], "domain": "environmental_science"}
{"id": "https://openalex.org/W4391602018", "title": "Auto-Encoding Variational Bayes", "abstract": "This paper employs the Auto-Encoding Variational Bayes (AEVB) estimator based on Stochastic Gradient Variational Bayes (SGVB), designed to optimize recognition models for challenging posterior distributions and large-scale datasets. It has been applied to the mnist dataset and extended to form a Dynamic Bayesian Network (DBN) in the context of time series. The paper delves into Bayesian inference, variational methods, and the fusion of Variational Autoencoders (VAEs) and variational techniques. Emphasis is placed on reparameterization for achieving efficient optimization. AEVB employs VAEs as an approximation for intricate posterior distributions.", "concepts": ["Computer science", "Mathematics", "Computational biology", "Artificial intelligence", "Algorithm", "Biology"], "domain": "mathematics"}
{"id": "https://openalex.org/W4293236393", "title": "Contabilidade de Custos", "abstract": "O estudo apresentou a importância da existência de um sistema que otimize os custos na atividade agrícola em pequenas propriedades. Diante de um cenário altamente competitivo, faz-se necessário aprofundar o conhecimento sobre o custeio da produção para que a empresa tenha os devidos conhecimentos sobre o potencial de seu negócio para melhor visão de tomadas de decisões futuras. Neste contexto, o trabalho apresenta um estudo de caso de uma pequena propriedade de cunho familiar localizada no município de Campo Grande/MS. A pesquisa tem o intuito de retratar como a utilização do ponto de equilíbrio pode auxiliar a gestão em uma propriedade rural. Para que o objetivo fosse atingido, foi necessário a apuração dos custos fixos e variáveis, assim como a receita bruta do empreendimento. Em relação à metodologia, utilizou-se de um estudo de caso, quanto a forma da abordagem do problema, uma pesquisa qualitativa e ao tipo de pesquisa, a bibliográfica. Os resultados obtidos do estudo evidenciam que a utilização de ferramentas de controle na apuração dos custos auxilia na gestão da propriedade e contribui para a otimização dos resultados.", "concepts": ["Humanities", "Philosophy", "Political science"], "domain": "social_sciences"}
{"id": "https://openalex.org/W4396625320", "title": "Development of a Cost-Effective Coconut Dehusking Machine", "abstract": "This study aimed to develop an affordable mechanized solution to address this challenge.A coconut dehusking machine prototype was designed, fabricated, and tested. It consists of a rigid steel frame, two counter- rotating cylindrical drums fitted with spikes, an electric motor, a V-belt drive system, and a control panel. Components were sized through structural and mechanical calculations. Fabrication utilized locally sourced materials within a 250,000 NGN budget.Testing showed the machine achieving 90% dehusking efficiency at 120 nuts/hour. Operational costs are minimized through a 1.5HP electric motor. Finite element analysis verified the structural integrity of machine components under operational loads.Results indicate the objectives of developing an affordable and efficient mechanized solution were achieved. Widespread adoption has the prospect of enhancing coconut farming viability, boosting rural livelihoods, and promoting agro- industrialization in Nigeria through coconut value addition. This study demonstrates how appropriately designed technology can support sustainable agricultural development in resource-constrained communities.", "concepts": ["Mathematics", "Computer science"], "domain": "mathematics"}
{"id": "https://openalex.org/W2982303713", "title": "Guidelines for the Early Management of Patients With Acute Ischemic Stroke: 2019 Update to the 2018 Guidelines for the Early Management of Acute Ischemic Stroke: A Guideline for Healthcare Professionals From the American Heart Association/American Stroke Association", "abstract": "Background and Purpose- The purpose of these guidelines is to provide an up-to-date comprehensive set of recommendations in a single document for clinicians caring for adult patients with acute arterial ischemic stroke. The intended audiences are prehospital care providers, physicians, allied health professionals, and hospital administrators. These guidelines supersede the 2013 Acute Ischemic Stroke (AIS) Guidelines and are an update of the 2018 AIS Guidelines. Methods- Members of the writing group were appointed by the American Heart Association (AHA) Stroke Council's Scientific Statements Oversight Committee, representing various areas of medical expertise. Members were not allowed to participate in discussions or to vote on topics relevant to their relations with industry. An update of the 2013 AIS Guidelines was originally published in January 2018. This guideline was approved by the AHA Science Advisory and Coordinating Committee and the AHA Executive Committee. In April 2018, a revision to these guidelines, deleting some recommendations, was published online by the AHA. The writing group was asked review the original document and revise if appropriate. In June 2018, the writing group submitted a document with minor changes and with inclusion of important newly published randomized controlled trials with >100 participants and clinical outcomes at least 90 days after AIS. The document was sent to 14 peer reviewers. The writing group evaluated the peer reviewers' comments and revised when appropriate. The current final document was approved by all members of the writing group except when relationships with industry precluded members from voting and by the governing bodies of the AHA. These guidelines use the American College of Cardiology/AHA 2015 Class of Recommendations and Level of Evidence and the new AHA guidelines format. Results- These guidelines detail prehospital care, urgent and emergency evaluation and treatment with intravenous and intra-arterial therapies, and in-hospital management, including secondary prevention measures that are appropriately instituted within the first 2 weeks. The guidelines support the overarching concept of stroke systems of care in both the prehospital and hospital settings. Conclusions- These guidelines provide general recommendations based on the currently available evidence to guide clinicians caring for adult patients with acute arterial ischemic stroke. In many instances, however, only limited data exist demonstrating the urgent need for continued research on treatment of acute ischemic stroke.", "concepts": ["Medicine", "Emergency medicine", "Intensive care medicine", "Medical emergency", "Cardiology", "Nursing", "Pathology", "Mechanical engineering"], "domain": "medicine"}
{"id": "https://openalex.org/W2106525823", "title": "Graph-based approach for airborne light detection and ranging segmentation", "abstract": "A graph-based segmentation technique has been tailored to segment airborne LiDAR points which, unlike images, are irregularly distributed. In our method, every LiDAR point is labeled as a node and interconnected as a graph extended to its neighborhood, defined in a 4-D feature space: the spatial coordinates (x,y,z) and the reflection intensity. The interconnections between pairs of neighboring nodes are weighted based on the distance in the feature space. The segmentation consists of an iterative process of classification of nodes into homogeneous groups based on their similarity. This approach is intended to be part of a complete system for the classification of structures from LiDAR point clouds in applications needing fast response times. In this sense, a study of the performance/accuracy trade-off has been performed, extracting some conclusions about the benefits of the proposed solution. In addition, an interlaced graph-based approach is proposed to increase the reliability in general purpose segmentations.", "concepts": ["Computer science", "Artificial intelligence", "Computer vision", "Remote sensing", "Geology", "Theoretical computer science", "Telecommunications"], "domain": "engineering"}
{"id": "https://openalex.org/W2891378911", "title": "PRISMA Extension for Scoping Reviews (PRISMA-ScR): Checklist and Explanation", "abstract": "Scoping reviews, a type of knowledge synthesis, follow a systematic approach to map evidence on a topic and identify main concepts, theories, sources, and knowledge gaps. Although more scoping reviews are being done, their methodological and reporting quality need improvement. This document presents the PRISMA-ScR (Preferred Reporting Items for Systematic reviews and Meta-Analyses extension for Scoping Reviews) checklist and explanation. The checklist was developed by a 24-member expert panel and 2 research leads following published guidance from the EQUATOR (Enhancing the QUAlity and Transparency Of health Research) Network. The final checklist contains 20 essential reporting items and 2 optional items. The authors provide a rationale and an example of good reporting for each item. The intent of the PRISMA-ScR is to help readers (including researchers, publishers, commissioners, policymakers, health care providers, guideline developers, and patients or consumers) develop a greater understanding of relevant terminology, core concepts, and key items to report for scoping reviews.", "concepts": ["Medicine", "Medical education", "Management science", "Knowledge management", "Process management", "Psychology", "Computer science", "Engineering"], "domain": "materials_science"}
{"id": "https://openalex.org/W2895486342", "title": "The UK Biobank resource with deep phenotyping and genomic data", "abstract": "Abstract The UK Biobank project is a prospective cohort study with deep genetic and phenotypic data collected on approximately 500,000 individuals from across the United Kingdom, aged between 40 and 69 at recruitment. The open resource is unique in its size and scope. A rich variety of phenotypic and health-related information is available on each participant, including biological measurements, lifestyle indicators, biomarkers in blood and urine, and imaging of the body and brain. Follow-up information is provided by linking health and medical records. Genome-wide genotype data have been collected on all participants, providing many opportunities for the discovery of new genetic associations and the genetic bases of complex traits. Here we describe the centralized analysis of the genetic data, including genotype quality, properties of population structure and relatedness of the genetic data, and efficient phasing and genotype imputation that increases the number of testable variants to around 96 million. Classical allelic variation at 11 human leukocyte antigen genes was imputed, resulting in the recovery of signals with known associations between human leukocyte antigen alleles and many diseases.", "concepts": ["Biology", "Genetics", "Medicine", "Environmental health", "Computer science", "Machine learning"], "domain": "biology"}
{"id": "https://openalex.org/W4387937121", "title": "Developmental Pragmatics", "abstract": "Developmental pragmatics can be understood as growing the skills of using a language appropriately in context. In other words, it concerns the evolution of abilities to cope with the interplay between language, language users, and context. To become pragmatically competent, language users need to have linguistic resources, understand the context of interaction, and employ the resources in the context appropriately. This competence takes time to develop, which is the focus of developmental pragmatics research. Researchers in this field study how language users improve pragmatic competence over time or what contextual factors affect the development of pragmatic competence. Different points of time are the key to revealing the development of pragmatic competence and distinguishing developmental pragmatics from other subfields of pragmatics. These different points of time can be indicated by language users’ ages or language proficiency levels. Language users can develop their pragmatic competence in a first language or a second language. This article is organized around two broad topics—first language pragmatic development and second language pragmatic development. Under these two general topics are more specific subtopics about preverbal pragmatic development, development of conversation organization, communicative acts, pragmatic awareness, among others.", "concepts": ["Linguistics", "Computer science", "Psychology", "Communication", "Social psychology", "Philosophy"], "domain": "psychology"}
{"id": "https://openalex.org/W2549976854", "title": "Ultrastructural Characterization of the Lower Motor System in a Mouse Model of Krabbe Disease", "abstract": "Abstract Krabbe disease (KD) is a neurodegenerative disorder caused by the lack of β- galactosylceramidase enzymatic activity and by widespread accumulation of the cytotoxic galactosyl-sphingosine in neuronal, myelinating and endothelial cells. Despite the wide use of Twitcher mice as experimental model for KD, the ultrastructure of this model is partial and mainly addressing peripheral nerves. More details are requested to elucidate the basis of the motor defects, which are the first to appear during KD onset. Here we use transmission electron microscopy (TEM) to focus on the alterations produced by KD in the lower motor system at postnatal day 15 (P15), a nearly asymptomatic stage, and in the juvenile P30 mouse. We find mild effects on motorneuron soma, severe ones on sciatic nerves and very severe effects on nerve terminals and neuromuscular junctions at P30, with peripheral damage being already detectable at P15. Finally, we find that the gastrocnemius muscle undergoes atrophy and structural changes that are independent of denervation at P15. Our data further characterize the ultrastructural analysis of the KD mouse model, and support recent theories of a dying-back mechanism for neuronal degeneration, which is independent of demyelination.", "concepts": ["Biology", "Pathology", "Cell biology", "Neuroscience", "Anatomy", "Medicine"], "domain": "environmental_science"}
{"id": "https://openalex.org/W147232447", "title": "The<i>Gaia</i>mission", "abstract": "Gaia is a cornerstone mission in the science programme of the EuropeanSpace Agency (ESA). The spacecraft construction was approved in 2006, following a study in which the original interferometric concept was changed to a direct-imaging approach. Both the spacecraft and the payload were built by European industry. The involvement of the scientific community focusses on data processing for which the international Gaia Data Processing and Analysis Consortium (DPAC) was selected in 2007. Gaia was launched on 19 December 2013 and arrived at its operating point, the second Lagrange point of the Sun-Earth-Moon system, a few weeks later. The commissioning of the spacecraft and payload was completed on 19 July 2014. The nominal five-year mission started with four weeks of special, ecliptic-pole scanning and subsequently transferred into full-sky scanning mode. We recall the scientific goals of Gaia and give a description of the as-built spacecraft that is currently (mid-2016) being operated to achieve these goals. We pay special attention to the payload module, the performance of which is closely related to the scientific performance of the mission. We provide a summary of the commissioning activities and findings, followed by a description of the routine operational mode. We summarise scientific performance estimates on the basis of in-orbit operations. Several intermediate Gaia data releases are planned and the data can be retrieved from the Gaia Archive, which is available through the Gaia home page.", "concepts": ["Physics", "Aeronautics", "Remote sensing", "Astronomy", "Computer science", "Engineering", "Computer network", "Geology"], "domain": "engineering"}
{"id": "https://openalex.org/W4384464487", "title": "Students’ voices on generative AI: perceptions, benefits, and challenges in higher education", "abstract": "Abstract This study explores university students’ perceptions of generative AI (GenAI) technologies, such as ChatGPT, in higher education, focusing on familiarity, their willingness to engage, potential benefits and challenges, and effective integration. A survey of 399 undergraduate and postgraduate students from various disciplines in Hong Kong revealed a generally positive attitude towards GenAI in teaching and learning. Students recognized the potential for personalized learning support, writing and brainstorming assistance, and research and analysis capabilities. However, concerns about accuracy, privacy, ethical issues, and the impact on personal development, career prospects, and societal values were also expressed. According to John Biggs’ 3P model, student perceptions significantly influence learning approaches and outcomes. By understanding students’ perceptions, educators and policymakers can tailor GenAI technologies to address needs and concerns while promoting effective learning outcomes. Insights from this study can inform policy development around the integration of GenAI technologies into higher education. By understanding students’ perceptions and addressing their concerns, policymakers can create well-informed guidelines and strategies for the responsible and effective implementation of GenAI tools, ultimately enhancing teaching and learning experiences in higher education.", "concepts": ["Psychology", "Engineering ethics", "Medical education", "Pedagogy", "Political science", "Engineering", "Medicine", "Business"], "domain": "psychology"}
{"id": "https://openalex.org/W4361204578", "title": "A SWOT analysis of ChatGPT: Implications for educational practice and research", "abstract": "ChatGPT is an AI tool that has sparked debates about its potential implications for education. We used the SWOT analysis framework to outline ChatGPT's strengths and weaknesses and to discuss its opportunities for and threats to education. The strengths include using a sophisticated natural language model to generate plausible answers, self-improving capability, and providing personalised and real-time responses. As such, ChatGPT can increase access to information, facilitate personalised and complex learning, and decrease teaching workload, thereby making key processes and tasks more efficient. The weaknesses are a lack of deep understanding, difficulty in evaluating the quality of responses, a risk of bias and discrimination, and a lack of higher-order thinking skills. Threats to education include a lack of understanding of the context, threatening academic integrity, perpetuating discrimination in education, democratising plagiarism, and declining high-order cognitive skills. We provide agenda for educational practice and research in times of ChatGPT.", "concepts": ["Pedagogy", "Sociology", "Psychology", "Engineering ethics", "Mathematics education", "Engineering", "Business", "Marketing"], "domain": "psychology"}
{"id": "https://openalex.org/W4389560718", "title": "2. Diagnosis and Classification of Diabetes: <i>Standards of Care in Diabetes—2024</i>", "abstract": "The American Diabetes Association (ADA) \"Standards of Care in Diabetes\" includes the ADA's current clinical practice recommendations and is intended to provide the components of diabetes care, general treatment goals and guidelines, and tools to evaluate quality of care. Members of the ADA Professional Practice Committee, an interprofessional expert committee, are responsible for updating the Standards of Care annually, or more frequently as warranted. For a detailed description of ADA standards, statements, and reports, as well as the evidence-grading system for ADA's clinical practice recommendations and a full list of Professional Practice Committee members, please refer to Introduction and Methodology. Readers who wish to comment on the Standards of Care are invited to do so at professional.diabetes.org/SOC.", "concepts": ["Medicine", "Family medicine", "Medical education", "Nursing", "Engineering ethics", "Engineering", "Civil engineering", "Political science"], "domain": "social_sciences"}
{"id": "https://openalex.org/W4392622986", "title": "Factors Associated with Membership in a Mutual Health Insurance Fund in the Thiès Region (Senegal) in 2023: Article", "abstract": " Introduction : Mutual health insurance constitutes a micro-insurance system which facilitates access to care by avoiding direct payment. They represent one of the pillars of our Universal Health Coverage. After years of existence and despite political commitment, community support for mutual health insurance remains low until now. The objective of our work was to study the factors linked to the membership of mutual health insurance companies in the Thiès region and to propose solutions.  Methodology : The study was cross-sectional, descriptive and analytical. It was carried out among a sample of 1,300 people, residing in the Thiès region for at least 6 months, chosen following a three-stage cluster survey. A questionnaire was used to collect data related to predisposing, facilitating and health system factors. These data were entered and analyzed using SPSS version 21 software. The significance value was P &lt; 0.05. The Odds ratio was used to measure the strength of the link.  Results : The average age is 42 years and among the people surveyed 75.3% lived in an urban area, 84.5% claimed to know mutual insurance companies. The number of dependent children among the people surveyed was 9 and 90% had an income-generating activity, married people were 82.9% and 78.2% were educated. The mutual penetration rate was 69.3%. The analysis showed that membership in mutual health insurance was significantly influenced by the area of residence with P &lt; 0.001 [OR: 2.0; CI:1.4-2.8], by age group with P &lt; 0.001[OR:1.4; CI:1.1-2.0], by income-generating activity with P &lt; 0.001 [OR:2.1; CI:1.1-4.1], by knowledge of a mutual with P &lt; 0.001 [OR:81.6; CI: 42.2-157] and education with P &lt; 0.001 [OR: 1.9; CI: 1.3-2.6]. Membership was also associated with marital status and the number of children in care with P &lt; 0.001 and P &lt; 0.002 respectively.  Conclusion : This study made it possible to evaluate the penetration rate of mutual health insurance in the Thiès region in 2023, but also to identify the factors associated with membership in a mutual health insurance. Strengthening communication and targeted awareness and improving the level of knowledge of the populations will help to boost the level of support of the populations of the Thiès region.", "concepts": ["Actuarial science", "Business", "Economics", "Finance", "Economic growth"], "domain": "economics"}
{"id": "https://openalex.org/W4322499406", "title": "Tractatus Logico-Philosophicus", "abstract": "Tractatus Logico-Philosophicus by Ludwig Wittgenstein: Three parallel tree-structured editions. (1) Tree-structured arrangement of the German text, edited by David G. Stern, Joachim Schulte and Katia Saporiti. (2) Tree-structured arrangement of the English translation by Ogden and Ramsey, edited by David G. Stern. (3) Tree-structured arrangement of the English translation by Pears and McGuinness, edited by David G. Stern.", "concepts": ["Computer science", "Philosophy", "Linguistics", "History", "Mathematics", "Combinatorics", "Physics", "Ancient history"], "domain": "biology"}
{"id": "https://openalex.org/W4392240262", "title": "Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond", "abstract": "This article presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs) in their downstream Natural Language Processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from the perspectives of models, data, and downstream tasks. First, we offer an introduction and brief summary of current language models. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a detailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as knowledge-intensive tasks, traditional natural language understanding tasks, generation tasks, emergent abilities, and considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and limitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated with each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such as efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide aims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the successful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly updated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide . An LLMs evolutionary tree, editable yet regularly updated, can be found at llmtree.ai .", "concepts": ["Data science", "Geography", "Political science", "Computer science", "Quantum mechanics", "Physics"], "domain": "computer_science"}
{"id": "https://openalex.org/W2969542839", "title": "The 2019 WHO classification of tumours of the digestive system", "abstract": "The WHO classification of digestive system tumours presented in the first volume of the WHO classification of tumours series, 5th edition, reflects important advancements in our understanding of tumours of the digestive system (Table 1). For the first time, certain tumour types are defined as much by their molecular phenotype as their histological characteristics; however, in most instances histopathological classification remains the gold standard for diagnosis. The WHO classification of tumours series is designed to be used worldwide, including those settings where a lack of tissue samples or of specific technical facilities limits the pathologist's ability to rely on molecular testing. Since the publication of the 4th-edition digestive system tumours volume in 2010,1 there have been important developments in our understanding of the aetiology and pathogenesis of many tumours. However, the extent to which this new information has altered clinical practice has been quite variable. For some of the tumours described in this volume there is little molecular pathology in clinical use, despite the fact that we now have a more detailed understanding of their molecular pathogenesis. A tumour's molecular pathology, as defined for the purposes of this publication, concerns the molecular markers that are relevant to the tumour's diagnosis, biological behaviour, outcome and treatment, rather than its molecular pathogenesis. However, the role of molecular pathology is expanding; for some tumour entities, molecular analysis is now essential for establishing an accurate diagnosis. Some of these analyses require investigation of somatic (acquired) genetic alterations, gene or protein expression, or even circulating tumour markers. For certain tumour types, specific analytical tests are needed to predict prognosis or tumour progression, and these tests are carefully outlined in this volume. In the following paragraphs, we have summarised some of the more notable changes since the 4th edition. In instances where the new WHO classification of tumours editorial board determined that there was insufficient evidence of the diagnostic or clinical relevance of new information about a particular tumour entity, the position held in the 4th edition has been maintained as the standard in the new volume. There has been substantial progress in our understanding of the development of glandular oesophageal neoplasia and the sequential neoplastic progression from inflammation to metaplasia (Barrett's oesophagus), dysplasia and, ultimately, adenocarcinoma. This process is initially driven by gastro-oesophageal reflux disease, which leads to reprogramming of cell differentiation and proliferation in the oesophagus. There is evidence that TP53 mutation in proliferating epithelium leads to high-grade dysplasia, while SMAD4 mutation precedes the development of invasive carcinoma. While demonstration of these mutations is not required clinically, testing oesophageal and gastric adenocarcinomas for ERBB2 [human epidermal growth factor receptor 2 (HER2)] is recommended, as this influences treatment decisions. The pathogenesis of precursor lesions is less clear in oesophageal squamous carcinogenesis than in gastric carcinogenesis. Environmental factors are believed to play an important role, but the mechanisms of neoplastic change as a result of specific factors, such as tobacco use and alcohol consumption, are poorly understood. For example, human papillomavirus (HPV) infection was initially believed to play a key role in squamous carcinogenesis, but recent evidence suggests that there is no such association in most cases of oesophageal squamous cell carcinoma. The molecular pathway of cancer progression in the stomach is less clear. Most epidemic gastric cancers are now considered inflammation-driven, and their aetiology is characteristically environmental – usually related to Helicobacter pylori infection. It is because of this infectious aetiology that gastric cancer is included among the limited number of highly lethal, but preventable, cancers. Chronic gastric inflammation leads to changes in the microenvironment (including the microbiome) that results in mucosal atrophy/metaplasia, which may then progress to neoplasia after further molecular alterations. Metaplastic changes in the upper gastrointestinal tract are well-recognised as early cancer precursors, but their precise molecular mechanisms and the exact role of progenitor cells in the oncogenic cascade remain a subject of intense investigation. For some rare tumours, distinctive driver mutations have been identified; for example, the characteristic MALAT1–GLI1 fusion gene in gastroblastoma and EWSR1 fusions in gastrointestinal clear cell sarcoma and malignant gastrointestinal neuroectodermal tumour. In both examples, demonstration of the fusion gene is now required for the diagnosis. The pathogenesis of adenocarcinomas of the intestines (the small and large bowel and the appendix) is now much better delineated than it was a decade ago. The introduction of population-based screening for colorectal cancer has laid the foundation for a better understanding of neoplastic precursor lesions and the molecular pathways associated with each type of tumour. For example, our knowledge of the molecular pathways and biological behaviour of conventional adenomas and serrated precursor lesions, including the recently renamed sessile serrated lesion (formerly called sessile serrated polyp/adenoma), has grown rapidly in the past decade, and this has enabled clinicians to provide tailored, evidence-driven screening and surveillance programmes. Colorectal cancers, in which it will make a difference to patient treatment, should undergo molecular testing for microsatellite instability and extended RAS testing for mutations in KRAS, NRAS and BRAF. Our understanding of appendiceal tumours has also improved. For example, we now know that many tumours of the appendix develop via neoplastic precursor lesions similar to those in the small and large intestines, and the biological potential and molecular pathways of appendiceal tumours are therefore much better appreciated. The recently renamed goblet cell adenocarcinoma (formerly called goblet cell carcinoid/carcinoma) of the appendix is a prime example of a tumour whose biological potential and histological characteristics have been better described, resulting in improvements in the pathological approach to these tumours. Studies of the aetiology and pathogenesis of anal squamous lesions suggests that HPV infection plays an important aetiological role, driving genetic alterations similar to those in cervical cancer. p16 and HPV testing are recommended for such lesions. One particularly important change in the 5th edition is in the classification of neuroendocrine neoplasms (NENs), which occur in multiple sites throughout the body. In this volume, NENs are covered within each organ-specific chapter, including the chapter on tumours of the pancreas, where detailed sections describing each functioning and non-functioning subtype are provided. Previously, these neoplasms were covered only in the volume on tumours of endocrine organs.2 The general principles guiding the classification of all NENs are presented in a separate introduction to this topic (Table 2). To consolidate our increased understanding of the genetics of these neoplasms, a group of experts met for a consensus conference at the International Agency for Research on Cancer (IARC) in November 2017 and subsequently published a paper in which they proposed distinguishing between well-differentiated neuroendocrine tumours (NETs) and poorly differentiated neuroendocrine carcinomas (NECs) in all sites where these neoplasms arise.3 NEN are divided into NET and NECs, based on their molecular differences. Mutations in MEN1, DAXX and ATRX are entity-defining for well-differentiated NETs, whereas NECs usually have TP53 or RB1 mutations. In some cases, these mutations can be of diagnostic benefit. Genomic data have also led to a change in the classification of mixed NENs, which are now grouped into the conceptual category of 'mixed neuroendocrine–non-neuroendocrine neoplasms (MiNENs)'. Mixed adenoneuroendocrine carcinomas (MANECs), which show genomic alterations similar to those of adenocarcinomas or NECs rather than NETs, probably reflect clonal evolution within the tumours, which is a rapidly growing area of interest. The study of these mixed carcinomas may also lead to an improved understanding of other facets of clonality in tumours of the digestive system and other parts of the body. Another important change concerns the recognition that well-differentiated NETs may be high grade (G3 in the WHO grading system, defined as having a mitotic rate >20 per 2 mm2 or Ki67 >20%), but these neoplasms remain well-differentiated genetically and distinct from poorly differentiated NECs. G3 NETs were first recognised and are most common in the pancreas, but they can occur throughout the GI tract. Thus, the current WHO classification includes three grades (G1, G2 and G3) for NETs. NECs are no longer graded, as they are recognised to be uniformly high grade by definition, but continue to be separated into small-and large-cell types. There are certain terms in current day-to-day use about which many pathologists continue to disagree. The editorial board carefully considered our current understanding of carcinogenetic pathways when considering the use of specific terms and definitions. In general, the overall consensus was that established terms, definitions and criteria should not be changed unless there was strong evidence to support doing so and the proposed changes had clinical relevance. For some tumours, our understanding of the progression from normal epithelium to metastatic carcinoma remains inadequate. For example, in certain tumours the line between benign and malignant can be ambiguous, and in some cases the distinction is more definitional than biological. These are some of the many areas of tumour biology that need to be more fully investigated in the future. In the 5th edition, the terminology for precursors to invasive carcinoma in the digestive system has been standardised somewhat, although the terms 'dysplasia' and 'intra-epithelial neoplasia' are both still considered acceptable for lesions in certain anatomical locations, in acknowledgement of their ongoing clinical acceptance. For example, the term 'dysplasia' is preferred for lesions in the tubular gut, whereas 'intra-epithelial neoplasia' is preferred for those in the pancreas, gallbladder and biliary tree. For all anatomical sites, however, a two-tiered system (low- versus high-grade) is considered the standard grading system for neoplastic precursor lesions. This has replaced the three-tiered grading scheme previously used for lesions in the pancreatobiliary system.4 The term 'carcinoma in situ' continues to be strongly discouraged in clinical practice for a variety of reasons, most notably its clinical ambiguity. This term is encompassed by the category of high-grade dysplasia/intraepithelial neoplasia. Many refinements of the 4th-edition classification have been made concerning liver tumours, supported by novel molecular findings. For example, a comprehensive picture of the molecular changes that occur in common hepatocellular carcinoma has recently emerged from large-scale molecular profiling studies. Meanwhile, several rarer hepatocellular carcinoma subtypes, which together may account for 20–30% of cases, have been defined by consistent morphomolecular and clinical features, with fibrolamellar carcinoma and its diagnostic DNAJB1–PRKACA translocation being one prime example. Intrahepatic cholangiocarcinoma is now understood to be an anatomically defined entity with two different major subtypes: a large duct type, which resembles extrahepatic cholangiocarcinoma, and a small duct type, which shares significant aetiological, pathogenetic and imaging characteristics with hepatocellular carcinoma. The two subtypes have very different aetiologies, molecular alterations, growth patterns and clinical behaviours, exemplifying the conflict between anatomically and histogenetically/pathogenetically based classifications. Clinical research and study protocols will need to incorporate these findings in the near future. Also supported by molecular findings, the definition of combined hepatocellular–cholangiocarcinoma and its distinction from other entities has recently become clearer. Cholangiolocellular carcinoma is no longer considered a subtype of combined hepatocellular–cholangiocarcinoma, but rather a subtype of small duct intrahepatic cholangiocarcinoma, renamed cholangiolocarcinoma, meaning that all intrahepatic carcinomas with a ductal or tubular phenotype are now included within the category of intrahepatic cholangiocarcinoma. A classic example of morphology-based molecular profiling leading to a new classification based on a combination of biological and molecular factors is the classification of hepatocellular adenomas, which has gained a high degree of clinical relevance and has fuelled the implementation of refined morphological criteria and molecular testing in routine diagnostics. Most of the classification of pancreatic neoplasms in the 5th edition remains unchanged from the last volume. As highlighted above, precursor lesions including pancreatic intraepithelial neoplasia, intraductal papillary mucinous neoplasms and mucinous cystic neoplasms are now classified into two tiers of dysplasia, based on the highest grade of dysplasia detected, rather than the three-tier system used in the last edition of the WHO classification. Intraductal oncocytic papillary neoplasm and intraductal tubulopapillary neoplasms are now separated from the other subtypes of intraductal papillary mucinous neoplasm based on their distinct genomic and morphological features. The prior entity of acinar cell cystadenoma, which has recently been demonstrated to be non-neoplastic by molecular clonality analysis, is now termed 'acinar cystic transformation of the pancreas'. Also, the entire spectrum of pancreatic neuroendocrine neoplasms is now included in this volume; previously, details concerning the individual functional types were presented in the WHO classification of tumours of the endocrine organs. Mixed tumours in several anatomical sites (e.g. oesophageal adenosquamous carcinoma and mucoepidermoid carcinoma, as well as hepatic carcinomas with mixed hepatocellular and cholangiocellular differentiation), remain subjects of some uncertainty. The relative importance of the various lineages of differentiation within these neoplasms remains unknown. It is also uncertain how these neoplasms develop and how they should be treated. These issues are a matter of debate because hard evidence is lacking, but there are improvements in the pathological criteria and classification of these neoplasms that should help to standardise the diagnostic approach and facilitate better clinical and genomic research. Each of these tumour types is grouped together in separate chapters. This ensures consistency and avoids duplication. The term 'EBV positive inflammatory follicular dendritic cell sarcoma of the digestive tract' has been adopted to replace the entity previously known as 'inflammatory pseudotumour-like fibroblastic/follicular dendritic cell tumour'. New in this book is the chapter on genetic tumour syndromes of the digestive system, the introduction to which contains a table that lists each of the major syndromes and summarises key information about the disease/phenotype, pattern of inheritance, causative gene(s) and normal function of the encoded protein(s). Common syndromes, including Lynch syndrome and familial adenomatous polyposis 1 (FAP), are covered in detail, as well as several other adenomatous polyposes defined since the last volume and the GAPPS (gastric adenocarcinoma and proximal polyposis of the stomach) syndrome, now recognised as a FAP variant, with a unique phenotype. A number of other genetic tumour predisposition syndromes that confer a raised risk of various gastrointestinal tumours are also described, including Li–Fraumeni syndrome, hereditary haemorrhagic telangiectasia, syndromes associated with gastroenteropancreatic NETs and multilocus inherited neoplasia alleles syndrome. This should be helpful to many involved in the diagnosis of such syndromes, as well as those researching the mechanisms involved. The format of the books has been updated to reflect the new edition of the classification: the move from three to two columns has allowed larger illustrations, and the use of set headings for each tumour type show very clearly where evidence is lacking. The content of this article represents the personal views of the authors and does not represent the views of the authors' employers and associated institutions. Where authors are identified as personnel of the International Agency for Research on Cancer/World Health Organization, the authors alone are responsible for the views expressed in this article and do not necessarily represent the decisions, policy or views of the International Agency for Research on Cancer/World Health Organization. I.D.N. reports that her institute benefits from research funding from the Dutch Cancer Society (KWF) and the Dutch Digestive Foundation (MLDS). No other authors report any conflicts of interest to IARC that would affect their participation in forming the classification.", "concepts": ["Library science", "Political science", "Medicine", "Management", "Sociology", "Social science", "Computer science", "Internal medicine"], "domain": "economics"}
{"id": "https://openalex.org/W4392762752", "title": "APOE4/4 is linked to damaging lipid droplets in Alzheimer’s disease microglia", "abstract": "Abstract Several genetic risk factors for Alzheimer’s disease implicate genes involved in lipid metabolism and many of these lipid genes are highly expressed in glial cells 1 . However, the relationship between lipid metabolism in glia and Alzheimer’s disease pathology remains poorly understood. Through single-nucleus RNA sequencing of brain tissue in Alzheimer’s disease, we have identified a microglial state defined by the expression of the lipid droplet-associated enzyme ACSL1 with ACSL1-positive microglia being most abundant in patients with Alzheimer’s disease having the APOE4/4 genotype. In human induced pluripotent stem cell-derived microglia, fibrillar Aβ induces ACSL1 expression, triglyceride synthesis and lipid droplet accumulation in an APOE-dependent manner. Additionally, conditioned media from lipid droplet-containing microglia lead to Tau phosphorylation and neurotoxicity in an APOE-dependent manner. Our findings suggest a link between genetic risk factors for Alzheimer’s disease with microglial lipid droplet accumulation and neurotoxic microglia-derived factors, potentially providing therapeutic strategies for Alzheimer’s disease.", "concepts": ["Biology", "Neuroscience", "Cell biology", "Medicine", "Pathology", "Immunology", "Biochemistry", "Internal medicine"], "domain": "computer_science"}
{"id": "https://openalex.org/W3004280078", "title": "A pneumonia outbreak associated with a new coronavirus of probable bat origin", "abstract": "Abstract Since the outbreak of severe acute respiratory syndrome (SARS) 18 years ago, a large number of SARS-related coronaviruses (SARSr-CoVs) have been discovered in their natural reservoir host, bats 1–4 . Previous studies have shown that some bat SARSr-CoVs have the potential to infect humans 5–7 . Here we report the identification and characterization of a new coronavirus (2019-nCoV), which caused an epidemic of acute respiratory syndrome in humans in Wuhan, China. The epidemic, which started on 12 December 2019, had caused 2,794 laboratory-confirmed infections including 80 deaths by 26 January 2020. Full-length genome sequences were obtained from five patients at an early stage of the outbreak. The sequences are almost identical and share 79.6% sequence identity to SARS-CoV. Furthermore, we show that 2019-nCoV is 96% identical at the whole-genome level to a bat coronavirus. Pairwise protein sequence analysis of seven conserved non-structural proteins domains show that this virus belongs to the species of . In addition, 2019-nCoV virus isolated from the bronchoalveolar lavage fluid of a critically ill patient could be neutralized by sera from several patients. Notably, we confirmed that 2019-nCoV uses the same cell entry receptor—angiotensin converting enzyme II (ACE2)—as SARS-CoV.", "concepts": ["Virology", "Biology", "Immunology", "Medicine", "Genetics", "Pathology", "Internal medicine"], "domain": "environmental_science"}
{"id": "https://openalex.org/W4399896625", "title": "Implementation of Total Productive Maintenance on Frame Welding Machine Maintenance Using the Overall Equipment Effectiveness (OEE) Method at PT Electronics Components Indonesia", "abstract": "PT. Electronics Components Indonesia manufactures capacitors and focuses on enhancing productivity and operational efficiency of the frame welding machines through effective maintenance. This study employs a quantitative method to analyze the Overall Equipment Effectiveness (OEE) values, including availability, performance efficiency, and rate of quality, as well as conducting a Six Big Losses analysis. The results indicate that the average availability reached 97.83%, with a significant decrease in August due to downtime. Performance efficiency remained consistently above 90%, although higher product output tended to reduce efficiency. The rate of quality was stable and high, reflecting improvements in production processes and quality control. The average OEE value reached 88%, exceeding the global standard of 85%. To further enhance the effectiveness of the frame welding machines, suggested improvements include operator training, regular performance evaluations, attention to operator well-being, selection of high-quality raw materials, updating SOPs, regular preventive maintenance, improving workplace safety, and investing in backup energy systems. In conclusion, the improvements implemented successfully enhanced the performance and operational quality of the frame welding machines.", "concepts": ["Manufacturing engineering", "Computer science", "Engineering", "Automotive engineering", "Reliability engineering", "Mechanical engineering", "Electrical engineering", "Economics"], "domain": "economics"}
{"id": "https://openalex.org/W4321351832", "title": "Artificial Hallucinations in ChatGPT: Implications in Scientific Writing", "abstract": "While still in its infancy, ChatGPT (Generative Pretrained Transformer), introduced in November 2022, is bound to hugely impact many industries, including healthcare, medical education, biomedical research, and scientific writing. Implications of ChatGPT, that new chatbot introduced by OpenAI on academic writing, is largely unknown. In response to the Journal of Medical Science (Cureus) Turing Test - call for case reports written with the assistance of ChatGPT, we present two cases one of homocystinuria-associated osteoporosis, and the other is on late-onset Pompe disease (LOPD), a rare metabolic disorder. We tested ChatGPT to write about the pathogenesis of these conditions. We documented the positive, negative, and rather troubling aspects of our newly introduced chatbot’s performance.", "concepts": ["Medicine", "Medical education", "Cognitive science", "Linguistics", "Artificial intelligence", "Psychology", "Computer science", "Philosophy"], "domain": "psychology"}
{"id": "https://openalex.org/W4398182947", "title": "A Hand Book of Field and Herbarium Methods", "abstract": "No Abstract.", "concepts": ["History", "Archaeology", "Geography", "Geology", "Paleontology", "Mathematics", "Pure mathematics"], "domain": "mathematics"}
{"id": "https://openalex.org/W4393065402", "title": "A survey on large language model based autonomous agents", "abstract": "Abstract Autonomous agents have long been a research focus in academic and industry communities. Previous research often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from human learning processes, and makes the agents hard to achieve human-like decisions. Recently, through the acquisition of vast amounts of Web knowledge, large language models (LLMs) have shown potential in human-level intelligence, leading to a surge in research on LLM-based autonomous agents. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of LLM-based autonomous agents from a holistic perspective. We first discuss the construction of LLM-based autonomous agents, proposing a unified framework that encompasses much of previous work. Then, we present a overview of the diverse applications of LLM-based autonomous agents in social science, natural science, and engineering. Finally, we delve into the evaluation strategies commonly used for LLM-based autonomous agents. Based on the previous studies, we also present several challenges and future directions in this field.", "concepts": ["Computer science", "Artificial intelligence"], "domain": "computer_science"}
{"id": "https://openalex.org/W2773928770", "title": "A Review of Global Precipitation Data Sets: Data Sources, Estimation, and Intercomparisons", "abstract": "Abstract In this paper, we present a comprehensive review of the data sources and estimation methods of 30 currently available global precipitation data sets, including gauge‐based, satellite‐related, and reanalysis data sets. We analyzed the discrepancies between the data sets from daily to annual timescales and found large differences in both the magnitude and the variability of precipitation estimates. The magnitude of annual precipitation estimates over global land deviated by as much as 300 mm/yr among the products. Reanalysis data sets had a larger degree of variability than the other types of data sets. The degree of variability in precipitation estimates also varied by region. Large differences in annual and seasonal estimates were found in tropical oceans, complex mountain areas, northern Africa, and some high‐latitude regions. Overall, the variability associated with extreme precipitation estimates was slightly greater at lower latitudes than at higher latitudes. The reliability of precipitation data sets is mainly limited by the number and spatial coverage of surface stations, the satellite algorithms, and the data assimilation models. The inconsistencies described limit the capability of the products for climate monitoring, attribution, and model validation.", "concepts": ["Environmental science", "Climatology", "Atmospheric sciences", "Meteorology", "Statistics", "Geography", "Geology", "Mathematics"], "domain": "engineering"}
{"id": "https://openalex.org/W2789843538", "title": "Minimap2: pairwise alignment for nucleotide sequences", "abstract": "Motivation: Recent advances in sequencing technologies promise ultra-long reads of $\\sim$100 kilo bases (kb) in average, full-length mRNA or cDNA reads in high throughput and genomic contigs over 100 mega bases (Mb) in length. Existing alignment programs are unable or inefficient to process such data at scale, which presses for the development of new alignment algorithms. Results: Minimap2 is a general-purpose alignment program to map DNA or long mRNA sequences against a large reference database. It works with accurate short reads of $\\ge$100bp in length, $\\ge$1kb genomic reads at error rate $\\sim$15%, full-length noisy Direct RNA or cDNA reads, and assembly contigs or closely related full chromosomes of hundreds of megabases in length. Minimap2 does split-read alignment, employs concave gap cost for long insertions and deletions (INDELs) and introduces new heuristics to reduce spurious alignments. It is 3-4 times faster than mainstream short-read mappers at comparable accuracy and $\\ge$30 times faster at higher accuracy for both genomic and mRNA reads, surpassing most aligners specialized in one type of alignment. Availability and implementation: https://github.com/lh3/minimap2 Contact: hengli@broadinstitute.org", "concepts": ["Computational biology", "Computer science", "Genetics", "Biology", "Artificial intelligence"], "domain": "biology"}
{"id": "https://openalex.org/W2950595506", "title": "The Gene Ontology Resource: 20 years and still GOing strong", "abstract": "The Gene Ontology resource (GO; http: //geneontology.org)provides structured, computable knowledge regarding the functions of genes and gene products.Founded in 1998, GO has become widely adopted in the life sciences, and its contents are under continual improvement, both in quantity and in quality.Here, we report the major developments of the GO resource during the past two years.Each monthly release of the GO resource is now packaged and given a unique identifier (DOI), enabling GO-based analyses on a specific release to be reproduced in the future.The molecular function ontology has been refactored to better represent the overall activities of gene products, with a focus on transcription regulator activities.Quality assurance efforts have been ramped up to address potentially out-of-date or inaccurate annotations.New evidence codes for high-throughput experiments now enable users to filter out annotations obtained from these sources.GO-CAM, a new framework for representing gene function that is more expressive than standard GO annotations, has been released, and users can now explore the growing repository of these models.We also provide the 'GO ribbon' widget for visualizing GO annotations to a gene; the widget can be easily embedded in any web page.", "concepts": ["Biology", "World Wide Web", "Computational biology", "Computer science", "Data science", "Genetics", "Ecology", "Epistemology"], "domain": "materials_science"}
{"id": "https://openalex.org/W4390976747", "title": "Refractiveindex.info database of optical constants", "abstract": "Abstract We introduce the refractiveindex.info database, a comprehensive open-source repository containing optical constants for a wide array of materials, and describe in detail the underlying dataset. This collection, derived from a meticulous compilation of data sourced from peer-reviewed publications, manufacturers’ datasheets, and authoritative texts, aims to advance research in optics and photonics. The data is stored using a YAML-based format, ensuring integrity, consistency, and ease of access. Each record is accompanied by detailed metadata, facilitating a comprehensive understanding and efficient utilization of the data. In this descriptor, we outline the data curation protocols and the file format used for data records, and briefly demonstrate how the data can be organized in a user-friendly fashion akin to the books in a traditional library.", "concepts": ["Computer science", "Database", "Information retrieval", "World Wide Web", "Data science", "Artificial intelligence"], "domain": "computer_science"}
{"id": "https://openalex.org/W4362521115", "title": "The SCARE 2023 guideline: updating consensus Surgical CAse REport (SCARE) guidelines", "abstract": "The Surgical CAse REport (SCARE) guidelines were first published in 2016 as a tool for surgeons to document and report their surgical cases in a standardised and comprehensive manner. However, with advances in technology and changes in the healthcare landscape, it is important to revise and update these guidelines to ensure they remain relevant and valuable for surgeons.The updated guidelines were produced through a Delphi consensus exercise. Members of the SCARE 2020 guidelines Delphi group, editorial board members, and peer reviewers were invited to participate. Potential contributors were contacted by e-mail. An online survey was completed to indicate their agreement with the proposed changes to the guideline items.A total of 54 participants were invited to participate and 44 (81.5%) completed the survey. There was a high degree of agreement among reviewers, with 36 items (83.7%) meeting the threshold for inclusion.Through a completed Delphi consensus exercise we present the SCARE 2023 guidelines. This will provide surgeons with a comprehensive and up-to-date tool for documenting and reporting their surgical cases while highlighting the importance of patient-centred care.", "concepts": ["Medicine", "Family medicine", "Medical education", "Pathology", "Statistics", "Mathematics", "Computer science", "Political science"], "domain": "social_sciences"}
{"id": "https://openalex.org/W2614464134", "title": "WorldClim 2: new 1‐km spatial resolution climate surfaces for global land areas", "abstract": "ABSTRACT We created a new dataset of spatially interpolated monthly climate data for global land areas at a very high spatial resolution (approximately 1 km 2 ). We included monthly temperature (minimum, maximum and average), precipitation, solar radiation, vapour pressure and wind speed, aggregated across a target temporal range of 1970–2000, using data from between 9000 and 60 000 weather stations. Weather station data were interpolated using thin‐plate splines with covariates including elevation, distance to the coast and three satellite‐derived covariates: maximum and minimum land surface temperature as well as cloud cover, obtained with the MODIS satellite platform. Interpolation was done for 23 regions of varying size depending on station density. Satellite data improved prediction accuracy for temperature variables 5–15% (0.07–0.17 °C), particularly for areas with a low station density, although prediction error remained high in such regions for all climate variables. Contributions of satellite covariates were mostly negligible for the other variables, although their importance varied by region. In contrast to the common approach to use a single model formulation for the entire world, we constructed the final product by selecting the best performing model for each region and variable. Global cross‐validation correlations were ≥ 0.99 for temperature and humidity, 0.86 for precipitation and 0.76 for wind speed. The fact that most of our climate surface estimates were only marginally improved by use of satellite covariates highlights the importance having a dense, high‐quality network of climate station data.", "concepts": ["Environmental science", "Climatology", "Meteorology", "Atmospheric sciences", "Geography", "Statistics", "Mathematics", "Geology"], "domain": "engineering"}
{"id": "https://openalex.org/W4255683973", "title": "2018 Guidelines for the Early Management of Patients With Acute Ischemic Stroke: A Guideline for Healthcare Professionals From the American Heart Association/American Stroke Association", "abstract": "Correction This article has two related Corrections: (10.1161/STR.0000000000000163) (10.1161/STR.0000000000000172)", "concepts": ["Medicine", "Emergency medicine", "Internal medicine", "Intensive care medicine", "Cardiology", "Family medicine", "Pathology", "Epistemology"], "domain": "materials_science"}
{"id": "https://openalex.org/W2412782625", "title": "DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs", "abstract": "In this work we address the task of semantic image segmentation with Deep Learning and make three main contributions that are experimentally shown to have substantial practical merit. First, we highlight convolution with upsampled filters, or 'atrous convolution', as a powerful tool in dense prediction tasks. Atrous convolution allows us to explicitly control the resolution at which feature responses are computed within Deep Convolutional Neural Networks. It also allows us to effectively enlarge the field of view of filters to incorporate larger context without increasing the number of parameters or the amount of computation. Second, we propose atrous spatial pyramid pooling (ASPP) to robustly segment objects at multiple scales. ASPP probes an incoming convolutional feature layer with filters at multiple sampling rates and effective fields-of-views, thus capturing objects as well as image context at multiple scales. Third, we improve the localization of object boundaries by combining methods from DCNNs and probabilistic graphical models. The commonly deployed combination of max-pooling and downsampling in DCNNs achieves invariance but has a toll on localization accuracy. We overcome this by combining the responses at the final DCNN layer with a fully connected Conditional Random Field (CRF), which is shown both qualitatively and quantitatively to improve localization performance. Our proposed \"DeepLab\" system sets the new state-of-art at the PASCAL VOC-2012 semantic image segmentation task, reaching 79.7 percent mIOU in the test set, and advances the results on three other datasets: PASCAL-Context, PASCAL-Person-Part, and Cityscapes. All of our code is made publicly available online.", "concepts": ["Artificial intelligence", "Computer science", "Linguistics", "Philosophy", "Programming language"], "domain": "materials_science"}
{"id": "https://openalex.org/W4327946446", "title": "ChatGPT Utility in Healthcare Education, Research, and Practice: Systematic Review on the Promising Perspectives and Valid Concerns", "abstract": "ChatGPT is an artificial intelligence (AI)-based conversational large language model (LLM). The potential applications of LLMs in health care education, research, and practice could be promising if the associated valid concerns are proactively examined and addressed. The current systematic review aimed to investigate the utility of ChatGPT in health care education, research, and practice and to highlight its potential limitations. Using the PRIMSA guidelines, a systematic search was conducted to retrieve English records in PubMed/MEDLINE and Google Scholar (published research or preprints) that examined ChatGPT in the context of health care education, research, or practice. A total of 60 records were eligible for inclusion. Benefits of ChatGPT were cited in 51/60 (85.0%) records and included: (1) improved scientific writing and enhancing research equity and versatility; (2) utility in health care research (efficient analysis of datasets, code generation, literature reviews, saving time to focus on experimental design, and drug discovery and development); (3) benefits in health care practice (streamlining the workflow, cost saving, documentation, personalized medicine, and improved health literacy); and (4) benefits in health care education including improved personalized learning and the focus on critical thinking and problem-based learning. Concerns regarding ChatGPT use were stated in 58/60 (96.7%) records including ethical, copyright, transparency, and legal issues, the risk of bias, plagiarism, lack of originality, inaccurate content with risk of hallucination, limited knowledge, incorrect citations, cybersecurity issues, and risk of infodemics. The promising applications of ChatGPT can induce paradigm shifts in health care education, research, and practice. However, the embrace of this AI chatbot should be conducted with extreme caution considering its potential limitations. As it currently stands, ChatGPT does not qualify to be listed as an author in scientific articles unless the ICMJE/COPE guidelines are revised or amended. An initiative involving all stakeholders in health care education, research, and practice is urgently needed. This will help to set a code of ethics to guide the responsible use of ChatGPT among other LLMs in health care and academia.", "concepts": ["Medical education", "Psychology", "Medicine", "Computer science", "Political science", "Paleontology", "Computer security", "Database"], "domain": "medicine"}
{"id": "https://openalex.org/W4396834099", "title": "Millet based Nutritious Powder for the Geriatric Population", "abstract": "Objective: This study aimed to utilize finger millet as a primary ingredient for creating nutritious millet powder suitable for hot beverages. Desiccated coconut was incorporated for color enhancement. The optimization process involved sensory evaluation and trials on a laboratory scale. Three variations of millet products and two recipes were developed: one for a beverage made by mixing millet (Ragi/ Finger millet) nutritious powder with hot water, and another for millet nutritious halua powder fortified with nutrients. Additionally, a millet nutritious powder based on Pearl millet was formulated for easy consumption by the ageing population.  Methods: The study involved the preparation and experimentation of three types of millet nutritious powder, derived from finger and pearl millet, targeting the nutritional needs of ageing individuals. Age-related challenges such as esophagus stenosis were taken into account during formulation. The viscosity graphs were utilized to refine the texture of the food, ensuring ease of swallowing. Laboratory-scale trials and benchtop sensory evaluations were conducted to optimize the formulations. The acceptability of the beverages was assessed using a 9-point hedonic scale.  Results: The formulated millet nutritious powders demonstrated excellent nutrient composition, with calcium content exceeding three times that of a cup of milk. The halua powder exhibited low viscosity, high solubility, and excellent swallowing properties. The optimized beverages achieved a total acceptability score exceeding 7 on the hedonic scale, indicating favourable consumer reception. The study successfully developed three variants of millet nutritious powder tailored for aging individuals, addressing concerns related to swallowing difficulties and offering a comfortable dietary option.  Conclusion: In conclusion, this study demonstrates the feasibility of utilizing finger and pearl millet to create nutritious powders suitable for hot beverages, particularly catering to the dietary needs of the aging population. The formulations offer a convenient and easily consumable option for individuals facing challenges with chewing solid food. Moreover, the affordability and widespread accessibility of the developed food products make them suitable for diverse populations, highlighting their potential for addressing nutritional needs on a broader scale.", "concepts": ["Business", "Food science", "Environmental health", "Biotechnology", "Medicine", "Chemistry", "Biology"], "domain": "chemistry"}
{"id": "https://openalex.org/W3183286355", "title": "Sample size determination and power analysis using the G*Power software", "abstract": "Appropriate sample size calculation and power analysis have become major issues in research and publication processes. However, the complexity and difficulty of calculating sample size and power require broad statistical knowledge, there is a shortage of personnel with programming skills, and commercial programs are often too expensive to use in practice. The review article aimed to explain the basic concepts of sample size calculation and power analysis; the process of sample estimation; and how to calculate sample size using G*Power software (latest ver. 3.1.9.7; Heinrich-Heine-Universität Düsseldorf, Düsseldorf, Germany) with 5 statistical examples. The null and alternative hypothesis, effect size, power, alpha, type I error, and type II error should be described when calculating the sample size or power. G*Power is recommended for sample size and power calculations for various statistical methods (F, t, χ2, Z, and exact tests), because it is easy to use and free. The process of sample estimation consists of establishing research goals and hypotheses, choosing appropriate statistical tests, choosing one of 5 possible power analysis methods, inputting the required variables for analysis, and selecting the “calculate” button. The G*Power software supports sample size and power calculation for various statistical methods (F, t, χ2, z, and exact tests). This software is helpful for researchers to estimate the sample size and to conduct power analysis.", "concepts": ["Computer science", "Statistics", "Data mining", "Reliability engineering", "Mathematics", "Algorithm", "Engineering", "Programming language"], "domain": "chemistry"}
{"id": "https://openalex.org/W4391530715", "title": "Achievement of Target Gain Larger than Unity in an Inertial Fusion Experiment", "abstract": "On December 5, 2022, an indirect drive fusion implosion on the National Ignition Facility (NIF) achieved a target gain <a:math xmlns:a=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><a:mrow><a:msub><a:mrow><a:mi>G</a:mi></a:mrow><a:mrow><a:mtext>target</a:mtext></a:mrow></a:msub></a:mrow></a:math> of 1.5. This is the first laboratory demonstration of exceeding “scientific breakeven” (or <c:math xmlns:c=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><c:msub><c:mi>G</c:mi><c:mtext>target</c:mtext></c:msub><c:mo>&gt;</c:mo><c:mn>1</c:mn></c:math>) where 2.05 MJ of 351 nm laser light produced 3.1 MJ of total fusion yield, a result which significantly exceeds the Lawson criterion for fusion ignition as reported in a previous NIF implosion [H. Abu-Shawareb (Indirect Drive ICF Collaboration), ]. This achievement is the culmination of more than five decades of research and gives proof that laboratory fusion, based on fundamental physics principles, is possible. This Letter reports on the target, laser, design, and experimental advancements that led to this result. Published by the American Physical Society 2024", "concepts": ["Physics", "Nuclear physics", "Classical mechanics", "Philosophy", "Linguistics"], "domain": "computer_science"}
{"id": "https://openalex.org/W2800392236", "title": "SCANPY: large-scale single-cell gene expression data analysis", "abstract": "Scanpy is a scalable toolkit for analyzing single-cell gene expression data. It includes methods for preprocessing, visualization, clustering, pseudotime and trajectory inference, differential expression testing, and simulation of gene regulatory networks. Its Python-based implementation efficiently deals with data sets of more than one million cells ( https://github.com/theislab/Scanpy ). Along with Scanpy, we present AnnData, a generic class for handling annotated data matrices ( https://github.com/theislab/anndata ).", "concepts": ["Computational biology", "Biology", "Computer science", "Data mining", "Genetics", "Artificial intelligence", "Programming language", "Database"], "domain": "biology"}
{"id": "https://openalex.org/W4361289889", "title": "Benefits, Limits, and Risks of GPT-4 as an AI Chatbot for Medicine", "abstract": "Chatbots are computer programs with which one can have a conversation. In this article, the authors describe how the GPT-4 chatbot, which has been given a general education, could affect the practice of medicine.", "concepts": ["Computer science", "Medicine", "Medical education", "Engineering ethics", "Psychology", "World Wide Web", "Engineering", "Communication"], "domain": "psychology"}
{"id": "https://openalex.org/W3095583226", "title": "Pfam: The protein families database in 2021", "abstract": "Abstract The Pfam database is a widely used resource for classifying protein sequences into families and domains. Since Pfam was last described in this journal, over 350 new families have been added in Pfam 33.1 and numerous improvements have been made to existing entries. To facilitate research on COVID-19, we have revised the Pfam entries that cover the SARS-CoV-2 proteome, and built new entries for regions that were not covered by Pfam. We have reintroduced Pfam-B which provides an automatically generated supplement to Pfam and contains 136 730 novel clusters of sequences that are not yet matched by a Pfam family. The new Pfam-B is based on a clustering by the MMseqs2 software. We have compared all of the regions in the RepeatsDB to those in Pfam and have started to use the results to build and refine Pfam repeat families. Pfam is freely available for browsing and download at http://pfam.xfam.org/.", "concepts": ["Biology", "Computational biology", "Database", "Bioinformatics", "Genetics", "Computer science"], "domain": "environmental_science"}
{"id": "https://openalex.org/W4401146808", "title": "A Detailed Case Study on Deviation, Out-of-Specification(OOS) and CAPA Generation in Pharmaceutical Industry", "abstract": "This review provide an overview of the various documentation of quality management system, which includes deviations, OOS and CAPA. A detailed case study of deviations, out-of-Specification and CAPA generation is beneficial for improving pharmaceutical capabilities and understanding the documentation associated with a quality management system. It is essential for understanding deviations and out-of-spec in the pharmaceutical industry. The quality of medicines means that they meet the required specifications. The quality management system in the pharmaceutical industry is essential because the drugs or pharmaceutical products are delivered directly to the customer's body. Therefore, identity, purity, safety, and the quality of the products are critical. A Deviation can define as \"a deviation from an approved instruction or established standard\" The deviation process helps identify potential risks to product quality and patient safety and establish the root cause. Once the root cause identifies, appropriate corrective and preventive actions take to prevent reoccurrence. OOS defines as \"A result that is outside the specifications or acceptance criteria established by the manufacturer or laboratory\" As the industry moves to newer and more complicated products, quality control procedures must be in place to ensure consistent product quality. \"CAPA defined by corrections.", "concepts": ["Risk analysis (engineering)", "Computer science", "Operations management", "Reliability engineering", "Business", "Engineering", "Medicine", "Marketing"], "domain": "mathematics"}
{"id": "https://openalex.org/W2902386805", "title": "How To Correctly Determine the Band Gap Energy of Modified Semiconductor Photocatalysts Based on UV–Vis Spectra", "abstract": "ADVERTISEMENT RETURN TO ISSUEPREVViewpointNEXTHow To Correctly Determine the Band Gap Energy of Modified Semiconductor Photocatalysts Based on UV–Vis SpectraPatrycja MakułaPatrycja MakułaFaculty of Chemistry, Jagiellonian University in Kraków, ul. Gronostajowa 2, 30-387 Kraków, PolandMore by Patrycja Makuła, Michał PaciaMichał PaciaFaculty of Chemistry, Jagiellonian University in Kraków, ul. Gronostajowa 2, 30-387 Kraków, PolandMore by Michał Pacia, and Wojciech Macyk*Wojciech MacykFaculty of Chemistry, Jagiellonian University in Kraków, ul. Gronostajowa 2, 30-387 Kraków, Poland*W. Macyk. E-mail: [email protected]More by Wojciech Macykhttp://orcid.org/0000-0002-1317-6115Cite this: J. Phys. Chem. Lett. 2018, 9, 23, 6814–6817Publication Date (Web):December 6, 2018Publication History Published online6 December 2018Published inissue 6 December 2018https://pubs.acs.org/doi/10.1021/acs.jpclett.8b02892https://doi.org/10.1021/acs.jpclett.8b02892editorialACS PublicationsCopyright © 2018 American Chemical Society. This publication is available under these Terms of Use. Request reuse permissions This publication is free to access through this site. Learn MoreArticle Views234144Altmetric-Citations2208LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail PDF (775 KB) Get e-AlertscloseSupporting Info (2)»Supporting Information Supporting Information SUBJECTS:Absorption,Electrical conductivity,Energy,Oxides,Semiconductors Get e-Alerts", "concepts": ["Library science", "Physics", "Engineering physics", "Nanotechnology", "Engineering", "Computer science", "Materials science"], "domain": "physics"}
{"id": "https://openalex.org/W3017125154", "title": "Endothelial cell infection and endotheliitis in COVID-19", "abstract": "Cardiovascular complications are rapidly emerging as a key threat in coronavirus disease 2019 (COVID-19) in addition to respiratory disease. The mechanisms underlying the disproportionate effect of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection on patients with cardiovascular comorbidities, however, remain incompletely understood.1Zhou F Yu T Du R et al.Clinical course and risk factors for mortality of adult inpatients with COVID-19 in Wuhan, China: a retrospective cohort study.Lancet. 2020; 395: 1054-1062Summary Full Text Full Text PDF PubMed Scopus (18730) Google Scholar, 2Horton R Offline: COVID-19—bewilderment and candour.Lancet. 2020; 3951178Summary Full Text Full Text PDF PubMed Scopus (23) Google Scholar SARS-CoV-2 infects the host using the angiotensin converting enzyme 2 (ACE2) receptor, which is expressed in several organs, including the lung, heart, kidney, and intestine. ACE2 receptors are also expressed by endothelial cells.3Ferrario CM Jessup J Chappell MC et al.Effect of angiotensin-converting enzyme inhibition and angiotensin II receptor blockers on cardiac angiotensin-converting enzyme 2.Circulation. 2005; 111: 2605-2610Crossref PubMed Scopus (1278) Google Scholar Whether vascular derangements in COVID-19 are due to endothelial cell involvement by the virus is currently unknown. Intriguingly, SARS-CoV-2 can directly infect engineered human blood vessel organoids in vitro.4Monteil V KH Prado P Hagelkrüys A et al.Inhibition of SARS-CoV-2 infections in engineered human tissues using clinical-grade soluble human ACE2.Cell. 2020; (published online in press.)https://www.cell.com/pb-assets/products/coronavirus/CELL_CELL-D-20-00739.pdfDate accessed: April 17, 2020Summary Full Text Full Text PDF PubMed Scopus (1597) Google Scholar Here we demonstrate endothelial cell involvement across vascular beds of different organs in a series of patients with COVID-19 (further case details are provided in the appendix). Patient 1 was a male renal transplant recipient, aged 71 years, with coronary artery disease and arterial hypertension. The patient's condition deteriorated following COVID-19 diagnosis, and he required mechanical ventilation. Multisystem organ failure occurred, and the patient died on day 8. Post-mortem analysis of the transplanted kidney by electron microscopy revealed viral inclusion structures in endothelial cells (figure A, B). In histological analyses, we found an accumulation of inflammatory cells associated with endothelium, as well as apoptotic bodies, in the heart, the small bowel (figure C) and lung (figure D). An accumulation of mononuclear cells was found in the lung, and most small lung vessels appeared congested. Patient 2 was a woman, aged 58 years, with diabetes, arterial hypertension, and obesity. She developed progressive respiratory failure due to COVID-19 and subsequently developed multi-organ failure and needed renal replacement therapy. On day 16, mesenteric ischaemia prompted removal of necrotic small intestine. Circulatory failure occurred in the setting of right heart failure consequent to an ST-segment elevation myocardial infarction, and cardiac arrest resulted in death. Post-mortem histology revealed lymphocytic endotheliitis in lung, heart, kidney, and liver as well as liver cell necrosis. We found histological evidence of myocardial infarction but no sign of lymphocytic myocarditis. Histology of the small intestine showed endotheliitis (endothelialitis) of the submucosal vessels. Patient 3 was a man, aged 69 years, with hypertension who developed respiratory failure as a result of COVID-19 and required mechanical ventilation. Echocardiography showed reduced left ventricular ejection fraction. Circulatory collapse ensued with mesenteric ischaemia, and small intestine resection was performed, but the patient survived. Histology of the small intestine resection revealed prominent endotheliitis of the submucosal vessels and apoptotic bodies (figure C). We found evidence of direct viral infection of the endothelial cell and diffuse endothelial inflammation. Although the virus uses ACE2 receptor expressed by pneumocytes in the epithelial alveolar lining to infect the host, thereby causing lung injury, the ACE2 receptor is also widely expressed on endothelial cells, which traverse multiple organs.3Ferrario CM Jessup J Chappell MC et al.Effect of angiotensin-converting enzyme inhibition and angiotensin II receptor blockers on cardiac angiotensin-converting enzyme 2.Circulation. 2005; 111: 2605-2610Crossref PubMed Scopus (1278) Google Scholar Recruitment of immune cells, either by direct viral infection of the endothelium or immune-mediated, can result in widespread endothelial dysfunction associated with apoptosis (figure D). The vascular endothelium is an active paracrine, endocrine, and autocrine organ that is indispensable for the regulation of vascular tone and the maintenance of vascular homoeostasis.5Flammer AJ Anderson T Celermajer DS et al.The assessment of endothelial function: from research into clinical practice.Circulation. 2012; 126: 753-767Crossref PubMed Scopus (910) Google Scholar Endothelial dysfunction is a principal determinant of microvascular dysfunction by shifting the vascular equilibrium towards more vasoconstriction with subsequent organ ischaemia, inflammation with associated tissue oedema, and a pro-coagulant state.6Bonetti PO Lerman LO Lerman A Endothelial dysfunction - a marker of atherosclerotic risk.Arterioscl Throm Vas. 2003; 23: 168-175Crossref PubMed Scopus (1923) Google Scholar Our findings show the presence of viral elements within endothelial cells and an accumulation of inflammatory cells, with evidence of endothelial and inflammatory cell death. These findings suggest that SARS-CoV-2 infection facilitates the induction of endotheliitis in several organs as a direct consequence of viral involvement (as noted with presence of viral bodies) and of the host inflammatory response. In addition, induction of apoptosis and pyroptosis might have an important role in endothelial cell injury in patients with COVID-19. COVID-19-endotheliitis could explain the systemic impaired microcirculatory function in different vascular beds and their clinical sequelae in patients with COVID-19. This hypothesis provides a rationale for therapies to stabilise the endothelium while tackling viral replication, particularly with anti-inflammatory anti-cytokine drugs, ACE inhibitors, and statins.7Anderson TJ Meredith IT Yeung AC Frei B Selwyn AP Ganz P The effect of cholesterol-lowering and antioxidant therapy on endothelium-dependent coronary vasomotion.N Engl J Med. 1995; 332: 488-493Crossref PubMed Scopus (1111) Google Scholar, 8Taddei S Virdis A Ghiadoni L Mattei P Salvetti A Effects of angiotensin converting enzyme inhibition on endothelium-dependent vasodilatation in essential hypertensive patients.J Hypertens. 1998; 16: 447-456Crossref PubMed Scopus (105) Google Scholar, 9Flammer AJ Sudano I Hermann F et al.Angiotensin-converting enzyme inhibition improves vascular function in rheumatoid arthritis.Circulation. 2008; 117: 2262-2269Crossref PubMed Scopus (104) Google Scholar, 10Hurlimann D Forster A Noll G et al.Anti-tumor necrosis factor-alpha treatment improves endothelial function in patients with rheumatoid arthritis.Circulation. 2002; 106: 2184-2187Crossref PubMed Scopus (550) Google Scholar, 11Feldmann M Maini RN Woody JN et al.Trials of anti-tumour necrosis factor therapy for COVID-19 are urgently needed.Lancet. 2020; (published online April 9.)https://doi.org/10.1016/S0140-6736(20)30858-8Summary Full Text Full Text PDF PubMed Scopus (442) Google Scholar This strategy could be particularly relevant for vulnerable patients with pre-existing endothelial dysfunction, which is associated with male sex, smoking, hypertension, diabetes, obesity, and established cardiovascular disease, all of which are associated with adverse outcomes in COVID-19. ZV and AJF contributed equally as first authors, and RAS, FR, and HM contributed equally as last authors. AJF reports fees from Alnylam, Amgen, AstraZeneca, Fresenius, Imedos Systems, Novartis, Pfizer, Roche, Vifor, and Zoll, unrelated to this Correspondence. MRM reports consulting relationships with Abbott, Medtronic, Janssen, Mesoblast, Portola, Bayer, NupulseCV, FineHeart, Leviticus, Baim Institute for Clinical Research, Riovant, and Triple Gene, unrelated to this Correspondence. FR has been paid for the time spent as a committee member for clinical trials, advisory boards, other forms of consulting and lectures or presentations. These payments were made directly to the University of Zurich and no personal payments were received in relation to these trials or other activities. All other authors declare no competing interests. Download .pdf (1.83 MB) Help with pdf files Supplementary appendix Clinical course and risk factors for mortality of adult inpatients with COVID-19 in Wuhan, China: a retrospective cohort studyThe potential risk factors of older age, high SOFA score, and d-dimer greater than 1 μg/mL could help clinicians to identify patients with poor prognosis at an early stage. Prolonged viral shedding provides the rationale for a strategy of isolation of infected patients and optimal antiviral interventions in the future. Full-Text PDF Electron microscopy of SARS-CoV-2: a challenging task – Authors' replyWe thank Cynthia Goldsmith and colleagues for their interest in our recent Correspondence.1 We described autopsy findings from patients who had died from COVID-19 and showed a systemic endotheliitis with evidence of loss of integrity of the endothelial monolayer.1 Full-Text PDF Electron microscopy of SARS-CoV-2: a challenging taskWe read with interest the Correspondence by Zsuzsanna Varga and colleagues1 on the possible infection of endothelial cells by SARS-CoV-2 using electron microscopic (EM) images as evidence. However, we believe the EM images in the Correspondence do not show coronavirus particles but instead show cross-sections of the rough endoplasmic reticulum (RER). These spherical structures are surrounded by dark dots, which might have been interpreted as spikes on coronavirus particles but are instead ribosomes. Full-Text PDF", "concepts": ["Virology", "Medicine", "Biology", "Internal medicine"], "domain": "environmental_science"}
{"id": "https://openalex.org/W4396560090", "title": "2024 Alzheimer's disease facts and figures", "abstract": "This article describes the public health impact of Alzheimer's disease (AD), including prevalence and incidence, mortality and morbidity, use and costs of care and the ramifications of AD for family caregivers, the dementia workforce and society. The Special Report discusses the larger health care system for older adults with cognitive issues, focusing on the role of caregivers and non-physician health care professionals. An estimated 6.9 million Americans age 65 and older are living with Alzheimer's dementia today. This number could grow to 13.8 million by 2060, barring the development of medical breakthroughs to prevent or cure AD. Official AD death certificates recorded 119,399 deaths from AD in 2021. In 2020 and 2021, when COVID-19 entered the ranks of the top ten causes of death, Alzheimer's was the seventh-leading cause of death in the United States. Official counts for more recent years are still being compiled. Alzheimer's remains the fifth-leading cause of death among Americans age 65 and older. Between 2000 and 2021, deaths from stroke, heart disease and HIV decreased, whereas reported deaths from AD increased more than 140%. More than 11 million family members and other unpaid caregivers provided an estimated 18.4 billion hours of care to people with Alzheimer's or other dementias in 2023. These figures reflect a decline in the number of caregivers compared with a decade earlier, as well as an increase in the amount of care provided by each remaining caregiver. Unpaid dementia caregiving was valued at $346.6 billion in 2023. Its costs, however, extend to unpaid caregivers' increased risk for emotional distress and negative mental and physical health outcomes. Members of the paid health care and broader community-based workforce are involved in diagnosing, treating and caring for people with dementia. However, the United States faces growing shortages across different segments of the dementia care workforce due to a combination of factors, including the absolute increase in the number of people living with dementia. Therefore, targeted programs and care delivery models will be needed to attract, better train and effectively deploy health care and community-based workers to provide dementia care. Average per-person Medicare payments for services to beneficiaries age 65 and older with AD or other dementias are almost three times as great as payments for beneficiaries without these conditions, and Medicaid payments are more than 22 times as great. Total payments in 2024 for health care, long-term care and hospice services for people age 65 and older with dementia are estimated to be $360 billion. The Special Report investigates how caregivers of older adults with cognitive issues interact with the health care system and examines the role non-physician health care professionals play in facilitating clinical care and access to community-based services and supports. It includes surveys of caregivers and health care workers, focusing on their experiences, challenges, awareness and perceptions of dementia care navigation.", "concepts": ["Medicine", "Gerontology", "Nursing", "Physics", "Pathology", "Optics", "Economics", "Economic growth"], "domain": "economics"}
{"id": "https://openalex.org/W4220807057", "title": "Omicron escapes the majority of existing SARS-CoV-2 neutralizing antibodies", "abstract": "The SARS-CoV-2 B.1.1.529 (Omicron) variant contains 15 mutations of the receptor-binding domain (RBD). How Omicron evades RBD-targeted neutralizing antibodies requires immediate investigation. Here we use high-throughput yeast display screening1,2 to determine the profiles of RBD escaping mutations for 247 human anti-RBD neutralizing antibodies and show that the neutralizing antibodies can be classified by unsupervised clustering into six epitope groups (A-F)-a grouping that is highly concordant with knowledge-based structural classifications3-5. Various single mutations of Omicron can impair neutralizing antibodies of different epitope groups. Specifically, neutralizing antibodies in groups A-D, the epitopes of which overlap with the ACE2-binding motif, are largely escaped by K417N, G446S, E484A and Q493R. Antibodies in group E (for example, S309)6 and group F (for example, CR3022)7, which often exhibit broad sarbecovirus neutralizing activity, are less affected by Omicron, but a subset of neutralizing antibodies are still escaped by G339D, N440K and S371L. Furthermore, Omicron pseudovirus neutralization showed that neutralizing antibodies that sustained single mutations could also be escaped, owing to multiple synergetic mutations on their epitopes. In total, over 85% of the tested neutralizing antibodies were escaped by Omicron. With regard to neutralizing-antibody-based drugs, the neutralization potency of LY-CoV016, LY-CoV555, REGN10933, REGN10987, AZD1061, AZD8895 and BRII-196 was greatly undermined by Omicron, whereas VIR-7831 and DXP-604 still functioned at a reduced efficacy. Together, our data suggest that infection with Omicron would result in considerable humoral immune evasion, and that neutralizing antibodies targeting the sarbecovirus conserved region will remain most effective. Our results inform the development of antibody-based drugs and vaccines against Omicron and future variants.", "concepts": ["Virology", "Chemistry", "Biology", "Molecular biology", "Genetics"], "domain": "chemistry"}
{"id": "https://openalex.org/W4200426529", "title": "Emerging S‐Scheme Photocatalyst", "abstract": "Photocatalysis is a green technology to use ubiquitous and intermittent sunlight. The emerging S-scheme heterojunction has demonstrated its superiority in photocatalysis. This article covers the state-of-the-art progress and provides new insights into its general designing criteria. It starts with the challenges confronted by single photocatalyst from the perspective of energy dissipation by borrowing the common behaviors in the dye molecule. Subsequently, other problems faced by single photocatalyst are summarized. Then a viable solution for these problems is the construction of heterojunctions. To overcome the problems and mistakes of type-II and Z-scheme heterojunctions, S-scheme heterojunction is proposed and the underlying reaction mechanism is summarized. Afterward, the design principles for S-scheme heterojunction are proposed and four types of S-scheme heterojunctions are suggested. Following this, direct characterization techniques for testifying the charge transfer in S-scheme heterojunction are presented. Finally, different photocatalytic applications of S-scheme heterojunctions are summarized. Specifically, this work endeavors to clarify the critical understanding on curved Fermi level in S-scheme heterojunction interface, which can help strengthen and advance the fundamental theories of photocatalysis. Moreover, the current challenges and prospects of the S-scheme heterojunction photocatalyst are critically discussed.", "concepts": ["Materials science", "Nanotechnology", "Computer science", "Optoelectronics", "Chemistry", "Mathematics", "Mathematical analysis", "Biochemistry"], "domain": "chemistry"}
{"id": "https://openalex.org/W2799524357", "title": "MEGA X: Molecular Evolutionary Genetics Analysis across Computing Platforms", "abstract": "The Molecular Evolutionary Genetics Analysis (Mega) software implements many analytical methods and tools for phylogenomics and phylomedicine. Here, we report a transformation of Mega to enable cross-platform use on Microsoft Windows and Linux operating systems. Mega X does not require virtualization or emulation software and provides a uniform user experience across platforms. Mega X has additionally been upgraded to use multiple computing cores for many molecular evolutionary analyses. Mega X is available in two interfaces (graphical and command line) and can be downloaded from www.megasoftware.net free of charge.", "concepts": ["Biology", "Operating system", "Computer science", "Computational biology", "Genetics", "Physics", "Astronomy", "Economics"], "domain": "physics"}
{"id": "https://openalex.org/W4210642183", "title": "Dexamethasone in Hospitalized Patients with Covid-19", "abstract": "BackgroundCoronavirus disease 2019 (Covid-19) is associated with diffuse lung damage. Glucocorticoids may modulate inflammation-mediated lung injury and thereby reduce progression to respiratory failure and death.MethodsIn this controlled, open-label trial comparing a range of possible treatments in patients who were hospitalized with Covid-19, we randomly assigned patients to receive oral or intravenous dexamethasone (at a dose of 6 mg once daily) for up to 10 days or to receive usual care alone. The primary outcome was 28-day mortality. Here, we report the final results of this assessment.ResultsA total of 2104 patients were assigned to receive dexamethasone and 4321 to receive usual care. Overall, 482 patients (22.9%) in the dexamethasone group and 1110 patients (25.7%) in the usual care group died within 28 days after randomization (age-adjusted rate ratio, 0.83; 95% confidence interval [CI], 0.75 to 0.93; P<0.001). The proportional and absolute between-group differences in mortality varied considerably according to the level of respiratory support that the patients were receiving at the time of randomization. In the dexamethasone group, the incidence of death was lower than that in the usual care group among patients receiving invasive mechanical ventilation (29.3% vs. 41.4%; rate ratio, 0.64; 95% CI, 0.51 to 0.81) and among those receiving oxygen without invasive mechanical ventilation (23.3% vs. 26.2%; rate ratio, 0.82; 95% CI, 0.72 to 0.94) but not among those who were receiving no respiratory support at randomization (17.8% vs. 14.0%; rate ratio, 1.19; 95% CI, 0.92 to 1.55).ConclusionsIn patients hospitalized with Covid-19, the use of dexamethasone resulted in lower 28-day mortality among those who were receiving either invasive mechanical ventilation or oxygen alone at randomization but not among those receiving no respiratory support. (Funded by the Medical Research Council and National Institute for Health Research and others; RECOVERY ClinicalTrials.gov number, NCT04381936; ISRCTN number, 50189673.) Quick Take Dexamethasone and Covid-19 2m 20s", "concepts": ["Medicine", "Internal medicine", "Physics", "Optics"], "domain": "physics"}
